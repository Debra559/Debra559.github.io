<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>金娇娇</title>
        <subtitle>去留无意，漫随天外云卷云舒</subtitle>
        <icon>https://jinjiaojiao.top/images/favicon.ico</icon>
        <link>https://jinjiaojiao.top</link>
        <author>
          <name>Debra</name>
        </author>
        <description>金同学的个人博客</description>
        <language>zh-CN</language>
        <pubDate>Thu, 14 Mar 2024 15:31:25 +0800</pubDate>
        <lastBuildDate>Thu, 14 Mar 2024 15:31:25 +0800</lastBuildDate>
        <category term="计算机，人工智能，产品，数学建模，算法，网页开发" />
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/03/14/docker/</guid>
            <title>docker</title>
            <link>https://jinjiaojiao.top/2024/03/14/docker/</link>
            <pubDate>Thu, 14 Mar 2024 15:31:25 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;docker 的出现可以说让应用环境的配置、发布和测试变得异常轻松，尤其是现在大家都在讨论 coine swmp poman，&lt;/p&gt;
&lt;p&gt;如果没有 docker 的先决知识，大家听起来可能一头雾水。这期视频呢，我会用实例向大家介绍 docker 的基本概念、安装和使用，以及如何用 docker compose 来同时管理多个容器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;docker 的基本概念&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在学习使用 docker 之前，我们需要知道它是用来解决什么样的问题。&lt;/p&gt;
&lt;p&gt;比如，你写了一个 web 应用，并且本地调试没有任何问题，这时候你想发给你的朋友试试看，或者部署到远程的云服务器上。那么首先你需要配置相同的软件，比如数据库、web 服务器、必要的插件、库等等。而且你还不能保证软件一定能够正常运行起来，因为别人用的可能是完全不同的操作系统。即便同样是使用 Linux，每种发行版也会有微小的区别。为了模拟完全相同的本地开发环境，我们自然会想到使用虚拟机，但是虚拟机需要模拟硬件，运行整个操作系统，不但体积臃肿，内存这样高，程序的性能也会受到影响。&lt;/p&gt;
&lt;p&gt;这时候我们的 docker 就派上了用场。docker 在概念上与虚拟机非常类似，但却轻量很多，它不会去模拟底层的硬件，只会为每一个应用提供完全隔离的运行环境。你可以在环境中配置不同的工具软件，并且不同环境之间相互不影响。这个环境在 docker 中也被称作 container。容器。&lt;/p&gt;
&lt;p&gt;讲到这里，我们就不得不提到 docker 中的三个重要概念，Docker file image 和 container image。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Image，镜像&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你可以把它理解成一个虚拟机的快照，里面包含了你要部署的应用程序以及它所关联的所有库软件。通过镜像，我们可以创建许多不同的 container 容器。这里的容器就像是一台台运行起来的虚拟机，里面运行了你的应用程序，每个容器是独立运行的，它们相互之间不影响。&lt;/p&gt;
&lt;p&gt;最后，&lt;strong&gt;Docker file&lt;/strong&gt; 就像是一个自动化脚本，它主要被用来创建我们之前讲到的镜像。这个过程就好比是我们在虚拟机中安装操作系统和软件一样，只不过是通过 docker file 这个自动化脚本完成了。&lt;/p&gt;
&lt;p&gt;快速上手 docker 的最好方法就是亲自安装并去使用它。如果你使用的是 Windows 和 Mac，你可以在官网下载一个叫做 docker desktop 的应用，并且在 WINDOW10 以上。你可以使用 WS2，也就是 Windows 下的 Linux 子系统来运行 docker，这也是我这里使用的配置方式。&lt;/p&gt;
&lt;p&gt;如果你使用的不是 Windows 最新的预览版本 WS2 安装可能稍微复杂一点，不过基本也是按照这里的步骤安装。&lt;/p&gt;
&lt;p&gt;在 Linux 下面我们可以直接使用包管理工具，我们按照这里的指示一步一步执行即可。如果你使用的是 Vscode，我也非常推荐安装 docker 的扩展，&lt;/p&gt;
&lt;p&gt;它会提供 docker file 的语法检测、代码高亮、自动补全等等。&lt;/p&gt;
&lt;p&gt;你也可以通过菜单运行各种 docker 命令，&lt;/p&gt;
&lt;p&gt;并且在左侧面板中看到你创建的所有镜像容器等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;部署应用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接下来我们就尝试用 docker 来部署一个应用。这里我用之前写的一个拍 on 程序来举例，这是一个非常简单的用 flask 搭建的记账工具，主要为了方便自己对日常开销的一些统计。&lt;/p&gt;
&lt;p&gt;首先，我们在应用的根目录下创建一个 Dockertfile 文件。第一行我们需要用 from 命令指定一个基础镜像，这样可以帮我们节省许多软件安装配置的时间。&lt;/p&gt;
&lt;p&gt;可以看到在 docker hub 上提供了许多高质量的操作系统镜像，比如 Ubuntu 、debian 、fedora、 alpine 等等。不同的操作系统提供不同的包管理工具，比如 Ubuntu 上的 apt、fedora 上的 dnf。&lt;/p&gt;
&lt;p&gt;但是在 Docker Hub 上还有许多方便某一种语言、某种框架开发的镜像，比如 nginx、redis、node、 Python、tomcat 等等。&lt;/p&gt;
&lt;p&gt;由于这里我做的是 Python 应用的开发，自然我会使用 Python 的镜像，这样免去了它安装步骤。&lt;/p&gt;
&lt;p&gt;FROM python:3.8-slim-buster&lt;/p&gt;
&lt;p&gt;这里的 Python 是官方镜像的名字冒号，后面这一串是版本号，同时也是一个标签。我们可以点击 Python 转到 docker HUB 的镜像页面，里面可以找到所有支持的标签。&lt;/p&gt;
&lt;p&gt;比如我们这里用的是 Python3.8 版本，运行在 debian buster 的发行版上&lt;/p&gt;
&lt;p&gt;后面的 WORKDIR 指定了之后所有 docker 命令的工作路径，注意是这个命令之后的所有 docker 命令 (working directory)，比如我们马上要讲到的 RUN COPY 等等。当然，如果这个路径不存在，Docker 会帮你自动创建，这样可以避免使用绝对路径或者手动 CD 切换路径，增加程序的可读性。&lt;/p&gt;
&lt;p&gt;之后呢，我们可以调用 copy 命令将所有的程序拷贝到 docker 镜像中。&lt;/p&gt;
&lt;p&gt;第一个参数代表本地文件，&amp;quot;.&amp;quot; 代表程序根目录下的所有文件，&lt;/p&gt;
&lt;p&gt;第二个参数代表 docker 镜像中的路径，这里的 &amp;quot;.&amp;quot; 代表当前的工作路径，也就是之前指定的 APP 目录。随后的 RUN 允许我们在创建镜像时运行任意的 shell 命令。因为我们用的是 Linux 镜像，所以像 echo、pwd、 cp、rm 这些都是合法的。比如这里我用到 pip install 来安装 python 程序的所有关联。&lt;/p&gt;
&lt;p&gt;通过以上的所有命令，我们就可以完成一个 docker 镜像的创建。在 docker file 的最后，我们会用到 CMD 来指定当 docker 容器运行起来以后要执行的命令。大家需要注意这里容器和镜像的区别，并且它和我们之前讲到的 RUN 不一样。Run 是创建镜像时候使用的，而 CMD 是运行容器的时候使用的。到这里，我们的自动化脚本 doer file 就完成了。&lt;/p&gt;
&lt;p&gt;（terminal 运行）&lt;/p&gt;
&lt;p&gt;接下来我们可以使用 docker build 来创建一个镜像，&lt;/p&gt;
&lt;p&gt;docker build -t my-finance .&lt;/p&gt;
&lt;p&gt;这里的横杠 T 指定了我们镜像的名。字最后面的 &amp;quot;.&amp;quot; 告诉 docker，应该在当前目录下寻找这个 docker file，这个不能省略。&lt;/p&gt;
&lt;p&gt;第一次调用 docker build 会比较慢，因为 docker 会下载必要的镜像文件，然后一行行运行我们的指令，不过再次调用就会快很多，因为 docker 会缓存之前的每一个操作。这个在 docker 中也被称作分层，这里我们就不展开讨论了。&lt;/p&gt;
&lt;p&gt;docker run -p 80:5000 -d my-finance&lt;/p&gt;
&lt;p&gt;有了镜像以后，我们可以通过 docker run 来启动一个容器。这里需要注意的是这个 - p 参数，它会将容器上的某一个端口映射到你的本地主机上，这样你才能够从主机上访问容器中的 web 应用。前面的 80 是我们本地主机上的端口，后面是容器上的端口，这个不要搞反了。第二个参数 - d，这样容器在后台运行，这样容器的输出就不会直接显示在控制台。&lt;/p&gt;
&lt;p&gt;如果不出意外的话，你已经可以在浏览器中访问这个 web 应用了。我们通过 docker desktop 这个图形界面可以查看应用在后台的所有输出，这个对于调试非常方便，&lt;/p&gt;
&lt;p&gt;同时我们也可以看到当前容器的各种信息状态等等。这里的 containers 中显示了我们创建的所有容器。我们可以选择停止、重启或者删除它们还可以通过 shell 远程调试这个容器。这里是它们所对应的命令行指令。&lt;/p&gt;
&lt;p&gt;需要注意的是，当我们删除一个容器的时候，之前所做的修改、新添加的数据会全部丢失，这就好比是我们删除一个虚拟机，里面的数据会一同销毁一样。如果我们希望保留容器中的数据，我们可以使用 docker 提供的 volume 数据卷。你可以把当做是一个在本地主机和不同容器中共享的文件夹。比如，你在容器中修改了某一个 volume 的数据，它会同时反映在其他的容器上。&lt;/p&gt;
&lt;p&gt;docker run -dp 80：5000 -v my-finance-data:/etc/finace my-finance&lt;/p&gt;
&lt;p&gt;我们可以通过 docker volume create 来创建一个数据卷，随后再启动容器的时候，我们可以通过 - v 参数指定将这个数据卷挂载 (mount) 到容器的哪一个路径上。可以看到我们这里将 my finance data 挂载到了 etc/finance 这个路径上，像这个路径写入的任何数据都会被永久的保存在这个数据卷中。&lt;/p&gt;
&lt;p&gt;之前我们讲到的例子都只涉及单个容器，但在实际使用中，我们的应用程序可能会用到多个容器共同协作。比如我们可以使用一个容器来运行 web 应用，另一个容器来运行数据库系统 mysql，这样可以做到数据和应用逻辑的有效分离。比如当 web 程序宕机了，数据库依然在有效运转，这个时候我们只需要修复 web 容器即可，&lt;/p&gt;
&lt;p&gt;而 docker compose 刚好可以帮我们做到这一点，我们可以创建一个 docker compose.yama 文件，在这个文件下，我们通过 services 来定义多个 container，比如这里我们定义一个 web 容器，它里面运行了我们的。Web 应用。然后在定义一个 DB 容器里面运行了 MYCQL 数据库系统，这里我们可以通过这两个环境变量指定数据库的名字和连接密码。同时在 DB 容器中我们还可以通过 volumes 指定一个数据卷，用来永久存放数据。&lt;/p&gt;
&lt;p&gt;定义完毕之后，我们保存文件，使用 docker compose up 来运行所有的容器。这里的 - d 同样代表在后台运行所有容器不直接输出在控制台。与这个命令对应的，我们可以使用 docker compose down . 来停止并删除所有的容器。不过新创建的数据卷需要我们手动删除，除非我们在后面加入 volumes 参数。另外，刚刚讲到的所有操作也都可以在图形界面中完成。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/03/13/%E5%8E%9F%E5%9E%8B%E8%AE%BE%E8%AE%A1/</guid>
            <title>原型设计</title>
            <link>https://jinjiaojiao.top/2024/03/13/%E5%8E%9F%E5%9E%8B%E8%AE%BE%E8%AE%A1/</link>
            <category term="产品经理" scheme="https://jinjiaojiao.top/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <pubDate>Wed, 13 Mar 2024 14:45:38 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240313144543438.png&#34; alt=&#34;image-20240313144543438&#34; /&gt;&lt;/p&gt;
&lt;p&gt;常用软件 / 网站：&lt;/p&gt;
&lt;p&gt;墨刀 / Axure&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/03/13/%E5%A5%BD%E7%94%A8%E7%BD%91%E7%AB%99%E8%AE%B0%E5%BD%95/</guid>
            <title>好用网站记录</title>
            <link>https://jinjiaojiao.top/2024/03/13/%E5%A5%BD%E7%94%A8%E7%BD%91%E7%AB%99%E8%AE%B0%E5%BD%95/</link>
            <pubDate>Wed, 13 Mar 2024 14:32:31 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;avif-&amp;gt;jpg&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9jb252ZXJ0aW8uY28vemgvYXZpZi1qcGcv&#34;&gt;https://convertio.co/zh/avif-jpg/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;网站设计的技巧&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cud29zaGlwbS5jb20vcGQvNTY5MTQyMC5odG1s&#34;&gt;https://www.woshipm.com/pd/5691420.html&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;boardmix博思白板&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#boardmix博思白板&#34;&gt;#&lt;/a&gt; boardmix 博思白板&lt;/h2&gt;
&lt;p&gt;下载 ppt 需要收费&lt;/p&gt;
&lt;h2 id=&#34;pocesson&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#pocesson&#34;&gt;#&lt;/a&gt; PocessOn&lt;/h2&gt;
&lt;h2 id=&#34;canvas可画&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#canvas可画&#34;&gt;#&lt;/a&gt; Canvas 可画&lt;/h2&gt;
&lt;h2 id=&#34;&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#&#34;&gt;#&lt;/a&gt; &lt;/h2&gt;
&lt;h2 id=&#34;文本gpt&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#文本gpt&#34;&gt;#&lt;/a&gt; 文本 GPT&lt;/h2&gt;
&lt;h3 id=&#34;1-kimi-chat&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-kimi-chat&#34;&gt;#&lt;/a&gt; &lt;strong&gt;1. Kimi Chat&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;笔者认为目前国内最聪明的 AI 工具&lt;/p&gt;
&lt;p&gt;Kimi 的地址：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9raW1pLmFp&#34;&gt;https://kimi.ai&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Kimi 支持最长 20 万字的上下文聊天，支持联网打开网址、支持搜索信息、支持上传文件进行提问、支持识别图片文字。&lt;/p&gt;
&lt;h3 id=&#34;2-chatglm&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-chatglm&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2. ChatGLM&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;国内综合实力最强的 AI 工具&lt;/p&gt;
&lt;h3 id=&#34;3文心一言&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3文心一言&#34;&gt;#&lt;/a&gt; 3. 文心一言&lt;/h3&gt;
&lt;h3 id=&#34;4通义千问&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4通义千问&#34;&gt;#&lt;/a&gt; 4. 通义千问&lt;/h3&gt;
&lt;h2 id=&#34;图片类&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#图片类&#34;&gt;#&lt;/a&gt; 图片类&lt;/h2&gt;
&lt;h3 id=&#34;1-通义万相&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-通义万相&#34;&gt;#&lt;/a&gt; &lt;strong&gt;1. 通义万相&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly90b25neWkuYWxpeXVuLmNvbS93YW54aWFuZy8=&#34;&gt;https://tongyi.aliyun.com/wanxiang/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;它支持文字生成图像、图像生成图像、图像风格模仿，目前免费试用，每人每天赠送 50 个灵感值，可以创作 50 张图片。&lt;/p&gt;
&lt;h3 id=&#34;2dreamina&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2dreamina&#34;&gt;#&lt;/a&gt; 2.&lt;strong&gt;Dreamina&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;剪映旗下的文字生成图片工具，生成图片的质量很高，据说使用的是 Stable Diffusion 模型。&lt;/p&gt;
&lt;p&gt;Dreamina 的地址：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuY2FwY3V0LmNuL2FpLXRvb2w=&#34;&gt;https://www.capcut.cn/ai-tool&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dreamina 不限量使用！使用的体验跟 MidJourney 相似，支持中文提示词。&lt;/p&gt;
&lt;p&gt;重要的是，它支持对生成的图片进行编辑、美化、局部重绘、扩展图片等！&lt;/p&gt;
&lt;h3 id=&#34;3liblibai&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3liblibai&#34;&gt;#&lt;/a&gt; 3.LibLibAI&lt;/h3&gt;
&lt;p&gt;国内基于 Stable Diffusion 模型开发的图片生成工具，之所以在那么多相似工具中把它放在第三个，原因在于它和原生的 Stable Diffusion WebUI 体验相似。&lt;/p&gt;
&lt;p&gt;你可以调整模型、选择 LoRA、使用 ControlNet 等插件，甚至在最新的版本中，上线了图片生成视频功能！&lt;/p&gt;
&lt;p&gt;LibLib 每天赠送 300 电力值，每幅图片消耗 1-N 个电力值，足够体验了。&lt;/p&gt;
&lt;p&gt;应用场景：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 社群私域运营场景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;引流文案、欢迎语、朋友圈文案、社群文案、促活话题设计 &amp;amp; 文案、促活问答问题 &amp;amp; 文案、早晚安文案、氛围组话术、文案话术排版美化&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 自媒体内容运营场景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小红书标题优化、小红书笔记排版、小红书笔记撰写、短视频脚本撰写、公众号文章撰写、直播脚本撰写、直播氛围组话术撰写、软文文案撰写、品牌通稿撰写、品牌通稿标题优化&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 市场活动场景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;市场分析调研、生成调研问卷、分析调研问卷、撰写营销策划案、撰写营销活动排期、SEO 优化、SEM 优化、信息流广告素材、线下活动策划、Rundown 审查&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. 数据分析场景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据采集、数据处理、数据清洗、数据分析维度建议、数据分析图表生成、业务数据分析、行业报告撰写、用户评价分析&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. 产品研发场景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;产品原型图生成、产品 UI 图生成、PRD 撰写、流程图生成、撰写代码、代码解释、代码优化、截图生成前端代码、编程语言学习&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. 绘画设计场景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LOGO 设计、主题海报生成、产品商详图、服装模特换装、字体设计、二维码美化、老照片修复、老照片上色、配图插画生成、写真照生成、线稿上色、表情包生成、装修图生成、包装设计、建筑设计&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7. 日常办公场景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;制作 PPT、润色日报周报、写客户邮件、批量处理 Excel 表格、文稿合同审核、OKR 润色、绩效考核评定、招聘面试、通知撰写、公文撰写&lt;/p&gt;
&lt;p&gt;根据您的需求，以下是几个提供高清万物互联和智能门锁图片的网站及其链接：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;视觉中国（&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL1ZDRy5DT00=&#34;&gt;VCG.COM&lt;/span&gt;）
&lt;ul&gt;
&lt;li&gt;网站提供了大量智能门锁的高清图片素材，用户可以下载和购买正版图片。&lt;/li&gt;
&lt;li&gt;链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cudmNnLmNvbS9jcmVhdGl2ZS1pbWFnZS96aGluZW5nc3VvLw==&#34;&gt;智能锁图片素材库 - 视觉中国&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;华为官网
&lt;ul&gt;
&lt;li&gt;华为官网展示了华为智能门锁的产品图片，可以找到与智能门锁相关的高清图片。&lt;/li&gt;
&lt;li&gt;链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9jb25zdW1lci5odWF3ZWkuY29tL2NuL3NtYXJ0LWxvY2sv&#34;&gt;华为智能门锁 - 华为官网&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;千图网
&lt;ul&gt;
&lt;li&gt;千图网提供了多种智能门锁相关的图片素材，包括高清背景图片、设计模板等。&lt;/li&gt;
&lt;li&gt;链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuNThwaWMuY29tL3R1cGlhbi96aGluZW5nbWVuc3VvLmh0bWw=&#34;&gt;智能门锁图片素材 - 千图网&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;摄图网
&lt;ul&gt;
&lt;li&gt;摄图网拥有关于智能门锁的正版可商用图片素材，包括高清图片、海报模板等。&lt;/li&gt;
&lt;li&gt;链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly82OTlwaWMuY29tL3R1cGlhbi96aGluZW5nbWVuc3VvLmh0bWw=&#34;&gt;智能门锁图片素材 - 摄图网&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;用户调研网站&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9qaW5zaHVqdS5uZXQv&#34;&gt;https://jinshuju.net/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9kb2NzLnBpbmdjb2RlLmNvbS9hc2svMjE3MzEuaHRtbA==&#34;&gt;https://docs.pingcode.com/ask/21731.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ppt + 视频录制&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aGl5YW4ud29uZGVyc2hhcmUuY24v&#34;&gt;https://zhiyan.wondershare.cn/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;网络上有许多提供免费 PPT 模板和资源的网站，可以帮助您创建专业且吸引人的演示文稿。以下是一些值得推荐的网站：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;SlidesCarnival&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuc2xpZGVzY2Fybml2YWwuY29tLw==&#34;&gt;https://www.slidescarnival.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;SlidesCarnival 提供了大量免费的 PPT 模板，设计现代且多样化，适合各种演示需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SlideModel&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9zbGlkZW1vZGVsLmNvbS8=&#34;&gt;https://slidemodel.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;SlideModel 提供了丰富的 PPT 模板、幻灯片和图表，用户可以根据需要进行搜索和筛选。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SlideHunter&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9zbGlkZWh1bnRlci5jb20v&#34;&gt;https://slidehunter.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;SlideHunter 提供了各种免费的 PPT 模板和幻灯片，涵盖了商业、教育和个人用途。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Canva&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuY2FudmEuY29tLw==&#34;&gt;https://www.canva.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Canva 是一个在线设计工具，提供了大量的免费 PPT 模板，用户可以直接在网站上编辑和定制。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SlideGeeks&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuc2xpZGVnZWVrcy5jb20v&#34;&gt;https://www.slidegeeks.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;SlideGeeks 提供了专业的 PPT 模板和幻灯片，设计简洁且专业，适合商务演示。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PoweredTemplate&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cucG93ZXJlZHRlbXBsYXRlLmNvbS8=&#34;&gt;https://www.poweredtemplate.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;PoweredTemplate 提供了各种模板，包括 PPT 模板、图表和图形，用户可以选择免费或付费资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prezi&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9wcmV6aS5jb20v&#34;&gt;https://prezi.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Prezi 提供了一种不同于传统 PPT 的演示方式，它允许创建动态和交互式的演示文稿，有免费和付费账户选项。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google Slides&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS9zbGlkZXMvYWJvdXQv&#34;&gt;https://www.google.com/slides/about/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Google Slides 是 Google Drive 的一部分，提供了一些免费的 PPT 模板，并且可以方便地与他人协作。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL1RlbXBsYXRlLm5ldA==&#34;&gt;Template.net&lt;/span&gt;&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cudGVtcGxhdGUubmV0Lw==&#34;&gt;https://www.template.net/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL1RlbXBsYXRlLm5ldA==&#34;&gt;Template.net&lt;/span&gt; 提供了各种类型的模板，包括 PPT 模板，用户可以根据自己的需求进行筛选和选择。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Office&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly90ZW1wbGF0ZXMub2ZmaWNlLmNvbS8=&#34;&gt;https://templates.office.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Microsoft Office 官方网站提供了一系列的免费 PPT 模板，这些模板设计专业，适合各种场合。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在使用这些网站时，请注意检查每个模板的使用条款，确保在符合许可协议的前提下使用。此外，一些网站可能需要您注册账户或提供电子邮件地址才能下载模板。&lt;/p&gt;
&lt;p&gt;复制再试一次分享&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL2FpcHB0LmNu&#34;&gt;aippt.cn&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ai 绘画软件&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuYXJ0YnJlZWRlci5jb20v&#34;&gt;https://www.artbreeder.com/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在线抠图工具可以帮助您快速地从图片中移除背景或提取特定对象。以下是一些免费的在线抠图网站推荐：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3JlbW92ZS5iZw==&#34;&gt;remove.bg&lt;/span&gt;&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cucmVtb3ZlLmJnLw==&#34;&gt;https://www.remove.bg/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3JlbW92ZS5iZw==&#34;&gt;remove.bg&lt;/span&gt; 是一个非常流行的在线抠图工具，它可以自动识别图片中的人物并移除背景。操作简单，只需上传图片，系统就会自动处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clipping Magic&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9jbGlwcGluZ21hZ2ljLmNvbS8=&#34;&gt;https://clippingmagic.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Clipping Magic 提供了强大的在线抠图服务，可以自动或手动移除图片背景。它还允许您保存透明背景的 PNG 文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fotor&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuZm90b3IuY29tLw==&#34;&gt;https://www.fotor.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Fotor 是一个在线照片编辑工具，提供了简单的抠图功能。它允许用户通过简单的画笔工具来选择和删除背景。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Canva&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuY2FudmEuY29tLw==&#34;&gt;https://www.canva.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Canva 是一个图形设计平台，它提供了一个简单的功能来移除图片背景。虽然 Canva 主要是用于设计，但它的抠图工具对于基本的背景移除非常有效。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PhotoScissors&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9waG90b3NjaXNzb3JzLmNvbS8=&#34;&gt;https://photoscissors.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;PhotoScissors 提供了一个用户友好的界面，可以自动检测和移除图片背景。它还提供了一些基本的编辑选项。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BG Eraser&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuYmctZXJhc2VyLmNvbS8=&#34;&gt;https://www.bg-eraser.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;BG Eraser 专注于移除图片背景，提供了一个简单的拖放界面和一些基本的编辑工具。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lunapic&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cubHVuYXBpYy5jb20vZWRpdG9yLw==&#34;&gt;https://www.lunapic.com/editor/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Lunapic 是一个多功能的在线图像编辑器，其中包括一个简单的抠图工具，允许用户使用魔术棒或套索工具来选择和移除背景。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PicMonkey&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cucGljbW9ua2V5LmNvbS8=&#34;&gt;https://www.picmonkey.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;PicMonkey 提供了一系列图像编辑工具，包括抠图功能。它的背景移除工具可以帮助您快速去除或更换图片背景。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;使用这些在线工具时，请注意它们的使用条款和隐私政策，确保您的图片不包含敏感或私人信息。此外，一些网站可能提供有限的免费使用，而更高级的功能或更频繁的使用可能需要付费订阅。&lt;/p&gt;
&lt;p&gt;PPT：&lt;/p&gt;
&lt;p&gt;稿定设计&lt;/p&gt;
&lt;p&gt;islide&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;第一 PPT&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3d3dy4xcHB0LmNvbS8=&#34;&gt;http://www.1ppt.com/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;第一 PPT 网站拥有丰富的 PPT 资源库，包括模板、背景、图表等，用户可以免费下载并使用这些资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Canva&lt;/strong&gt; (&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuY2FudmEuY29tL3poX2NuLw==&#34;&gt;https://www.canva.com/zh_cn/&lt;/span&gt;)
&lt;ul&gt;
&lt;li&gt;Canva 是一个在线设计工具，提供了许多免费的 PPT 模板，用户可以直接在网站上编辑和定制。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;请注意，虽然这些网站提供免费资源，但在使用时仍需遵守各自的版权声明和使用条款。在使用模板时，建议检查模板的授权情况，确保在合法的范围内使用。&lt;/p&gt;
&lt;p&gt;复制再试一次分享&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/03/05/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/</guid>
            <title>产品设计</title>
            <link>https://jinjiaojiao.top/2024/03/05/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/</link>
            <category term="产品经理" scheme="https://jinjiaojiao.top/categories/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <category term="产品经理" scheme="https://jinjiaojiao.top/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <pubDate>Tue, 05 Mar 2024 09:29:58 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;原型设计&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#原型设计&#34;&gt;#&lt;/a&gt; 原型设计&lt;/h1&gt;
&lt;h2 id=&#34;figma&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#figma&#34;&gt;#&lt;/a&gt; Figma&lt;/h2&gt;
&lt;p&gt;越来越主流产品设计软件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全平台使用&lt;/li&gt;
&lt;li&gt;云端文件&lt;/li&gt;
&lt;li&gt;历史版本&lt;/li&gt;
&lt;li&gt;共同协作（链接）&lt;/li&gt;
&lt;li&gt;实时操作&lt;/li&gt;
&lt;li&gt;团队沟通&lt;/li&gt;
&lt;li&gt;组件和共享样式&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ui界面&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ui界面&#34;&gt;#&lt;/a&gt; UI 界面&lt;/h1&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/29/%E7%AB%9E%E5%93%81%E5%88%86%E6%9E%90/</guid>
            <title>竞品分析</title>
            <link>https://jinjiaojiao.top/2024/02/29/%E7%AB%9E%E5%93%81%E5%88%86%E6%9E%90/</link>
            <category term="产品经理" scheme="https://jinjiaojiao.top/categories/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <category term="产品经理" scheme="https://jinjiaojiao.top/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <pubDate>Thu, 29 Feb 2024 13:48:14 +0800</pubDate>
            <description><![CDATA[ &lt;h2 id=&#34;scrum敏捷开发&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#scrum敏捷开发&#34;&gt;#&lt;/a&gt; scrum 敏捷开发&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MDc5Njg1NzA=&#34;&gt;Scrum 是什么？概念、定义、实施指南 - 知乎 (zhihu.com)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240229144231902.png&#34; alt=&#34;image-20240229144231902&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;竞品分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析&#34;&gt;#&lt;/a&gt; 竞品分析&lt;/h1&gt;
&lt;h2 id=&#34;概念&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#概念&#34;&gt;#&lt;/a&gt; 概念&lt;/h2&gt;
&lt;p&gt;产品与产品之间横向的比较&lt;/p&gt;
&lt;h2 id=&#34;作用&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#作用&#34;&gt;#&lt;/a&gt; 作用&lt;/h2&gt;
&lt;p&gt;1、知己知彼，百战不殆：&lt;br /&gt;
2、为自身产品设计提供功能、可用性、关键技术等方面的参考；&lt;br /&gt;
3、提高自身产品的差异化程度：&lt;br /&gt;
4、为新立项的产品、拍脑袋想出来的，降低风险；&lt;/p&gt;
&lt;h2 id=&#34;为什么竞品分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为什么竞品分析&#34;&gt;#&lt;/a&gt; 为什么竞品分析&lt;/h2&gt;
&lt;p&gt;答：竞品分析可以更好的了解这个行业、了解对手、了解别人都在做什么，探究别人怎么做 为什么这么做，培养产品思维，练习分析能力&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic1.zhimg.com/80/v2-254265c6dcad097f1973246efec88e74_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当我们对一个行业进行研究过后，觉得有前景，准备去做或者已经在做&lt;/strong&gt;，这个时候我们就需要进行竞品分析了。 准备开始做我们需要关注这些&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;看看市面上有没有和自己产品类似的竞品&lt;/li&gt;
&lt;li&gt;快速了解这块领域当前处于什么阶段？蓝海？红海？&lt;/li&gt;
&lt;li&gt;快速了解竞品的产品模式，用户群体，运营模式，是否可以借鉴与改进&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果已经在做了，那么我们做竞品分析更关注这些&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解自己与竞品的&lt;strong&gt;区别&lt;/strong&gt;、差距，自身优势与劣势，产品的市场份额及竞争力，有助于及时调整产品 / 运营策略&lt;/li&gt;
&lt;li&gt;了解客户评价，反馈，进一步了解用户需求，引导产品及服务改良或创新&lt;/li&gt;
&lt;li&gt;关注竞品的最新动向，有助于发现新的增长点，有助于及时调整产品 / 运营策略&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;竞品分析的方法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析的方法&#34;&gt;#&lt;/a&gt; 竞品分析的方法&lt;/h2&gt;
&lt;p&gt;◆竞品分析的目标&lt;br /&gt;
◆竞品分析的维度&lt;br /&gt;
◆如何获取竞争对手信息&lt;br /&gt;
◆竞品分析方法&lt;/p&gt;
&lt;h2 id=&#34;竞品分析目标&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析目标&#34;&gt;#&lt;/a&gt; 竞品分析目标&lt;/h2&gt;
&lt;p&gt;为了解决以下问题：&lt;br /&gt;
a. 对产品要设计哪些功能不确定&lt;br /&gt;
 b. 对产品中某个功能的修改犹豫不决&lt;br /&gt;
 C. 对产品的商业模式有疑问&lt;br /&gt;
 d. 对产品的 U 设计和交互设计不满意&lt;br /&gt;
 e. 对产品的技术实现不满意&lt;/p&gt;
&lt;h2 id=&#34;竞品分析过程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析过程&#34;&gt;#&lt;/a&gt; 竞品分析过程&lt;/h2&gt;
&lt;h3 id=&#34;1明确目的&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1明确目的&#34;&gt;#&lt;/a&gt; 1. 明确目的&lt;/h3&gt;
&lt;p&gt;竞品分析前写下目标&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65e022259f345e8d03666ed7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;不要偏离主线&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic3.zhimg.com/80/v2-dc8c196594ef536c384479fc3b541256_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;2找到竞品&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2找到竞品&#34;&gt;#&lt;/a&gt; 2. 找到竞品&lt;/h3&gt;
&lt;h4 id=&#34;搜索渠道&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#搜索渠道&#34;&gt;#&lt;/a&gt; 搜索渠道&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65e023d29f345e8d036a036e.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;苹果手机 各种应用商店 应用宝 等等等&lt;/p&gt;
&lt;p&gt;用所有能想到的关键词搜索&lt;/p&gt;
&lt;p&gt;关键词搜索&lt;/p&gt;
&lt;p&gt;相似推荐&lt;/p&gt;
&lt;p&gt;罗列竞品&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240228143231350.png&#34; alt=&#34;image-20240228143231350&#34; /&gt;&lt;/p&gt;
&lt;p&gt;直接搜关键词&lt;/p&gt;
&lt;p&gt;电商软件找&lt;/p&gt;
&lt;p&gt;不是越多越好 选合适的 做深度分析&lt;/p&gt;
&lt;p&gt;介绍页找信息&lt;/p&gt;
&lt;p&gt;作为客户去体验&lt;/p&gt;
&lt;p&gt;说明书 / 操作手册&lt;/p&gt;
&lt;p&gt;用户评论（电商 社交媒体 群聊）最在意的是什么 最不满意的是什么&lt;/p&gt;
&lt;p&gt;平台数据&lt;/p&gt;
&lt;p&gt;财报 / 招股书&lt;/p&gt;
&lt;p&gt;合作方（上游的原材料提供商、下游的经销商代理商、营销投放物流运输等服务商）情况和数据&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-85c33e6657acb096dd7fe4ba7c4842f3_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;当我们明确了分析目的之后就是寻找竞品与选择竞品。&lt;/p&gt;
&lt;p&gt;** 如何寻找竞品？** 我们可以通过以下渠道来寻找&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;App Store 分类，应用商城分类&lt;/li&gt;
&lt;li&gt;行业分析报告&lt;/li&gt;
&lt;li&gt;行业媒体&lt;/li&gt;
&lt;li&gt;网上的竞品分析&lt;/li&gt;
&lt;li&gt;各类搜索引擎关键词搜索&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;找出竞品之后，又如何选择竞品？&lt;/strong&gt;&lt;br /&gt;
竞品有很多，我们需要对这些竞品进行分级&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;直接竞品&lt;/strong&gt; – 产品功能相似，目标人群重合，解决方案与技术无明显差异。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;重要竞品&lt;/strong&gt; – 做得比我们好的竞品&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;核心竞品&lt;/strong&gt; – 做得比我们好，并且非常有竞争力的竞品&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一般竞品&lt;/strong&gt; – 不如我的竞品&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;间接竞品&lt;/strong&gt; – 产品功能形态和解决方案不同，但用户群高度重合，解决的用户需求相同，目前不构成直接的利益竞争，但未来有很大的竞争风险。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在确定分级关系之后，在竞品分析过程中，你就需要决定在核心竞品，重要竞品，一般竞品中，对哪些模块需要花多大力度去研究和分析。一般而言需要分析的是主要是重点竞品和核心竞品。&lt;/p&gt;
&lt;h4 id=&#34;怎么选择竞品&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#怎么选择竞品&#34;&gt;#&lt;/a&gt; 怎么选择竞品&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240228153146969.png&#34; alt=&#34;image-20240228153146969&#34; /&gt;&lt;/p&gt;
&lt;p&gt;1、客观：从竞品中，圈出考察维度，得出真实情况，尽量客观公正；&lt;br /&gt;
2、主观：挑选竞品时，主观判断很重要针对境品中的具体比较内容，也是需要主观判断的（比如交互）。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65e026bd9f345e8d03704814.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;3确定维度&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3确定维度&#34;&gt;#&lt;/a&gt; 3. 确定维度&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65e0241c9f345e8d036aa0a3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;维度的选择要和调研目标紧密结合&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic1.zhimg.com/80/v2-4b4a695ee68fecf7ebff8ca86ae7d7b8_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;选择完竞品之后，我们需要定义分析维度。如果此时你不知道怎么定义，不妨先体验一款竞品，然后采取它的信息维度作为分析维度，然后再在后面的竞品数据收集时增加或者删减维度。下面给一个比较通用的分析维度模板&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;竞品基本信息
&lt;ul&gt;
&lt;li&gt;竞品所属公司，公司愿景&lt;/li&gt;
&lt;li&gt;竞品的核心成员&lt;/li&gt;
&lt;li&gt;竞品发展历程&lt;/li&gt;
&lt;li&gt;竞品的运营数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;竞品的产品定位&lt;/li&gt;
&lt;li&gt;竞品的目标用户&lt;/li&gt;
&lt;li&gt;息架构&lt;/li&gt;
&lt;li&gt;主要功能&lt;/li&gt;
&lt;li&gt;视觉与交互&lt;/li&gt;
&lt;li&gt;运营推广策略&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic3.zhimg.com/80/v2-3b4eff1603870d700208c9a39131a262_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;竞品分析步骤4-数据收集&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析步骤4-数据收集&#34;&gt;#&lt;/a&gt; &lt;strong&gt;竞品分析步骤 4 – 数据收集&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;分析竞品，少不了的一个环节就是数据收集&lt;br /&gt;
收集竞品数据，我们可以从以下途径来进行收集，收集下来之后放在一起便于比较分析，收集的数据可以用截图，excel 表格，文档等形式记录。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;官方渠道&lt;/strong&gt;：公司官网，财报，公司数据披露，招聘信息&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;行业研究&lt;/strong&gt;：行业分析报告，艾瑞咨询，易观智库，企鹅智酷，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据平台&lt;/strong&gt;：CNNIC，DCCI 互联网数据中心 ，百度指数，七麦数据，App Annie 等&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;媒体咨询&lt;/strong&gt;：行业媒体、论坛&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;相关人员&lt;/strong&gt;：调查核心用户，公司员工&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;亲身体验&lt;/strong&gt;：使用对方的产品，咨询客服，技术问答&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic1.zhimg.com/80/v2-b68c461468bfd5eb1c9558c17cf143ec_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic1.zhimg.com/80/v2-942b624adcd9cff31b477890779b44cc_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic2.zhimg.com/80/v2-02ac2df1ecfb0d3eb85b79c883cdf7f9_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-1ed80b0597e6312e7f70c197b3c0d163_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;选择竞品分析方法&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SWOT 分析法&lt;/strong&gt; – 针对索要分析的竞品，从 “优势、劣势、机会、威胁” 四个维度进行比较和梳理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;YES/NO 法&lt;/strong&gt; – 适用于功能层面，将功能点全盘列出，具有该功能点的产品标记为 yes，没有的标记 no，通过对比可以清晰的了解竞品间功能点的差异&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评分法&lt;/strong&gt; – 这个方法在用户研究中常会用到，通常适用于定量研究的问券调查中，即给出 1-5 分的区间，根据产品中的某一个方面或某点进行打分&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分析描述法&lt;/strong&gt; – 指将不同的产品特性以比较的形式描述出来&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#&#34;&gt;#&lt;/a&gt; &lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic3.zhimg.com/80/v2-2b6f4b5d6e473dda7b97b68c9395c4d2_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;竞品分析步骤5-分析总结产出竞品分析报告&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析步骤5-分析总结产出竞品分析报告&#34;&gt;#&lt;/a&gt; &lt;strong&gt;竞品分析步骤 5 – 分析总结，产出竞品分析报告&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;针对分析目的，运用上述收集的数据，选择合适的分析方法，分析总结，形成竞品分析报告，分析报告通常为文档形式，或者 PPT 的形式。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic3.zhimg.com/80/v2-da0d9e0cc874073515d0d601a5b7c7de_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;竞品分析案例-现金贷竞品分析-前面说了那么多方法论现在附一个案例现金贷竞品分析以便更容易理解消化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析案例-现金贷竞品分析-前面说了那么多方法论现在附一个案例现金贷竞品分析以便更容易理解消化&#34;&gt;#&lt;/a&gt; &lt;strong&gt;竞品分析案例 – 现金贷竞品分析&lt;/strong&gt; 前面说了那么多方法论，现在附一个案例《现金贷竞品分析》以便更容易理解消化。&lt;/h2&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic1.zhimg.com/80/v2-6db3b22eb4f4bee6497910a5d8af6ef4_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic2.zhimg.com/80/v2-3ef8c3629ee2e441e0b1d5570d4b6939_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-0e69bc391832c86b2fbbc0758c5db3ab_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic3.zhimg.com/80/v2-849daf2b07bb891bd370ff7253f7a0ae_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-5a232ac67bed8e4a905881ddef89961b_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-770b2b49d16b591742c5aa3ab9fd9847_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.4 数据收集&lt;/strong&gt;&lt;br /&gt;
数据的收集我采用了官网查询，公司年报，使用产品，产品帮助手册，询问产品客服，行业媒体披露，网络检索，以及其他竞品分析文章中的数据等等。&lt;br /&gt;
最后将收集的数据整理分析比较后以 ppt 的形势产出了竞品分析报告。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic1.zhimg.com/80/v2-67ecbc50c1d138ef5ba85de5592da578_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;现金贷竞品分析.ppt&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-17a8eab5ec0f47005c85d73083ad185f_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;竞品分析.ppt&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic3.zhimg.com/80/v2-5656ebdbf0ffcac672d76069197a2c02_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;现金贷行业分析.ppt&lt;/p&gt;
&lt;h3 id=&#34;3信息的收集与分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3信息的收集与分析&#34;&gt;#&lt;/a&gt; 3. 信息的收集与分析&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240229142938725.png&#34; alt=&#34;image-20240229142938725&#34; /&gt;&lt;/p&gt;
&lt;p&gt;excel 列出&lt;/p&gt;
&lt;p&gt;竞品名称， 版本号，最后更新时间，下载量 / 使用量， 融资情况， 发布时间， 产品定位，核心功能，日活月活&lt;/p&gt;
&lt;p&gt;竞品名称、版本号、最后更新时间、下载量、融资情况、发布时间、产品定位、核心功能、日活月活、优缺点&lt;br /&gt;
一些网址：七麦数据、APPGrowing、艾瑞数据、易观千帆、百度指数&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240229143017112.png&#34; alt=&#34;image-20240229143017112&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;5数据分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5数据分析&#34;&gt;#&lt;/a&gt; 5. 数据分析&lt;/h3&gt;
&lt;h4 id=&#34;a市场竞争环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#a市场竞争环境&#34;&gt;#&lt;/a&gt; a. 市场竞争环境&lt;/h4&gt;
&lt;p&gt;市场现状 / 市场规模 / 用户规模 / 发展趋势&lt;/p&gt;
&lt;p&gt;行业调研报告 / 分析方法 如 PEST&lt;/p&gt;
&lt;h4 id=&#34;b基础数据分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#b基础数据分析&#34;&gt;#&lt;/a&gt; b. 基础数据分析&lt;/h4&gt;
&lt;p&gt;同类产品 / 排名情况 / 共性 / 规律&lt;/p&gt;
&lt;h4 id=&#34;c分类分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#c分类分析&#34;&gt;#&lt;/a&gt; c. 分类分析&lt;/h4&gt;
&lt;p&gt;产品模式 / 盈利方式 / 目标人群&lt;/p&gt;
&lt;h4 id=&#34;d核心竞品选择&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#d核心竞品选择&#34;&gt;#&lt;/a&gt; d. 核心竞品选择&lt;/h4&gt;
&lt;p&gt;根据 c 的每一类选一个：下载量多 / 大的&lt;/p&gt;
&lt;h4 id=&#34;e核心竞品分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#e核心竞品分析&#34;&gt;#&lt;/a&gt; e. 核心竞品分析&lt;/h4&gt;
&lt;p&gt;产品定位 / 目标人群 /slogan/ 发展历程 / 用户属性： 性别 / 地域 / 年龄 分布  / 盈利模式 / 产品模式 / 核心功能&lt;/p&gt;
&lt;p&gt;产品运营数据&lt;/p&gt;
&lt;h3 id=&#34;6总结思考&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6总结思考&#34;&gt;#&lt;/a&gt; 6. 总结思考&lt;/h3&gt;
&lt;p&gt;看别人的分析报告&lt;/p&gt;
&lt;p&gt;多看行业报告；多跟商务沟通；多看新项目的招标文书、中标那家的材料；多研究友商公开的文书、官网、产品和解决方案的规划、友商公司的组织架构、业务发展等等；也需要多跟客户沟通实际需求。其实公司内网上肯定也有前人搜集的一些公开资料，可以充分利用起来。&lt;/p&gt;
&lt;p&gt;去装客户给他们销售打个电话，他们就会好好的给你介绍他们的产品了&lt;/p&gt;
&lt;h2 id=&#34;注意&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#注意&#34;&gt;#&lt;/a&gt; 注意&lt;/h2&gt;
&lt;h3 id=&#34;1不要把竞品分析做成用户体验&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1不要把竞品分析做成用户体验&#34;&gt;#&lt;/a&gt; 1. 不要把竞品分析做成用户体验&lt;/h3&gt;
&lt;p&gt;尽调的本质是帮产品经理做出决策，而不是罗列信息&lt;/p&gt;
&lt;h3 id=&#34;2硬搬竞品的功能或策略&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2硬搬竞品的功能或策略&#34;&gt;#&lt;/a&gt; 2. 硬搬竞品的功能或策略&lt;/h3&gt;
&lt;p&gt;不是抄袭，而是用更短的路径少走弯路获取更优的解决思路&lt;/p&gt;
&lt;h3 id=&#34;3结论不要太空泛&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3结论不要太空泛&#34;&gt;#&lt;/a&gt; 3. 结论不要太空泛&lt;/h3&gt;
&lt;p&gt;结论产出基于目标 用户 场景&lt;/p&gt;
&lt;h4 id=&#34;补充&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#补充&#34;&gt;#&lt;/a&gt; 补充：&lt;/h4&gt;
&lt;h4 id=&#34;竞品分析报告&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析报告&#34;&gt;#&lt;/a&gt; 竞品分析报告：&lt;/h4&gt;
&lt;p&gt;①市场竞争环境（当前市场现状？市场规模？用户规模？未来发展趋势？PEST 分析方法）、②基础数据分析（同类产品有多少、排名情况、共性规律）、③竞品分类分析（产品模式、盈利方式、目标人群等）、④核心竞品选择（选择的原因、根据上一步每一类选一个）、⑤核心竞品分析（产品定位、目标人群、解决什么需求、Slogan、发展历程、用户属性（性别分布、地域分布、年龄分布）、盈利模式、产品模式、核心功能分析（结构、流程））&lt;/p&gt;
&lt;p&gt;关注竞品，是产品经理贯穿整个职业生涯的事情。&lt;/p&gt;
&lt;p&gt;参考文档：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NzU2NTcxMw==&#34;&gt;如何做好竞品分析？ – 每个产品经理的必经之路 - 知乎 (zhihu.com)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUFONDExQTdNRi8/c3BtX2lkX2Zyb209MzMzLjMzNy5zZWFyY2gtY2FyZC5hbGwuY2xpY2smYW1wO3ZkX3NvdXJjZT1mYzJhNjk4OWI3ODMxYmFhYmMwNmVkYmZlNWI4NmM4MQ==&#34;&gt;https://www.bilibili.com/video/BV1AN411A7MF/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=fc2a6989b7831baabc06edbfe5b86c81&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;黑马课程（未完待续）&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/24/%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/</guid>
            <title>需求分析</title>
            <link>https://jinjiaojiao.top/2024/02/24/%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/</link>
            <category term="产品经理" scheme="https://jinjiaojiao.top/categories/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <category term="产品经理" scheme="https://jinjiaojiao.top/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <pubDate>Sat, 24 Feb 2024 13:48:14 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65e031f89f345e8d038b326b.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;目录：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一、需求分析的基本认知&lt;br /&gt;
二、需求分析的步骤&lt;br /&gt;
三、需求分析的方法&lt;br /&gt;
四、需求分析的产出&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;一-需求分析的基本认知&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#一-需求分析的基本认知&#34;&gt;#&lt;/a&gt; 一、需求分析的基本认知&lt;/h2&gt;
&lt;h3 id=&#34;1-什么是需求分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-什么是需求分析&#34;&gt;#&lt;/a&gt; 1、什么是需求分析&lt;/h3&gt;
&lt;p&gt;需求分析是指，产品经理从用户 / 业务的需求出发，确定用户 / 业务的目的和目标，&lt;strong&gt;将用户 / 业务需求转化为产品需求&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;简单理解就是判断一个需求值不值得做，要做成什么样子，要怎么来做才能实现产品目标以及价值最大化。&lt;/p&gt;
&lt;h3 id=&#34;2-核心要素&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-核心要素&#34;&gt;#&lt;/a&gt; 2、核心要素&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用户的真实目的&lt;/li&gt;
&lt;li&gt;产品的解决方案&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-需求分析的原则&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-需求分析的原则&#34;&gt;#&lt;/a&gt; 3、需求分析的原则&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;透过现象看本质&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;4-什么样的的需求分析是好的需求分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-什么样的的需求分析是好的需求分析&#34;&gt;#&lt;/a&gt; 4、什么样的的需求分析是好的需求分析&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;价值导向而非目标导向&lt;/li&gt;
&lt;li&gt;搞清楚 “去角色化的个体特征” 以及 “集体人格特征”&lt;/li&gt;
&lt;li&gt;明确痛点、痒点以及爽点均是产品机会&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;二-需求分析的步骤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二-需求分析的步骤&#34;&gt;#&lt;/a&gt; 二、需求分析的步骤&lt;/h2&gt;
&lt;h3 id=&#34;信息收集阶段&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#信息收集阶段&#34;&gt;#&lt;/a&gt; 信息收集阶段&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、需求转化&lt;/strong&gt;&lt;br /&gt;
将收集来的需求整理到需求分析记录表里面，确定需求的基本属性&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic3.zhimg.com/80/v2-2e226ac8653bd190563d767aebb92df2_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、确定基本属性&lt;/strong&gt;&lt;br /&gt;
明确需求是属于哪个类型，如新增功能、功能改进、体验提升、Bug 修复、内部需求……&lt;br /&gt;
 再确认需求的层级，使用 KANO 模型进行分析，确认是必要型需求、还是期望型需求、还是兴奋型需求、无差别需求还是逆向需求。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/24/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9/</guid>
            <title>产品经理工作内容</title>
            <link>https://jinjiaojiao.top/2024/02/24/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9/</link>
            <category term="产品经理" scheme="https://jinjiaojiao.top/categories/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <category term="产品经理" scheme="https://jinjiaojiao.top/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" />
            <pubDate>Sat, 24 Feb 2024 13:47:59 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;产品经理的工作流程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#产品经理的工作流程&#34;&gt;#&lt;/a&gt; 产品经理的工作流程&lt;/h1&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65d9848c9f345e8d030ec17d.jpg&#34; alt=&#34;image-20240224130410821&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65dc98069f345e8d03f67080.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;产品定义&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#产品定义&#34;&gt;#&lt;/a&gt; &lt;strong&gt;产品定义：&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;产品在设计前，需要做两份准备工作：详细的&lt;strong&gt;调研&lt;/strong&gt;和输出&lt;strong&gt;需求文档（prd）&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;调研&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#调研&#34;&gt;#&lt;/a&gt; 调研：&lt;/h2&gt;
&lt;p&gt;1. 目标用户调研&lt;/p&gt;
&lt;p&gt;2. 市场调研&lt;/p&gt;
&lt;p&gt;3. 竞品分析&lt;/p&gt;
&lt;h3 id=&#34;目标用户调研&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#目标用户调研&#34;&gt;#&lt;/a&gt; 目标用户调研&lt;/h3&gt;
&lt;p&gt;需求都是从用户中来，到用户中去的，很多时候用户也不知道自己想要什么，那 PM 还要听用户的吗？答案当然是要听，但有技巧地听，并进行分析。&lt;/p&gt;
&lt;h4 id=&#34;用户调研的两种情景&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#用户调研的两种情景&#34;&gt;#&lt;/a&gt; &lt;strong&gt;用户调研的两种情景：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;【产品还未设计】，处于从 0 到 1 的过程，在设计前收集资料来针对性的设计产品&lt;strong&gt;功能&lt;/strong&gt;和&lt;strong&gt;布局&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;【产品已经上线】，处于待优化的状态，&lt;strong&gt;收集用户反馈&lt;/strong&gt;来优化产品功能。&lt;/p&gt;
&lt;h4 id=&#34;用户调研的目的&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#用户调研的目的&#34;&gt;#&lt;/a&gt; &lt;strong&gt;用户调研的目的&lt;/strong&gt;：&lt;/h4&gt;
&lt;p&gt;了解用户对产品的&lt;strong&gt;使用过程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;了解目标用户群的&lt;strong&gt;使用场景和过程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;总结用户的&lt;strong&gt;问题和流程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;提出最合理的&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;市场调研&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#市场调研&#34;&gt;#&lt;/a&gt; 市场调研&lt;/h3&gt;
&lt;p&gt;市场调查方法可分为两大类：第一类按选择&lt;strong&gt;调查对象&lt;/strong&gt;来划分，有&lt;strong&gt;全面普查&lt;/strong&gt;、&lt;a href=&#34;https://links.jianshu.com/go?to=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E9%87%8D%E7%82%B9%E8%B0%83%E6%9F%A5%26tn%3DSE_PcZhidaonwhc_ngpagmjz%26rsv_dl%3Dgh_pc_zhidao&#34;&gt;&lt;strong&gt;重点调查&lt;/strong&gt;&lt;/a&gt;、&lt;strong&gt;随机抽样&lt;/strong&gt;、&lt;a href=&#34;https://links.jianshu.com/go?to=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E9%9D%9E%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7%26tn%3DSE_PcZhidaonwhc_ngpagmjz%26rsv_dl%3Dgh_pc_zhidao&#34;&gt;&lt;strong&gt;非随机抽样&lt;/strong&gt;&lt;/a&gt;等；第二类是按调查对象所采用的具体方法来划分，有&lt;strong&gt;访问法&lt;/strong&gt;、&lt;strong&gt;观察法&lt;/strong&gt;、&lt;strong&gt;实验法&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;市场调研的方法：&lt;/p&gt;
&lt;h4 id=&#34;需求文档prd&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#需求文档prd&#34;&gt;#&lt;/a&gt; 需求文档（Prd）：&lt;/h4&gt;
&lt;p&gt;一份完整的需求文档的结构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65dc98f79f345e8d03f9a76d.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://upload-images.jianshu.io/upload_images/15808187-a14fe1bf5e0f0c8e?imageMogr2/auto-orient/strip%7CimageView2/2/w/710/format/webp&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;竞品分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞品分析&#34;&gt;#&lt;/a&gt; &lt;strong&gt;竞品分析&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65dc997c9f345e8d03fbe4f7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://upload-images.jianshu.io/upload_images/15808187-9a81fd3f62af28fe?imageMogr2/auto-orient/strip%7CimageView2/2/w/363/format/web&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;产品设计&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#产品设计&#34;&gt;#&lt;/a&gt; &lt;strong&gt;产品设计：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;产品设计分为&lt;strong&gt;原型设计&lt;/strong&gt;和&lt;strong&gt;视觉设计&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;原型设计&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#原型设计&#34;&gt;#&lt;/a&gt; &lt;strong&gt;原型设计&lt;/strong&gt;：&lt;/h4&gt;
&lt;p&gt;首先要缕清业务流程，根据用户调研和市场调研分析得来的结论，来设计界面布局和整体架构。&lt;/p&gt;
&lt;p&gt;所需工具及产出：&lt;/p&gt;
&lt;p&gt;原型 —— &lt;code&gt;Axure RP&lt;/code&gt; 、 &lt;code&gt;墨刀&lt;/code&gt; 、 &lt;code&gt;figma&lt;/code&gt; 、 &lt;code&gt;Mockup&lt;/code&gt;  等（苹果电脑推荐 sketch、Mockplus）&lt;/p&gt;
&lt;p&gt;流程图 —— &lt;code&gt;visio&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;脑图 —— &lt;code&gt;mindmanager&lt;/code&gt; 、 &lt;code&gt;Xmind&lt;/code&gt;  等&lt;/p&gt;
&lt;p&gt;用例图 —— &lt;code&gt;processOn&lt;/code&gt; 、 &lt;code&gt;visio&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;视觉设计ui-交互&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#视觉设计ui-交互&#34;&gt;#&lt;/a&gt; &lt;strong&gt;视觉设计（ &lt;code&gt;UI&lt;/code&gt; 、交互）：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;视觉设计是把原型细化、美化。包括&lt;strong&gt; UI&lt;/strong&gt; 和交互。色彩搭配、图片、Logo、图标等等。交互设计所用软件与原型设计所用软件大多相似，一般原型设计软件都带有交互功能。只是交互设计更注重于产品的美感和交互形式。&lt;/p&gt;
&lt;h4 id=&#34;产品研发&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#产品研发&#34;&gt;#&lt;/a&gt; &lt;strong&gt;产品研发：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在产品研发阶段，产品经理需要跟进研发进度，沟通研发人员、测试人员、UI 设计人员等。管理需求，及时修改方案。&lt;/p&gt;
&lt;h4 id=&#34;测试&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#测试&#34;&gt;#&lt;/a&gt; &lt;strong&gt;测试&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;测试是从开始研发到产品上线前一直贯穿的。而产品经理需要进行可行性测试、用户体验测试、用例测试。&lt;/p&gt;
&lt;h4 id=&#34;发布&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#发布&#34;&gt;#&lt;/a&gt; &lt;strong&gt;发布&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在产品完成后，需要进行发布准备：销售培训（培训产品的功能、使用流程、卖点）、产品定价、运营策略、推广方案、用户教育（撰写产品使用手册）。&lt;/p&gt;
&lt;h4 id=&#34;改进&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#改进&#34;&gt;#&lt;/a&gt; &lt;strong&gt;改进&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在产品上线后，产品经理还有个漫长的工作：产品改进 / 产品迭代。需要收集用户反馈、产品使用的相关数据、竞品分析…… 进行数据分析，从而进行功能改进，产品迭代。&lt;/p&gt;
&lt;h3 id=&#34;通过用户反馈发现问题&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#通过用户反馈发现问题&#34;&gt;#&lt;/a&gt; &lt;strong&gt;通过用户反馈发现问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;当看到用户反馈的内容的时候，关注的点，基本是：&lt;strong&gt;自身产品的问题&lt;/strong&gt;、&lt;strong&gt;竞品的问题、可能的机会点&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那我们可以通过哪些&lt;strong&gt;渠道&lt;/strong&gt;来收集用户反馈？&lt;/p&gt;
&lt;p&gt;公开渠道：App Store 等应用市场、微博、贴吧&lt;/p&gt;
&lt;p&gt;半公开渠道：微信朋友圈&lt;/p&gt;
&lt;p&gt;内部渠道：用户投诉，电话录音、客服咨询&lt;/p&gt;
&lt;h4 id=&#34;针对用户反馈不同渠道的处理策略&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#针对用户反馈不同渠道的处理策略&#34;&gt;#&lt;/a&gt; &lt;strong&gt;针对用户反馈不同渠道的处理策略：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;公开渠道&lt;/strong&gt;：对于公开渠道，可以采取&lt;strong&gt;搜索 + 关键字订阅 + 使用监测工具&lt;/strong&gt;的策略；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半公开渠道&lt;/strong&gt;：微信朋友圈可以通过 “搜一搜” 功能，搜索关键字的方法；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;内部渠道&lt;/strong&gt;：这就需要整合内部用户反馈渠道，包括邮件、QQ、留言等；需要定期与一线的同事进行沟通，或者适当地当一天客服。&lt;/p&gt;
&lt;p&gt;具体的用户调研渠道有哪些，进入这些渠道中有大量的用户反馈，又该着重看什么？&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;应用商店评论&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主流的应用商店与常用的工具包括：&lt;/p&gt;
&lt;p&gt;IOS：App Store，安卓：360 手机助手、安卓市场、百度手机助手、小米应用商店、安智市场、豌豆荚等；常用的工具有 APPAnnie、应用雷达、ASO114、酷传等。&lt;/p&gt;
&lt;p&gt;对于应用商店，应该着重监控以下四点：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;低分差评&lt;/strong&gt;：重点看低分 1-3 分；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有效评论&lt;/strong&gt;：重点看有实际描述的评论&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异常行为&lt;/strong&gt;：比如水军刷榜、恶意评价&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;竞品变化&lt;/strong&gt;：监控竞争对手的应用变化&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65dc99d29f345e8d03fd475c.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主流的社交平台与常用工具&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;微博、贴吧、知乎、人人网、雪球的&lt;/strong&gt;等，工具是关&lt;strong&gt;键字 + 收藏夹&lt;/strong&gt;、&lt;strong&gt;微博企业版、百度、Google&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;查看贴吧内容有个小技巧，在关键词后添加 &lt;code&gt;site:tieba.baidu.com&lt;/code&gt; ，相当于筛选了站点的内容。&lt;/p&gt;
&lt;p&gt;通过用户咨询、投诉发现问题&lt;/p&gt;
&lt;p&gt;内容来源：客服后台、录音、意见建议、用户反馈、邮件等。&lt;/p&gt;
&lt;h4 id=&#34;通过用户调研发现问题&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#通过用户调研发现问题&#34;&gt;#&lt;/a&gt; &lt;strong&gt;通过用户调研发现问题&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;用户调研的流程：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65dc9a159f345e8d03fe668d.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;明确调研的背景和目的&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#明确调研的背景和目的&#34;&gt;#&lt;/a&gt; 明确调研的背景和目的：&lt;/h4&gt;
&lt;p&gt;背景：什么情况下发起的调研？是否必须通过用户调研来解决？&lt;/p&gt;
&lt;p&gt;目的：希望通过用户调研得到的结果是什么？&lt;/p&gt;
&lt;p&gt;调研的目的忌大而全，调研的方向越聚焦，越有价值；忌假大空，针对行业用户的调研，针对满意度的调研，价值都不大。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://upload-images.jianshu.io/upload_images/15808187-ca471eea21c477ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/812/format/webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;选择目标用户&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#选择目标用户&#34;&gt;#&lt;/a&gt; &lt;strong&gt;选择目标用户&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;基于背景和目的，先挑出大量符合行为的用户&lt;/p&gt;
&lt;p&gt;选定部分目标用户，针对性分析（用户画像）&lt;/p&gt;
&lt;p&gt;选择合适的用户（时间、地点、感兴趣程度等）&lt;/p&gt;
&lt;p&gt;邀约用户：直接说明目的，并告知可能发生的情况&lt;/p&gt;
&lt;p&gt;数量：一般不超过 5 个&lt;/p&gt;
&lt;h4 id=&#34;分析用户和问题&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#分析用户和问题&#34;&gt;#&lt;/a&gt; &lt;strong&gt;分析用户和问题&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;这里是事先猜测目标用户可能面临的&lt;strong&gt;问题&lt;/strong&gt;是什么。&lt;/p&gt;
&lt;p&gt;分析调研对象可能碰到的问题和解决方案&lt;/p&gt;
&lt;p&gt;猜测用户的需求并提出解决方案&lt;/p&gt;
&lt;p&gt;把解决方案变成可执行的 demo（纸面、原型等）&lt;/p&gt;
&lt;h4 id=&#34;准备任务和访谈提纲并演习&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#准备任务和访谈提纲并演习&#34;&gt;#&lt;/a&gt; &lt;strong&gt;准备任务和访谈提纲，并演习&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;按照用户调研预设时间的&lt;strong&gt; 2 倍&lt;/strong&gt;去准备问题，标注必须要回答和用户操作的关键问题，准备用户必须操作的任务，把问题串起来，并找同事预演一遍，最后总结和调整。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65dc9a419f345e8d03fef7da.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;调研现场&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#调研现场&#34;&gt;#&lt;/a&gt; &lt;strong&gt;调研现场&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;根据不同情况，布置调研现场。先缓和用户情绪，不要着急一下子进入到访谈 / 调研中，其次了解背景信息与自己的猜想是否匹配（用户画像），尽可能模拟用户真实的环境，尽可能记录用户的操作过程：&lt;strong&gt;录屏、录音、笔记&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;调研结束总结&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#调研结束总结&#34;&gt;#&lt;/a&gt; &lt;strong&gt;调研结束总结&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;整理单个用户的调研过程，是否要调整调研对象，汇总本轮调研用户的过程和结论。&lt;/p&gt;
&lt;p&gt;参照文档：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC8zYTI5YTJkNmNjMGI=&#34;&gt;产品经理（PM）的工作流程 - 简书 (jianshu.com)&lt;/span&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/14/%E5%AD%A6%E4%B9%A0d2l%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0day2%E2%80%94%E2%80%94%E5%9B%9E%E5%BD%92/</guid>
            <title>学习d2l深度学习day2——回归</title>
            <link>https://jinjiaojiao.top/2024/02/14/%E5%AD%A6%E4%B9%A0d2l%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0day2%E2%80%94%E2%80%94%E5%9B%9E%E5%BD%92/</link>
            <category term="深度学习" scheme="https://jinjiaojiao.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" />
            <category term="跟着李沐学深度学习" scheme="https://jinjiaojiao.top/tags/%E8%B7%9F%E7%9D%80%E6%9D%8E%E6%B2%90%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" />
            <pubDate>Wed, 14 Feb 2024 02:46:58 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;线性回归&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#线性回归&#34;&gt;#&lt;/a&gt; 线性回归&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;回归&lt;/strong&gt;&lt;/em&gt;（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法。 在自然科学和社会科学领域，回归经常用来表示输入和输出之间的关系。&lt;/p&gt;
&lt;p&gt;在机器学习领域中的大多数任务通常都与&lt;em&gt;&lt;strong&gt;预测&lt;/strong&gt;&lt;/em&gt;（prediction）有关。&lt;/p&gt;
&lt;p&gt;当我们想预测一个数值时，就会涉及到回归问题。 常见的例子包括：预测价格（房屋、股票等）、预测住院时间（针对住院病人等）、 预测需求（零售销量等）。&lt;/p&gt;
&lt;p&gt;但不是所有的&lt;em&gt;预测&lt;/em&gt;都是回归问题。&lt;/p&gt;
&lt;p&gt;分类问题的目标是预测数据属于一组类别中的哪一个。&lt;/p&gt;
&lt;h2 id=&#34;线性回归的基本元素&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#线性回归的基本元素&#34;&gt;#&lt;/a&gt; 线性回归的基本元素&lt;/h2&gt;
&lt;p&gt;线性回归基于几个简单的假设： 首先，假设自变量 x 和因变量 y 之间的关系是线性的， 即 y 可以表示为 x 中元素的加权和，这里通常允许包含观测值的一些噪声； 其次，我们假设任何噪声都比较正常，如噪声遵循正态分布。&lt;/p&gt;
&lt;p&gt;为了解释&lt;em&gt;线性回归&lt;/em&gt;，我们举一个实际的例子： 我们希望根据房屋的面积（平方英尺）和房龄（年）来估算房屋价格（美元）。 为了开发一个能预测房价的模型，我们需要收集一个真实的数据集。 这个数据集包括了房屋的销售价格、面积和房龄。 在机器学习的术语中，该数据集称为&lt;em&gt;&lt;strong&gt;训练数据集&lt;/strong&gt;&lt;/em&gt;（training data set） 或&lt;em&gt;&lt;strong&gt;训练集&lt;/strong&gt;&lt;/em&gt;（training set）。 每行数据（比如一次房屋交易相对应的数据）称为&lt;em&gt;样本&lt;/em&gt;（sample）， 也可以称为&lt;em&gt;&lt;strong&gt;数据点&lt;/strong&gt;&lt;/em&gt;（data point）或&lt;em&gt;&lt;strong&gt;数据样本&lt;/strong&gt;&lt;/em&gt;（data instance）。 我们把试图预测的目标（比如预测房屋价格）称为&lt;em&gt;&lt;strong&gt;标签&lt;/strong&gt;&lt;/em&gt;（label）或&lt;em&gt;&lt;strong&gt;目标&lt;/strong&gt;&lt;/em&gt;（target）。 预测所依据的自变量（面积和房龄）称为&lt;em&gt;&lt;strong&gt;特征&lt;/strong&gt;&lt;/em&gt;（feature）或&lt;em&gt;&lt;strong&gt;协变量&lt;/strong&gt;&lt;/em&gt;（covariate）。&lt;/p&gt;
&lt;p&gt;通常，我们使用 n 来表示数据集中的样本数。 对索引为 i 的样本，其输入表示为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi mathvariant=&#34;bold&#34;&gt;X&lt;/mi&gt;&lt;mrow&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;[&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;mo fence=&#34;true&#34;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\mathbf{X}^{(i)} = \left[ x_1^{(i)}, x_2^{(i)} \right]^T
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.938em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathbf&#34;&gt;X&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.938em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.031251em;vertical-align:-0.65002em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size2&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.0448em;&#34;&gt;&lt;span style=&#34;top:-2.433692em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2198em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.266308em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.0448em;&#34;&gt;&lt;span style=&#34;top:-2.433692em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2198em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.266308em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size2&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.3812309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.6029em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;， 其对应的标签是 y（i）。&lt;/p&gt;
&lt;h1 id=&#34;softmax回归&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#softmax回归&#34;&gt;#&lt;/a&gt; Softmax 回归&lt;/h1&gt;
&lt;p&gt;Softmax 实质上是分类&lt;/p&gt;
&lt;h2 id=&#34;回归与分类&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#回归与分类&#34;&gt;#&lt;/a&gt; 回归与分类&lt;/h2&gt;
&lt;h3 id=&#34;回归&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#回归&#34;&gt;#&lt;/a&gt; 回归&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;单&lt;/strong&gt;连续数值输出&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;自然区间 R&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;跟真实值的区别作为损失&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;分类&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#分类&#34;&gt;#&lt;/a&gt; 分类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;通常&lt;strong&gt;多个输出&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;输出 i 是预测为第 i 类的置信度&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;从回归到多类分类均方损失&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#从回归到多类分类均方损失&#34;&gt;#&lt;/a&gt; 从回归到多类分类 —— 均方损失&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218211324212.png&#34; alt=&#34;image-20240218211324212&#34; /&gt;&lt;/p&gt;
&lt;p&gt;最大化 Oi 置信度&lt;/p&gt;
&lt;p&gt;需要更置信的识别正确类（大余量）&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218211654235.png&#34; alt=&#34;image-20240218211654235&#34; /&gt;&lt;/p&gt;
&lt;p&gt;远远大于其他&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218211732178.png&#34; alt=&#34;image-20240218211732178&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218211813295.png&#34; alt=&#34;image-20240218211813295&#34; /&gt;&lt;/p&gt;
&lt;p&gt;导数是我们 softmax 模型分配的概率如（0.1，0.2，0.7）与实际发生的情况（0，0，1）（由独热标签向量表示）之间的差异&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;交叉熵损失函数：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi mathvariant=&#34;bold&#34;&gt;y&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi mathvariant=&#34;bold&#34;&gt;y&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;msub&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j.
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathbf&#34; style=&#34;margin-right:0.01597em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord accent&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.70788em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathbf&#34; style=&#34;margin-right:0.01597em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.01344em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;accent-body&#34; style=&#34;left:-0.19444em;&#34;&gt;&lt;span class=&#34;mord&#34;&gt;^&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.19444em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:3.1122820000000004em;vertical-align:-1.4137769999999998em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.6985050000000006em;&#34;&gt;&lt;span style=&#34;top:-1.872331em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;mrel mtight&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.050005em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-4.347113em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.4137769999999998em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.311664em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.286108em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop&#34;&gt;lo&lt;span style=&#34;margin-right:0.01389em;&#34;&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord accent&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.69444em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;accent-body&#34; style=&#34;left:-0.19444em;&#34;&gt;&lt;span class=&#34;mord&#34;&gt;^&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.19444em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.311664em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.286108em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;y 是一个长度为 q 的独热编码向量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Softmax 回归是一个多类分类模型&lt;/li&gt;
&lt;li&gt;・使用 Softmax 操作子得到每个类的预测置信度&lt;/li&gt;
&lt;li&gt;・使用交叉熵来来衡量预测和标号的区别&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;损失函数&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#损失函数&#34;&gt;#&lt;/a&gt; 损失函数&lt;/h2&gt;
&lt;h4 id=&#34;l2-loss&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#l2-loss&#34;&gt;#&lt;/a&gt; L2 Loss&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218215459096.png&#34; alt=&#34;image-20240218215459096&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;l1-loss&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#l1-loss&#34;&gt;#&lt;/a&gt; L1 Loss&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218215513903.png&#34; alt=&#34;image-20240218215513903&#34; /&gt;&lt;/p&gt;
&lt;p&gt;特性：预测值与真实值无论多远，梯度都是常数，较稳定，0 点处不可导，但是 0 点处不平滑&lt;/p&gt;
&lt;p&gt;蓝色：y&#39;&lt;/p&gt;
&lt;p&gt;绿色：似然函数（高斯分布）&lt;/p&gt;
&lt;p&gt;黄色：梯度（穿过原点）&lt;/p&gt;
&lt;h4 id=&#34;huber-s-robust-loss&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#huber-s-robust-loss&#34;&gt;#&lt;/a&gt; Huber&#39; s Robust Loss&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218215531852.png&#34; alt=&#34;image-20240218215531852&#34; /&gt;&lt;/p&gt;
&lt;p&gt;结合两个&lt;/p&gt;
&lt;h2 id=&#34;信息论基础&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#信息论基础&#34;&gt;#&lt;/a&gt; 信息论基础&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;信息论&lt;/em&gt;（information theory）涉及编码、解码、发送以及尽可能简洁地处理信息或数据。&lt;/p&gt;
&lt;h3 id=&#34;熵&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#熵&#34;&gt;#&lt;/a&gt; 熵&lt;/h3&gt;
&lt;p&gt;信息论的核心思想是量化数据中的信息内容。 在信息论中，该数值被称为分布 P 的&lt;em&gt;熵&lt;/em&gt;（entropy）。可以通过以下方程得到：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;[&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;]&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/munder&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;H[P] = \sum_j - P(j) \log P(j).
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.463782em;vertical-align:-1.413777em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.050005em;&#34;&gt;&lt;span style=&#34;top:-1.8723309999999997em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0500049999999996em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.413777em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop&#34;&gt;lo&lt;span style=&#34;margin-right:0.01389em;&#34;&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;vscode终端进入运行jupyter&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#vscode终端进入运行jupyter&#34;&gt;#&lt;/a&gt; vscode 终端进入运行 jupyter&lt;/h3&gt;
&lt;p&gt;1. 下载&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install jupyter&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;2. 进入&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;jupyter notebook&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;图像分类数据集&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#图像分类数据集&#34;&gt;#&lt;/a&gt; 图像分类数据集&lt;/h2&gt;
&lt;p&gt;MNIST 数据集 (&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_references/zreferences.html#id90&#34;&gt;LeCun &lt;em&gt;et al.&lt;/em&gt;, 1998&lt;/a&gt;) 是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的 Fashion-MNIST 数据集 (&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_references/zreferences.html#id189&#34;&gt;Xiao &lt;em&gt;et al.&lt;/em&gt;, 2017&lt;/a&gt;)。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;%matplotlib inline&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms &lt;span class=&#34;comment&#34;&gt;#数据操作&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.use_svg_display()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;svg 清晰度高一些&lt;/p&gt;
&lt;h3 id=&#34;读取数据集&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#读取数据集&#34;&gt;#&lt;/a&gt; 读取数据集&lt;/h3&gt;
&lt;p&gt;我们可以通过框架中的内置函数将 Fashion-MNIST 数据集下载并读取到内存中。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 并除以255使得所有像素的数值均在0～1之间&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans = transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_train = torchvision.datasets.FashionMNIST(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#训练数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_test = torchvision.datasets.FashionMNIST(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;train=True 训练数据集&lt;/p&gt;
&lt;p&gt;transform=trans 拿到的是 tensor 而不是一堆图片&lt;/p&gt;
&lt;p&gt;download=True 默认在网上下载，如果已经存在 data 中就不用指定 download 了&lt;/p&gt;
&lt;p&gt;Fashion-MNIST 由 10 个类别的图像组成， 每个类别由&lt;em&gt;训练数据集&lt;/em&gt;（train dataset）中的 6000 张图像 和&lt;em&gt;测试数据集&lt;/em&gt;（test dataset）中的 1000 张图像组成。 因此，训练集和测试集分别包含 60000 和 10000 张图像。 测试数据集不会用于训练，只用于评估模型性能。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(mnist_train), &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(mnist_test)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(60000, 10000)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;每个输入图像的高度和宽度均为 28 像素。 数据集由灰度图像组成，其通道数为 1。 为了简洁起见，本书将高度ℎ像素、宽度 w 像素图像的形状记为ℎ×w 或（ℎ,w）。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;mnist_train[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].shape&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.Size([1, 28, 28])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Fashion-MNIST 中包含的 10 个类别，分别为 t-shirt（T 恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和 ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_fashion_mnist_labels&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;labels&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;#@save&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;返回Fashion-MNIST数据集的文本标签&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    text_labels = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;t-shirt&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;trouser&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;pullover&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;dress&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;coat&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   &lt;span class=&#34;string&#34;&gt;&amp;#x27;sandal&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;shirt&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;sneaker&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bag&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;ankle boot&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; [text_labels[&lt;span class=&#34;built_in&#34;&gt;int&lt;/span&gt;(i)] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; labels]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;我们现在可以创建一个函数来可视化这些样本。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_images&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;imgs, num_rows, num_cols, titles=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, scale=&lt;span class=&#34;number&#34;&gt;1.5&lt;/span&gt;&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;#@save&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;绘制图像列表&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    figsize = (num_cols * scale, num_rows * scale)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    axes = axes.flatten()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, (ax, img) &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(axes, imgs)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.is_tensor(img):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 图片张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            ax.imshow(img.numpy())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# PIL图片&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            ax.imshow(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ax.axes.get_xaxis().set_visible(&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ax.axes.get_yaxis().set_visible(&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; titles:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            ax.set_title(titles[i])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; axes&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;以下是训练数据集中前几个样本的图像及其相应的标签。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X, y = &lt;span class=&#34;built_in&#34;&gt;next&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;iter&lt;/span&gt;(data.DataLoader(mnist_train, batch_size=&lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_images(X.reshape(&lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;28&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;28&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;, titles=get_fashion_mnist_labels(y));&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240218232124716.png&#34; alt=&#34;image-20240218232124716&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;读取小批量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#读取小批量&#34;&gt;#&lt;/a&gt; 读取小批量&lt;/h2&gt;
&lt;p&gt;为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会读取一小批量数据，大小为 &lt;code&gt;batch_size&lt;/code&gt; 。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_dataloader_workers&lt;/span&gt;():  &lt;span class=&#34;comment&#34;&gt;#@save&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;使用4个进程来读取数据&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = data.DataLoader(mnist_train, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                             num_workers=get_dataloader_workers())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;训练集要随机，测试集都可以&lt;/p&gt;
&lt;p&gt;我们看一下&lt;strong&gt;读取&lt;/strong&gt;训练数据所需的时间。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;timer = d2l.Timer()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; train_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;continue&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;timer.stop():&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;f&amp;#125;&lt;/span&gt; sec&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&amp;#x27;3.37 sec&amp;#x27;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;保证读取速度比训练速度快，尽量快很多&lt;/p&gt;
&lt;h3 id=&#34;整合所有组件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#整合所有组件&#34;&gt;#&lt;/a&gt; 整合所有组件&lt;/h3&gt;
&lt;p&gt;现在我们定义 &lt;code&gt;load_data_fashion_mnist&lt;/code&gt;  函数，用于获取和读取 Fashion-MNIST 数据集。 这个函数返回&lt;strong&gt;训练集和验证集的数据迭代器&lt;/strong&gt;。 此外，这个函数还接受一个可选参数 &lt;code&gt;resize&lt;/code&gt; ，用来将图像大小调整为另一种形状。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_data_fashion_mnist&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, resize=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):   &lt;span class=&#34;comment&#34;&gt;#@save&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;下载Fashion-MNIST数据集，然后将其加载到内存中&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mnist_train, mnist_test = tf.keras.datasets.fashion_mnist.load_data()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 将所有数字除以255，使所有像素值介于0和1之间，在最后添加一个批处理维度，&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 并将标签转换为int32。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    process = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; X, y: (tf.expand_dims(X, axis=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;) / &lt;span class=&#34;number&#34;&gt;255&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                            tf.cast(y, dtype=&lt;span class=&#34;string&#34;&gt;&amp;#x27;int32&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    resize_fn = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; X, y: (&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        tf.image.resize_with_pad(X, resize, resize) &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; resize &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; X, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        tf.data.Dataset.from_tensor_slices(process(*mnist_train)).batch(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            batch_size).shuffle(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(mnist_train[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])).&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(resize_fn),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        tf.data.Dataset.from_tensor_slices(process(*mnist_test)).batch(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            batch_size).&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(resize_fn))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/14/%E5%AD%A6%E4%B9%A0d2l%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0day1%E2%80%94%E2%80%94%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</guid>
            <title>学习d2l深度学习day1——介绍与数据处理</title>
            <link>https://jinjiaojiao.top/2024/02/14/%E5%AD%A6%E4%B9%A0d2l%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0day1%E2%80%94%E2%80%94%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</link>
            <category term="深度学习" scheme="https://jinjiaojiao.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" />
            <category term="跟着李沐学深度学习" scheme="https://jinjiaojiao.top/tags/%E8%B7%9F%E7%9D%80%E6%9D%8E%E6%B2%90%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" />
            <pubDate>Wed, 14 Feb 2024 01:39:00 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;&lt;strong&gt;&lt;em&gt;深入理解深度学习的方法&lt;/em&gt;：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;亲自实现，从 0 开始编写可实现运行的程序，一边看源码，一边思考&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;课程信息：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9jb3Vyc2VzLmQybC5haS96aC12Mi8=&#34;&gt;课程安排 - 动手学深度学习课程 (d2l.ai)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;认识一下 &lt;code&gt;Colab&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81Mjc2NjMxNjM=&#34;&gt;Colab 使用教程（超级详细版）及 Colab Pro/Pro + 评测 - 知乎 (zhihu.com)&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;深度学习应用&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#深度学习应用&#34;&gt;#&lt;/a&gt; 深度学习应用&lt;/h1&gt;
&lt;h3 id=&#34;图像分类&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#图像分类&#34;&gt;#&lt;/a&gt; 图像分类&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3d3dy5pbWFnZS1uZXQub3JnLw==&#34;&gt;http://www.image-net.org/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9xei5jb20vMTAzNDk3Mi90aGUtZGF0YS10aGF0LWNoYW5nZWQtdGhlLWRpcmVjdGlvbi1vZi1haS1yZXNlYXJjaC1hbmQtcG9zc2libHktdGhlLXdvcmxk&#34;&gt;ImageNet: the data that spawned the current AI boom (qz.com)&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;物体检测和分割&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#物体检测和分割&#34;&gt;#&lt;/a&gt; 物体检测和分割&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65cbabb49f345e8d036e0632.png&#34; alt=&#34;image-20240213204425211&#34; /&gt;&lt;/p&gt;
&lt;p&gt;分割指的是某个像素点属于哪个物体&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL21hdHRlcnBvcnQvTWFza19SQ05O&#34;&gt;matterport/Mask_RCNN: Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow (github.com)&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;样式迁移&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#样式迁移&#34;&gt;#&lt;/a&gt; 样式迁移&lt;/h3&gt;
&lt;p&gt;风格变换&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL3poYW5naGFuZzE5ODkvTVhOZXQtR2x1b24tU3R5bGUtVHJhbnNmZXIv&#34;&gt;zhanghang1989/MXNet-Gluon-Style-Transfer: Neural Style and MSG-Net (github.com)&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;人脸合成&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#人脸合成&#34;&gt;#&lt;/a&gt; 人脸合成&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Karras et al, ICLR 2018&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;文字生成图片&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#文字生成图片&#34;&gt;#&lt;/a&gt; 文字生成图片&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9vcGVuYWkuY29tL2Jsb2cvZGFsbC1lLw==&#34;&gt;https://openai.com/blog/dall-e/&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;完整的故事&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#完整的故事&#34;&gt;#&lt;/a&gt; 完整的故事&lt;/h3&gt;
&lt;p&gt;领域专家（实现产品应用）&lt;/p&gt;
&lt;p&gt;数据科学家（data-&amp;gt;model）&lt;/p&gt;
&lt;p&gt;AI 专家（提升模型精度和性能）&lt;/p&gt;
&lt;h2 id=&#34;安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装&#34;&gt;#&lt;/a&gt; 安装&lt;/h2&gt;
&lt;h3 id=&#34;步骤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#步骤&#34;&gt;#&lt;/a&gt; 步骤&lt;/h3&gt;
&lt;h4 id=&#34;登录&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#登录&#34;&gt;#&lt;/a&gt; 登录&lt;/h4&gt;
&lt;p&gt;仅参考，李沐老师亚马逊平台 ubuntu 系统&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;ssh ubuntu@100.20.65.33 &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;升级服务器系统&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#升级服务器系统&#34;&gt;#&lt;/a&gt; 升级服务器系统&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo apt update&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;装一些gcc这类编译开发环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#装一些gcc这类编译开发环境&#34;&gt;#&lt;/a&gt; 装一些 GCC 这类编译开发环境&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo apt install build-essential&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;安装python&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装python&#34;&gt;#&lt;/a&gt; 安装 python&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo apt install python3.8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;安装miniconda&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装miniconda&#34;&gt;#&lt;/a&gt; 安装 miniconda&lt;/h4&gt;
&lt;p&gt;打开官网&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9kb2NzLmFuYWNvbmRhLmNvbS9mcmVlL21pbmljb25kYS8=&#34;&gt;Miniconda — Anaconda documentation&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;复制所需要的下载连接&lt;/p&gt;
&lt;p&gt;这里 Linux 安装到服务器&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;启动&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#启动&#34;&gt;#&lt;/a&gt; 启动&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;bash Miniconda3-latest-Linux-x86_64.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;一直回车到 yes&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;进入 conda 环境：刚开始最基础的 base 环境&lt;/p&gt;
&lt;h4 id=&#34;创建一个新环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建一个新环境&#34;&gt;#&lt;/a&gt; 创建一个新环境&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda create -n lm&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;激活&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#激活&#34;&gt;#&lt;/a&gt; 激活&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda activate lm&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;安装记事本&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装记事本&#34;&gt;#&lt;/a&gt; 安装记事本&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install jupyter d2l torch torchvision&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;（国内慢提前安装个源）&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65cbabe29f345e8d036e7eb7.png&#34; alt=&#34;image-20240213211231841&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;复制链接&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#复制链接&#34;&gt;#&lt;/a&gt; 复制链接&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;wget https://zh-v2.d2l.ai/d2l-zh.zip&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;安装zip&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装zip&#34;&gt;#&lt;/a&gt; 安装 zip&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda install zip&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;查看&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#查看&#34;&gt;#&lt;/a&gt; 查看&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;ls&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;解压文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#解压文件&#34;&gt;#&lt;/a&gt; 解压文件&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;unzip d2l-zh.zip&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;git clone https://github.com/d2l-ai/d2l-zh-pytorch-slides.git&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;jupyter notebook&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本地 prompt 操作！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;需要把远程机器的端口映射运行在本地&lt;/p&gt;
&lt;p&gt;m 神操作&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;ssh -L8888:localhost:8888 ubuntu@100.20.65.33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;ssh -L8888:localhost:8888 thjin@yuanshen.moe&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;再 vscode 点击 8888 进入&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240213213900135.png&#34; alt=&#34;image-20240213213900135&#34; /&gt;&lt;/p&gt;
&lt;p&gt;这个场景&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65cbabfa9f345e8d036eba41.png&#34; alt=&#34;image-20240213214121778&#34; /&gt;&lt;/p&gt;
&lt;p&gt;继续 prompt&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;别忘了启动对应的环境&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;下载插件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#下载插件&#34;&gt;#&lt;/a&gt; 下载插件&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install rise&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;下载之后 jupyter 就可以直接用了&lt;/p&gt;
&lt;h3 id=&#34;补充&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#补充&#34;&gt;#&lt;/a&gt; 补充&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;删除单个文件（所有系统）：&lt;/p&gt;
&lt;p&gt;Code&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1rm filename.ext&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;或（Windows）&lt;/p&gt;
&lt;p&gt;Code&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1del filename.ext&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除空文件夹（所有系统）：&lt;/p&gt;
&lt;p&gt;Code&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1rmdir foldername&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;或（Windows）&lt;/p&gt;
&lt;p&gt;Code&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1rmdir /S /Q foldername  # 使用/S/Q参数强制删除非空目录及其内容&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除非空文件夹及其中的所有内容（所有系统）：&lt;/p&gt;
&lt;p&gt;Code&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1rm -rf foldername&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;注意：在使用 &lt;code&gt;rm -rf&lt;/code&gt;  时要格外小心，因为它会立即、不可逆地删除指定的文件夹及其包含的所有内容。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65cbac129f345e8d036ef549.png&#34; alt=&#34;image-20240213202207539&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#数据操作&#34;&gt;#&lt;/a&gt; 数据操作&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9jb3Vyc2VzLmQybC5haS96aC12Mi8=&#34;&gt;课程安排 - 动手学深度学习课程 (d2l.ai)&lt;/span&gt;&lt;/p&gt;
&lt;h5 id=&#34;导入&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#导入&#34;&gt;#&lt;/a&gt; 导入&lt;/h5&gt;
&lt;p&gt;首先，我们导入  &lt;code&gt;torch&lt;/code&gt; 。请注意，虽然它被称为 PyTorch，但我们应该导入  &lt;code&gt;torch&lt;/code&gt;  而不是  &lt;code&gt;pytorch&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In [1]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;张量表示由一个数值组成的数组这个数组可能有多个维度&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#张量表示由一个数值组成的数组这个数组可能有多个维度&#34;&gt;#&lt;/a&gt; &lt;strong&gt;张量表示由一个数值组成的数组，这个数组可能有多个维度&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;In [2]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(12)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[2]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;可以通过张量的-shape-属性来访问张量的形状-和张量中元素的总数&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#可以通过张量的-shape-属性来访问张量的形状-和张量中元素的总数&#34;&gt;#&lt;/a&gt; &lt;strong&gt;可以通过张量的  &lt;code&gt;shape&lt;/code&gt;  属性来访问张量的&lt;em&gt;形状&lt;/em&gt; 和张量中元素的总数&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;In [3]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x.shape&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[3]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.Size([12])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;In [4]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x.numel()  #numel张量大小&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[4]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;要改变一个张量的形状而不改变元素数量和元素值可以调用-reshape-函数&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#要改变一个张量的形状而不改变元素数量和元素值可以调用-reshape-函数&#34;&gt;#&lt;/a&gt; &lt;strong&gt;要改变一个张量的形状而不改变元素数量和元素值，可以调用  &lt;code&gt;reshape&lt;/code&gt;  函数&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;In [5]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = x.reshape(3, 4)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[5]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[ 0,  1,  2,  3],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 4,  5,  6,  7],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 8,  9, 10, 11]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;使用全0-全1-其他常量或者从特定分布中随机采样的数字&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#使用全0-全1-其他常量或者从特定分布中随机采样的数字&#34;&gt;#&lt;/a&gt; &lt;strong&gt;使用全 0、全 1、其他常量或者从特定分布中随机采样的数字&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;In [6]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.zeros((2, 3, 4))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[6]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[[0., 0., 0., 0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [0., 0., 0., 0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [0., 0., 0., 0.]],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [[0., 0., 0., 0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [0., 0., 0., 0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [0., 0., 0., 0.]]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;In [7]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.ones((2, 3, 4))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[7]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[[1., 1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [1., 1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [1., 1., 1., 1.]],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [[1., 1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [1., 1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [1., 1., 1., 1.]]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;In [8]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.randn(3, 4)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[8]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[ 0.2104,  1.4439, -1.3455, -0.8273],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 0.8009,  0.3585, -0.2690,  1.6183],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [-0.4611,  1.5744, -0.4882, -0.5317]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;通过提供包含数值的-python-列表或嵌套列表来为所需张量中的每个元素赋予确定值&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#通过提供包含数值的-python-列表或嵌套列表来为所需张量中的每个元素赋予确定值&#34;&gt;#&lt;/a&gt; &lt;strong&gt;通过提供包含数值的 Python 列表（或嵌套列表）来为所需张量中的每个元素赋予确定值&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;In [9]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]).shape&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[9]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[2, 1, 4, 3],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1, 2, 3, 4],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [4, 3, 2, 1]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.Size([1,3,4])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常见的标准算术运算符（ &lt;code&gt;+&lt;/code&gt; 、 &lt;code&gt;-&lt;/code&gt; 、 &lt;code&gt;*&lt;/code&gt; 、 &lt;code&gt;/&lt;/code&gt;  和  &lt;code&gt;**&lt;/code&gt; ）都可以被升级为按元素运算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In [10]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([1.0, 2, 4, 8])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.tensor([2, 2, 2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x + y, x - y, x * y, x / y, x**y&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[10]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(tensor([ 3.,  4.,  6., 10.]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([-1.,  0.,  2.,  6.]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([ 2.,  4.,  8., 16.]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([0.5000, 1.0000, 2.0000, 4.0000]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([ 1.,  4., 16., 64.]))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;按按元素方式应用更多的计算&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#按按元素方式应用更多的计算&#34;&gt;#&lt;/a&gt; 按按元素方式应用更多的计算&lt;/h5&gt;
&lt;p&gt;In [11]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.exp(x) #每个数的指数&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[11]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;我们也可以把多个张量-连结concatenate-在一起&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#我们也可以把多个张量-连结concatenate-在一起&#34;&gt;#&lt;/a&gt; 我们也可以把多个张量 &lt;em&gt;连结&lt;/em&gt;（concatenate） 在一起&lt;/h5&gt;
&lt;p&gt;In [12]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.arange(12, dtype=torch.float32).reshape((3, 4))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# dim=0 按行拼接  dim=1 按列拼接&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[12]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(tensor([[ 0.,  1.,  2.,  3.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 4.,  5.,  6.,  7.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 8.,  9., 10., 11.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 2.,  1.,  4.,  3.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 1.,  2.,  3.,  4.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 4.,  3.,  2.,  1.]]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;数据预处理通过-逻辑运算符-构建二元张量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#数据预处理通过-逻辑运算符-构建二元张量&#34;&gt;#&lt;/a&gt; 数据预处理通过 &lt;em&gt;逻辑运算符&lt;/em&gt; 构建二元张量&lt;/h5&gt;
&lt;p&gt;In [13]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X == Y&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[13]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[False,  True, False,  True],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [False, False, False, False],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [False, False, False, False]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;求和&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#求和&#34;&gt;#&lt;/a&gt; 求和&lt;/h5&gt;
&lt;p&gt;对张量中的所有元素进行求和会产生一个只有一个元素的张量&lt;/p&gt;
&lt;p&gt;In [14]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X.sum()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[14]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor(66.)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;广播体制&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#广播体制&#34;&gt;#&lt;/a&gt; 广播体制&lt;/h5&gt;
&lt;p&gt;即使形状不同，我们仍然可以通过调用 &lt;em&gt;广播机制&lt;/em&gt; （broadcasting mechanism） 来执行按元素操作&lt;/p&gt;
&lt;p&gt;In [15]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;a = torch.arange(3).reshape((3, 1)) #3行1列&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = torch.arange(2).reshape((1, 2))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a, b&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[15]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(tensor([[0],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [1],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [2]]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([[0, 1]]))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;In [16]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;a + b  #广播机制 需要均有1维&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[16]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[0, 1],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1, 2],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [2, 3]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;可以用-1-选择最后一个元素可以用-13-选择第二个和第三个元素&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#可以用-1-选择最后一个元素可以用-13-选择第二个和第三个元素&#34;&gt;#&lt;/a&gt; 可以用  &lt;code&gt;[-1]&lt;/code&gt;  选择最后一个元素，可以用  &lt;code&gt;[1:3]&lt;/code&gt;  选择第二个和第三个元素&lt;/h5&gt;
&lt;p&gt;In [17]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X[-1] #最后一行&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;, X[1:3]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[17]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(tensor([ 8.,  9., 10., 11.]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([[ 4.,  5.,  6.,  7.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [ 8.,  9., 10., 11.]]))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;除读取外我们还可以通过指定索引来将元素写入矩阵&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#除读取外我们还可以通过指定索引来将元素写入矩阵&#34;&gt;#&lt;/a&gt; 除读取外，我们还可以通过指定索引来将元素写入矩阵&lt;/h5&gt;
&lt;p&gt;In [18]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X[1, 2] = 9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;#相当于 x[0:1,0:2]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[18]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[ 0.,  1.,  2.,  3.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 4.,  5.,  9.,  7.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 8.,  9., 10., 11.]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;为多个元素赋值相同的值我们只需要索引所有元素然后为它们赋值&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为多个元素赋值相同的值我们只需要索引所有元素然后为它们赋值&#34;&gt;#&lt;/a&gt; 为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值&lt;/h5&gt;
&lt;p&gt;In [19]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X[0:2, :] = 12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[19]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[12., 12., 12., 12.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [12., 12., 12., 12.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 8.,  9., 10., 11.]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;内存问题&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内存问题&#34;&gt;#&lt;/a&gt; 内存问题&lt;/h5&gt;
&lt;p&gt;运行一些操作可能会导致为新结果分配内存&lt;/p&gt;
&lt;p&gt;python 引用语义&lt;/p&gt;
&lt;p&gt;id 相当于 c 中的指针&lt;/p&gt;
&lt;p&gt;In [20]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;before = id(Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = Y + X #产生了一个新的Y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;id(Y) == before&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[20]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;False&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;执行原地操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#执行原地操作&#34;&gt;#&lt;/a&gt; 执行原地操作&lt;/h5&gt;
&lt;p&gt;In [21]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Z = torch.zeros_like(Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;id(Z):&amp;#x27;, id(Z))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Z[:] = X + Y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;id(Z):&amp;#x27;, id(Z))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;id(Z): 140452400950336&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;id(Z): 140452400950336&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;如果在后续计算中没有重复使用-x我们也可以使用-x-x-y-或-x-y-来减少操作的内存开销&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#如果在后续计算中没有重复使用-x我们也可以使用-x-x-y-或-x-y-来减少操作的内存开销&#34;&gt;#&lt;/a&gt; 如果在后续计算中没有重复使用  &lt;code&gt;X&lt;/code&gt; ，我们也可以使用  &lt;code&gt;X[:] = X + Y&lt;/code&gt;  或  &lt;code&gt;X += Y&lt;/code&gt;  来减少操作的内存开销&lt;/h5&gt;
&lt;p&gt;In [22]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;before = id(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X += Y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;id(X) == before&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[22]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;True&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;转换为-numpy-张量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#转换为-numpy-张量&#34;&gt;#&lt;/a&gt; 转换为  &lt;code&gt;NumPy&lt;/code&gt;  张量&lt;/h5&gt;
&lt;p&gt;In [23]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;A = X.numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;B = torch.tensor(A)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;type(A), type(B)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[23]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(numpy.ndarray, torch.Tensor)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;numpy 外部库，需要 import&lt;/p&gt;
&lt;h5 id=&#34;将大小为1的张量转换为-python-标量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#将大小为1的张量转换为-python-标量&#34;&gt;#&lt;/a&gt; 将大小为 1 的张量转换为 Python 标量&lt;/h5&gt;
&lt;p&gt;In [24]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;a = torch.tensor([3.5])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a, a.item(), float(a), int(a)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[24]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(tensor([3.5000]), 3.5, 3.5, 3)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据预处理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#数据预处理&#34;&gt;#&lt;/a&gt; 数据预处理&lt;/h2&gt;
&lt;h5 id=&#34;创建一个人工数据集并存储在csv逗号分隔值文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建一个人工数据集并存储在csv逗号分隔值文件&#34;&gt;#&lt;/a&gt; 创建一个人工数据集，并存储在 csv（逗号分隔值）文件&lt;/h5&gt;
&lt;p&gt;In [1]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;os.makedirs(os.path.join(&amp;#x27;..&amp;#x27;, &amp;#x27;data&amp;#x27;), exist_ok=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_file = os.path.join(&amp;#x27;..&amp;#x27;, &amp;#x27;data&amp;#x27;, &amp;#x27;house_tiny.csv&amp;#x27;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;with open(data_file, &amp;#x27;w&amp;#x27;) as f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&amp;#x27;NumRooms,Alley,Price\n&amp;#x27;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&amp;#x27;NA,Pave,127500\n&amp;#x27;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&amp;#x27;2,NA,106000\n&amp;#x27;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&amp;#x27;4,NA,178100\n&amp;#x27;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&amp;#x27;NA,NA,140000\n&amp;#x27;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;从创建的csv文件中加载原始数据集&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#从创建的csv文件中加载原始数据集&#34;&gt;#&lt;/a&gt; 从创建的 csv 文件中加载原始数据集&lt;/h5&gt;
&lt;p&gt;In [2]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import pandas as pd&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = pd.read_csv(data_file)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;   NumRooms Alley   Price&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;0       NaN  Pave  127500&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1       2.0   NaN  106000&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2       4.0   NaN  178100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3       NaN   NaN  140000&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;直接输出 data 会好看一些&lt;/p&gt;
&lt;p&gt;一般 csv 与 pandas 一起&lt;/p&gt;
&lt;h5 id=&#34;为了处理缺失的数据典型的方法包括插值和删除-这里我们将考虑插值&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为了处理缺失的数据典型的方法包括插值和删除-这里我们将考虑插值&#34;&gt;#&lt;/a&gt; 为了处理缺失的数据，典型的方法包括&lt;em&gt;插值&lt;/em&gt;和&lt;em&gt;删除&lt;/em&gt;， 这里，我们将考虑插值&lt;/h5&gt;
&lt;p&gt;In [3]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;inputs = inputs.fillna(inputs.mean())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(inputs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;   NumRooms Alley&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;0       3.0  Pave&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1       2.0   NaN&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2       4.0   NaN&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3       3.0   NaN&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;对于inputs中的类别值或离散值我们将nan视为一个类别&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#对于inputs中的类别值或离散值我们将nan视为一个类别&#34;&gt;#&lt;/a&gt; 对于 &lt;code&gt;inputs&lt;/code&gt;  中的类别值或离散值，我们将 “NaN” 视为一个类别&lt;/h5&gt;
&lt;p&gt;In [4]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;inputs = pd.get_dummies(inputs, dummy_na=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(inputs)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;   NumRooms  Alley_Pave  Alley_nan&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;0       3.0           1          0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1       2.0           0          1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2       4.0           0          1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3       3.0           0          1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;现在 &lt;code&gt;inputs&lt;/code&gt;  和 &lt;code&gt;outputs&lt;/code&gt;  中的所有条目都是数值类型，它们可以转换为张量格式&lt;/p&gt;
&lt;p&gt;In [5]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X, y&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out[5]:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;(tensor([[3., 1., 0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [2., 0., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [4., 0., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [3., 0., 1.]], dtype=torch.float64),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; tensor([127500, 106000, 178100, 140000]))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240214012040421.png&#34; alt=&#34;image-20240214012040421&#34; /&gt;&lt;/p&gt;
&lt;p&gt;tensor 是数学上的一个概念 array 是计算机一个概念&lt;/p&gt;
&lt;h2 id=&#34;下载电子书&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#下载电子书&#34;&gt;#&lt;/a&gt; 下载电子书&lt;/h2&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65cbac289f345e8d036f2f6e.png&#34; alt=&#34;image-20240208194727799&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;zlibrary&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#zlibrary&#34;&gt;#&lt;/a&gt; zlibrary&lt;/h3&gt;
&lt;p&gt;由于 free 经常被免费下架&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最新版网址获取方式：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;blackbox@zlib.se&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;向这个邮箱发任意信息，等几分钟就会回复最新版的网址&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65cbac4c9f345e8d036f8948.png&#34; alt=&#34;image-20240208200237222&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic.imgdb.cn/item/65cbac679f345e8d036fcbdc.png&#34; alt=&#34;image-20240208200405438&#34; /&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/11/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/</guid>
            <title>PyTorch学习第二章——深度学习入门</title>
            <link>https://jinjiaojiao.top/2024/02/11/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/</link>
            <category term="PyTorch学习" scheme="https://jinjiaojiao.top/categories/PyTorch%E5%AD%A6%E4%B9%A0/" />
            <category term="PyTorch学习" scheme="https://jinjiaojiao.top/tags/PyTorch%E5%AD%A6%E4%B9%A0/" />
            <pubDate>Sun, 11 Feb 2024 18:25:18 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NjU0Mzc5MQ==&#34;&gt;60 分钟快速入门 PyTorch - 知乎 (zhihu.com)&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;第二章pytorch之60min入门&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#第二章pytorch之60min入门&#34;&gt;#&lt;/a&gt; 第二章： &lt;code&gt;PyTorch&lt;/code&gt;  之 &lt;code&gt;60min&lt;/code&gt;  入门&lt;/h1&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic1.zhimg.com/80/v2-ef363cc5320400c63cf356c203d39bec_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;什么是-pytorch&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#什么是-pytorch&#34;&gt;#&lt;/a&gt; 什么是  &lt;code&gt;PyTorch&lt;/code&gt; ?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;PyTorch&lt;/code&gt;  是一个基于 Python 的科学计算包，主要定位两类人群：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NumPy&lt;/code&gt;  的替代品，可以利用  &lt;code&gt;GPU&lt;/code&gt;  的性能进行计算。&lt;/li&gt;
&lt;li&gt;深度学习研究平台拥有足够的&lt;strong&gt;灵活性&lt;/strong&gt;和&lt;strong&gt;速度&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;开始学习&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#开始学习&#34;&gt;#&lt;/a&gt; 开始学习&lt;/h2&gt;
&lt;h3 id=&#34;tensors-张量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#tensors-张量&#34;&gt;#&lt;/a&gt; Tensors (张量)&lt;/h3&gt;
&lt;p&gt;Tensors 类似于  &lt;code&gt;NumPy&lt;/code&gt;  的  &lt;code&gt;ndarrays&lt;/code&gt;  ，同时 Tensors 可以使用  &lt;code&gt;GPU&lt;/code&gt;  进行计算。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;from __future__ import print_function&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;import torch&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;torchempty-声明一个未初始化的矩阵&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#torchempty-声明一个未初始化的矩阵&#34;&gt;#&lt;/a&gt; &lt;strong&gt;torch.empty()&lt;/strong&gt;: 声明一个未初始化的矩阵。&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.empty(5, 3)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[9.2737e-41, 8.9074e-01, 1.9286e-37],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [1.7228e-34, 5.7064e+01, 9.2737e-41],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [2.2803e+02, 1.9288e-37, 1.7228e-34],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [1.4609e+04, 9.2737e-41, 5.8375e+04],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [1.9290e-37, 1.7228e-34, 3.7402e+06]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;torchrand随机初始化一个矩阵&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#torchrand随机初始化一个矩阵&#34;&gt;#&lt;/a&gt; &lt;strong&gt;torch.rand()&lt;/strong&gt;：随机初始化一个矩阵&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.rand(5, 3)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[ 0.6291,  0.2581,  0.6414],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  [ 0.9739,  0.8243,  0.2276],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  [ 0.4184,  0.1815,  0.5131],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  [ 0.5533,  0.5440,  0.0718],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  [ 0.2908,  0.1850,  0.5297]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;验证能否运行在gpu&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#验证能否运行在gpu&#34;&gt;#&lt;/a&gt; 验证能否运行在 GPU&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.cuda.is_available()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;torchzeros创建数值皆为-0-的矩阵&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#torchzeros创建数值皆为-0-的矩阵&#34;&gt;#&lt;/a&gt; &lt;strong&gt;torch.zeros()&lt;/strong&gt;：创建数值皆为 0 的矩阵&lt;/h5&gt;
&lt;p&gt;Construct a matrix filled zeros and of dtype long:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.zeros(5, 3, dtype=torch.long)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;tensor([[ 0,  0,  0],&lt;br /&gt;
[ 0,  0,  0],&lt;br /&gt;
[ 0,  0,  0],&lt;br /&gt;
[ 0,  0,  0],&lt;br /&gt;
[ 0,  0,  0]])&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;torchtensor直接传递-tensor-数值来创建&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#torchtensor直接传递-tensor-数值来创建&#34;&gt;#&lt;/a&gt; &lt;strong&gt;torch.tensor()&lt;/strong&gt;：直接传递 tensor 数值来创建&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor 数值是 [5.5 , 3]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([5.5, 3])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;tensor([ 5.5000,  3.0000])&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;除了上述几种方法，还可以根据已有的 tensor 变量创建新的 tensor 变量，这种做法的好处就是可以保留已有 tensor 的一些属性，包括尺寸大小、数值属性，除非是重新定义这些属性。相应的实现方法如下：&lt;/p&gt;
&lt;h5 id=&#34;tensornew_onesnew_-方法需要输入尺寸大小&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#tensornew_onesnew_-方法需要输入尺寸大小&#34;&gt;#&lt;/a&gt; tensor.new_ones()&lt;em&gt;：new_&lt;/em&gt;() 方法需要输入尺寸大小&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 显示定义新的尺寸是 5*3，数值类型是 torch.double&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensor2 = tensor1.new_ones(5, 3, dtype=torch.double)  # new_* 方法需要输入 tensor 大小&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(tensor2)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 1.]], dtype=torch.float64)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;torchrandn_likeold_tensor保留相同的尺寸大小&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#torchrandn_likeold_tensor保留相同的尺寸大小&#34;&gt;#&lt;/a&gt; &lt;strong&gt;torch.randn_like(old_tensor)&lt;/strong&gt;：保留相同的尺寸大小&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 修改数值类型&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensor3 = torch.randn_like(tensor2, dtype=torch.float)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;tensor3: &amp;#x27;, tensor3)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果，这里是根据上个方法声明的  &lt;code&gt;tensor2&lt;/code&gt;  变量来声明新的变量，可以看出尺寸大小都是 5*3，但是数值类型是改变了的。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor3:  tensor([[-0.4491, -0.2634, -0.0040],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [-0.1624,  0.4475, -0.8407],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [-0.6539, -1.2772,  0.6060],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 0.2304,  0.0879, -0.3876],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 1.2900, -0.7475, -1.8212]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;最后，对 tensors 的尺寸大小获取可以采用  &lt;code&gt;tensor.size()&lt;/code&gt;  方法：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;print(tensor3.size())  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 输出: torch.Size([5, 3])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;获取它的维度信息&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#获取它的维度信息&#34;&gt;#&lt;/a&gt; &lt;strong&gt;获取它的维度信息:&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;print(x.size())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.Size([5, 3])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：  &lt;code&gt;torch.Size&lt;/code&gt;  实际上是&lt;strong&gt;元组 (tuple) 类型，所以支持所有的元组操作&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#操作&#34;&gt;#&lt;/a&gt; 操作&lt;/h3&gt;
&lt;p&gt;在接下来的例子中，我们将会看到加法操作。&lt;/p&gt;
&lt;h4 id=&#34;加法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#加法&#34;&gt;#&lt;/a&gt; 加法&lt;/h4&gt;
&lt;h5 id=&#34;运算符&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#运算符&#34;&gt;#&lt;/a&gt; + 运算符&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;y = torch.rand(5, 3)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x + y)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[-0.1859,  1.3970,  0.5236],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [ 2.3854,  0.0707,  2.1970],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-0.3587,  1.2359,  1.8951],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-0.1189, -0.1376,  0.4647],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-1.8968,  2.0164,  0.1092]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;add&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#add&#34;&gt;#&lt;/a&gt; add&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;print(torch.add(x, y))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[-0.1859,  1.3970,  0.5236],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 2.3854,  0.0707,  2.1970],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [-0.3587,  1.2359,  1.8951],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [-0.1189, -0.1376,  0.4647],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [-1.8968,  2.0164,  0.1092]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h5 id=&#34;result提供一个输出&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#result提供一个输出&#34;&gt;#&lt;/a&gt; result 提供一个输出&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;result = torch.empty(5, 3)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.add(x, y, out=result) #x+y 结果储存在result中&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(result)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[-0.1859,  1.3970,  0.5236],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [ 2.3854,  0.0707,  2.1970],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-0.3587,  1.2359,  1.8951],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-0.1189, -0.1376,  0.4647],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-1.8968,  2.0164,  0.1092]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;add_-直接修改变量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#add_-直接修改变量&#34;&gt;#&lt;/a&gt; add_ 直接修改变量&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# adds x to y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y.add_(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(y)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[-0.1859,  1.3970,  0.5236],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [ 2.3854,  0.0707,  2.1970],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-0.3587,  1.2359,  1.8951],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-0.1189, -0.1376,  0.4647],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     [-1.8968,  2.0164,  0.1092]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;注意 任何使张量会发生变化的操作都有一个前缀 &#39;_&#39;。例如： &lt;code&gt;x.copy_(y)&lt;/code&gt; ,  &lt;code&gt;x.t_()&lt;/code&gt; , 将会改变  &lt;code&gt;x&lt;/code&gt; .&lt;/p&gt;
&lt;h4 id=&#34;对于-tensor-的访问&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#对于-tensor-的访问&#34;&gt;#&lt;/a&gt; 对于 Tensor 的访问&lt;/h4&gt;
&lt;p&gt;除了加法运算操作，，和 Numpy 对数组类似，可以使用索引来访问某一维的数据，如下所示：&lt;/p&gt;
&lt;h5 id=&#34;索引操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#索引操作&#34;&gt;#&lt;/a&gt; &lt;strong&gt;索引&lt;/strong&gt;操作&lt;/h5&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 访问 tensor3 第一列数据&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x[:, 1])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([ 0.4477, -0.0048,  1.0878, -0.2174,  1.3609])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;torchview对-tensor-的尺寸修改&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#torchview对-tensor-的尺寸修改&#34;&gt;#&lt;/a&gt; torch.view ()：对 Tensor 的尺寸修改&lt;/h5&gt;
&lt;p&gt;如果你想改变一个 tensor 的大小或者形状，你可以使用  &lt;code&gt;torch.view&lt;/code&gt; :&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.randn(4, 4)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = x.view(16)  # 1*16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = x.view(-1, 8)  # the size -1 is inferred from other dimensions&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x.size(), y.size(), z.size())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;-1&lt;/code&gt;  用于 &lt;code&gt;view&lt;/code&gt;  方法中作为一个特殊的参数值，表示自动计算该维度的大小。当你重新调整一个张量的形状时， &lt;code&gt;-1&lt;/code&gt;  将会被替换为一个值，这个值是根据张量的总元素数和其他维度的大小自动计算出来的，以保证新形状的元素总数与原张量相同。&lt;/p&gt;
&lt;p&gt;总数不变&lt;/p&gt;
&lt;h5 id=&#34;item&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#item&#34;&gt;#&lt;/a&gt; .item()&lt;/h5&gt;
&lt;p&gt;如果你有一个元素 tensor ，&lt;strong&gt;使用 .item () 来获得这个 value&lt;/strong&gt; 。如果 tensor 仅有一个元素，可以采用  &lt;code&gt;.item()&lt;/code&gt;  来获取类似 Python 中整数类型的数值：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.randn(1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x.item())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Out:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([ 0.9422])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;0.9422121644020081&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;更多运算操作请看文档&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS90b3JjaC5odG1s&#34;&gt;torch — PyTorch 2.2 documentation&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;和numpy数组的转换&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#和numpy数组的转换&#34;&gt;#&lt;/a&gt; 和 Numpy 数组的转换&lt;/h3&gt;
&lt;p&gt;Tensor 和 Numpy 的数组可以相互转换，并且两者转换后共享在 CPU 下的内存空间，即改变其中一个的数值，另一个变量也会随之改变。&lt;/p&gt;
&lt;h3 id=&#34;tensor-转换为-numpy-数组&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#tensor-转换为-numpy-数组&#34;&gt;#&lt;/a&gt; &lt;strong&gt;Tensor 转换为 Numpy 数组&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;实现 Tensor 转换为 Numpy 数组的例子如下所示，调用  &lt;code&gt;tensor.numpy()&lt;/code&gt;  可以实现这个转换操作。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;a = torch.ones(5)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(a)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = a.numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(b)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([1., 1., 1., 1., 1.])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[1. 1. 1. 1. 1.]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;numpy-数组转换为-tensor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#numpy-数组转换为-tensor&#34;&gt;#&lt;/a&gt; &lt;strong&gt;Numpy 数组转换为 Tensor&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;转换的操作是调用  &lt;code&gt;torch.from_numpy(numpy_array)&lt;/code&gt;  方法。例子如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import numpy as np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a = np.ones(5)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = torch.from_numpy(a)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;np.add(a, 1, out=a)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(a)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(b)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[2. 2. 2. 2. 2.]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensor([2., 2., 2., 2., 2.], dtype=torch.float64)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在  &lt;code&gt;CPU&lt;/code&gt;  上，除了  &lt;code&gt;CharTensor&lt;/code&gt;  外的所有  &lt;code&gt;Tensor&lt;/code&gt;  类型变量，都支持和  &lt;code&gt;Numpy&lt;/code&gt;  数组的相互转换操作。&lt;/p&gt;
&lt;h3 id=&#34;cuda-张量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#cuda-张量&#34;&gt;#&lt;/a&gt; &lt;strong&gt;CUDA 张量&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Tensors&lt;/code&gt;  可以通过  &lt;code&gt;.to&lt;/code&gt;  方法转换到不同的设备上，即 CPU 或者 GPU 上。&lt;/p&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 当 CUDA 可用的时候，可用运行下方这段代码，采用 torch.device() 方法来改变 tensors 是否在 GPU 上进行计算操作&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;if torch.cuda.is_available():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    device = torch.device(&amp;quot;cuda&amp;quot;)          # 定义一个 CUDA 设备对象&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y = torch.ones_like(x, device=device)  # 显示创建在 GPU 上的一个 tensor&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x = x.to(device)                       # 也可以采用 .to(&amp;quot;cuda&amp;quot;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    z = x + y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    print(z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    print(z.to(&amp;quot;cpu&amp;quot;, torch.double))       # .to() 方法也可以改变数值类型&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果，第一个结果就是在 GPU 上的结果，打印变量的时候会带有  &lt;code&gt;device=&#39;cuda:0&#39;&lt;/code&gt; ，而第二个是在 CPU 上的变量。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([1.4549], device=&amp;#x27;cuda:0&amp;#x27;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensor([1.4549], dtype=torch.float64)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;本小节教程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvYmxpdHovdGVuc29yX3R1dG9yaWFsLmh0bWw=&#34;&gt;https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;本小节的代码：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL2NjYzAxMy9EZWVwTGVhcm5pbmdfTm90ZXMvYmxvYi9tYXN0ZXIvUHl0b3JjaC9wcmFjdGlzZS9iYXNpY19wcmFjdGlzZS5pcHluYg==&#34;&gt;https://github.com/ccc013/DeepLearning_Notes/blob/master/Pytorch/practise/basic_practise.ipynb&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;autograd&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#autograd&#34;&gt;#&lt;/a&gt; &lt;strong&gt;autograd&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;对于 Pytorch 的神经网络来说，非常关键的一个库就是  &lt;code&gt;autograd&lt;/code&gt;  ，&lt;/p&gt;
&lt;p&gt;提供了对  &lt;code&gt;Tensors&lt;/code&gt;  上所有运算操作的&lt;strong&gt;自动微分功能&lt;/strong&gt;，也就是&lt;strong&gt;计算梯度&lt;/strong&gt;的功能。&lt;/p&gt;
&lt;p&gt;它属于  &lt;code&gt;define-by-run&lt;/code&gt;  类型框架，即反向传播操作的定义是根据代码的运行方式，因此每次迭代都可以是不同的。&lt;/p&gt;
&lt;h3 id=&#34;张量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#张量&#34;&gt;#&lt;/a&gt; &lt;strong&gt;张量&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;  是 Pytorch 最主要的库，当设置它的属性  &lt;code&gt;.requires_grad=True&lt;/code&gt; ，那么就会开始&lt;strong&gt;追踪在该变量上的所有操作&lt;/strong&gt;，而完成计算后，可以调用  &lt;code&gt;.backward()&lt;/code&gt;  并自动计算所有的梯度，得到的梯度都保存在属性  &lt;code&gt;.grad&lt;/code&gt;  中。&lt;/p&gt;
&lt;p&gt;调用  &lt;code&gt;.detach()&lt;/code&gt;  方法&lt;strong&gt;分离出计算的历史&lt;/strong&gt;，可以停止一个 tensor 变量继续追踪其历史信息 ，同时也防止未来的计算会被追踪。&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;with torch.no_grad():&lt;/code&gt;  就是告诉 PyTorch：“现在我只想用模型来做一些前向计算，不需要做梯度更新，请暂时不要保存那些用于梯度更新所必需的信息，以节省计算资源和内存”。这样做可以让模型运行得更快，同时消耗更少的资源。&lt;/p&gt;
&lt;h4 id=&#34;function&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#function&#34;&gt;#&lt;/a&gt; Function&lt;/h4&gt;
&lt;p&gt;对于  &lt;code&gt;autograd&lt;/code&gt;  的实现，还有一个类也是非常重要 &lt;code&gt;Function&lt;/code&gt;  。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Tensor&lt;/code&gt;  和  &lt;code&gt;Function&lt;/code&gt;  两个类是有关联并建立了一个&lt;strong&gt;非循环的图&lt;/strong&gt;，可以编码一个完整的计算记录。每个 tensor 变量都带有属性  &lt;code&gt;.grad_fn&lt;/code&gt;  ，该属性引用了创建了这个变量的  &lt;code&gt;Function&lt;/code&gt;  （除了由用户创建的 Tensors，它们的  &lt;code&gt;grad_fn=None&lt;/code&gt;  )。&lt;/p&gt;
&lt;p&gt;&amp;lt;details&amp;gt;&lt;br /&gt;
&amp;lt;summary&amp;gt;grad_fn&amp;lt;/summary&amp;gt;&lt;br /&gt;
 在深度学习中，模型训练的一个重要步骤是计算损失函数（即模型输出与真实值之间的差距）关于模型参数的梯度（或导数），然后根据这些梯度来更新模型参数，以使损失函数的值减小。这个过程称为梯度下降。PyTorch 通过建立一个计算图来帮助实现这个过程，而这个计算图是由 Tensor 和 Function 这两个类的实例组成的。&lt;br /&gt;
Tensor&lt;br /&gt;
 在 PyTorch 中，Tensor 是一个多维数组，用于存储模型的输入数据、参数、输出数据以及计算过程中的各种中间数据。每个 Tensor 都可以跟踪它是如何被创建的 —— 即它是通过什么样的操作从其他 Tensor 转换而来的。Function&lt;br /&gt;
 每个操作，不管是简单的数学运算还是复杂的神经网络层操作，都可以看作是一个 Function。这些 Function 不仅执行计算，还记录了计算的细节，以便于后续进行梯度的反向传播。&lt;br /&gt;
计算图&lt;br /&gt;
当你在 PyTorch 中执行操作时，你实际上是在构建一个计算图。这个图是由节点（Tensor）和边（Function，表示操作）组成的。这个图是向前构建的：从输入 Tensor 开始，通过各种操作，最终到达输出 Tensor。这个过程称为前向传播。&lt;br /&gt;
.grad_fn 属性&lt;br /&gt;
每个 Tensor 都有一个.grad_fn 属性，这个属性是一个指向 Function 的引用，即这个 Tensor 是通过哪个 Function 计算得到的。如果这个 Tensor 是直接由用户创建的（不是通过某些操作得到的），那么它的.grad_fn 就是 None，因为它不是通过计算得到的。&lt;br /&gt;
非循环图&lt;br /&gt;
这个计算图是非循环的，意味着数据流是有方向的，从输入流向输出，不会有任何循环或回路。这使得在图中进行前向传播和反向传播（用于计算梯度）变得简单明了。&lt;/p&gt;
&lt;p&gt;为什么这很重要？&lt;br /&gt;
当进行反向传播以计算梯度时，PyTorch 会沿着这个图从输出向后逐步移动，使用&lt;strong&gt;链式法&lt;/strong&gt;则自动计算每个参数的梯度。这个过程完全自动化，用户不需要手动编写梯度计算代码，极大地简化了深度学习模型的训练过程。&lt;/p&gt;
&lt;p&gt;简而言之， &lt;code&gt;Tensor&lt;/code&gt;  和 &lt;code&gt;Function&lt;/code&gt;  通过&lt;strong&gt;计算图&lt;/strong&gt;相互关联，这个图能够追踪整个计算过程，为自动梯度计算（自动微分）提供支持，使得深度学习模型的训练变得更加高效和简单。&lt;/p&gt;
&lt;p&gt;如果要进行求导运算，可以调用一个  &lt;code&gt;Tensor&lt;/code&gt;  变量的方法  &lt;code&gt;.backward()&lt;/code&gt;  。如果该变量是一个标量，即仅有一个元素，那么不需要传递任何参数给方法  &lt;code&gt;.backward()&lt;/code&gt; ，当包含多个元素的时候，就必须指定一个  &lt;code&gt;gradient&lt;/code&gt;  参数，表示匹配尺寸大小的 tensor，这部分见第二小节介绍梯度的内容。&lt;/p&gt;
&lt;p&gt;接下来就开始用代码来进一步介绍。&lt;/p&gt;
&lt;p&gt;首先导入必须的库：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;开始创建一个 tensor， 并让  &lt;code&gt;requires_grad=True&lt;/code&gt;  来&lt;strong&gt;追踪该变量相关的计算操作&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.ones(2, 2, requires_grad=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1.]], requires_grad=True)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;执行任意计算操作，这里进行简单的加法运算：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;y = x + 2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(y)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[3., 3.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [3., 3.]], grad_fn=&amp;lt;AddBackward&amp;gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;y&lt;/code&gt;  是一个操作的结果，所以它带有属性  &lt;code&gt;grad_fn&lt;/code&gt; ：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;print(y.grad_fn)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&amp;lt;AddBackward object at 0x00000216D25DCC88&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;继续对变量  &lt;code&gt;y&lt;/code&gt;  进行操作：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;z = y * y * 3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;out = z.mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;z=&amp;#x27;, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;out=&amp;#x27;, out)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;z= tensor([[27., 27.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [27., 27.]], grad_fn=&amp;lt;MulBackward&amp;gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;out= tensor(27., grad_fn=&amp;lt;MeanBackward1&amp;gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;实际上，一个  &lt;code&gt;Tensor&lt;/code&gt;  变量的默认  &lt;code&gt;requires_grad&lt;/code&gt;  是  &lt;code&gt;False&lt;/code&gt;  ，可以像上述定义一个变量时候指定该属性是  &lt;code&gt;True&lt;/code&gt; ，当然也可以定义变量后，调用  &lt;code&gt;.requires_grad_(True)&lt;/code&gt;  设置为  &lt;code&gt;True&lt;/code&gt;  ，这里带有后缀  &lt;code&gt;_&lt;/code&gt;  是会改变变量本身的属性，在上一节介绍加法操作  &lt;code&gt;add_()&lt;/code&gt;  说明过&lt;/p&gt;
&lt;p&gt;代码例子：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;a = torch.randn(2, 2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a = ((a * 3) / (a - 1))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(a.requires_grad)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a.requires_grad_(True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(a.requires_grad)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = (a * a).sum()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(b.grad_fn)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果如下，第一行是为设置  &lt;code&gt;requires_grad&lt;/code&gt;  的结果，接着显示调用  &lt;code&gt;.requires_grad_(True)&lt;/code&gt; ，输出结果就是  &lt;code&gt;True&lt;/code&gt;  。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;False&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;True&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&amp;lt;SumBackward0 object at 0x00000216D25ED710&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;梯度&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#梯度&#34;&gt;#&lt;/a&gt; &lt;strong&gt;梯度&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;接下来就是开始计算梯度，进行&lt;strong&gt;反向传播&lt;/strong&gt;的操作。 &lt;code&gt;out&lt;/code&gt;  变量是上一小节中定义的，它是一个标量，因此  &lt;code&gt;out.backward()&lt;/code&gt;  相当于  &lt;code&gt;out.backward(torch.tensor(1.))&lt;/code&gt;  ，&lt;/p&gt;
&lt;p&gt;代码如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;out.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 输出梯度 d(out)/dx&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x.grad)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[4.5000, 4.5000],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [4.5000, 4.5000]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;结果应该就是得到数值都是 4.5 的矩阵。这里我们用  &lt;code&gt;o&lt;/code&gt;  表示  &lt;code&gt;out&lt;/code&gt;  变量，那么根据之前的定义会有：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;O = \frac{1}{4} \sum_i z_i,
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.599109em;vertical-align:-1.277669em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.32144em;&#34;&gt;&lt;span style=&#34;top:-2.314em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.677em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.686em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.0500050000000003em;&#34;&gt;&lt;span style=&#34;top:-1.872331em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.050005em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.277669em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.04398em;&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;z_i = 3(x_i + 2)^2,
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.58056em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.04398em;&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.1141079999999999em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mo fence=&#34;false&#34;&gt;∣&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;27&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;z_i \big|_{x_i=1} = 27
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.3677899999999998em;vertical-align:-0.49980999999999987em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.04398em;&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;delimsizing mult&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8679800000000001em;&#34;&gt;&lt;span style=&#34;top:-2.2559899999999997em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.26698em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.86798em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.35000999999999993em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.051398000000000055em;&#34;&gt;&lt;span style=&#34;top:-2.30029em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3280857142857143em;&#34;&gt;&lt;span style=&#34;top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.143em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mrel mtight&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.49980999999999987em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;详细来说，初始定义的  &lt;code&gt;x&lt;/code&gt;  是一个全为 1 的矩阵，然后加法操作  &lt;code&gt;x+2&lt;/code&gt;  得到  &lt;code&gt;y&lt;/code&gt;  ，接着  &lt;code&gt;y*y*3&lt;/code&gt; ， 得到  &lt;code&gt;z&lt;/code&gt;  ，并且此时  &lt;code&gt;z&lt;/code&gt;  是一个 2*2 的矩阵，所以整体求平均得到  &lt;code&gt;out&lt;/code&gt;  变量应该是除以 4，所以得到上述三条公式。&lt;/p&gt;
&lt;p&gt;因此，计算梯度：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∂&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∂&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{\partial o}{\partial x_i} = \frac{3}{2} (x_i + 2),
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.20744em;vertical-align:-0.8360000000000001em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.37144em;&#34;&gt;&lt;span style=&#34;top:-2.3139999999999996em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34; style=&#34;margin-right:0.05556em;&#34;&gt;∂&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.677em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34; style=&#34;margin-right:0.05556em;&#34;&gt;∂&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8360000000000001em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.00744em;vertical-align:-0.686em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.32144em;&#34;&gt;&lt;span style=&#34;top:-2.314em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.677em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.686em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∂&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∂&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo fence=&#34;true&#34;&gt;∣&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;9&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;4.5&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\left.\frac{\partial o}{\partial x_i}\right|_{x_i=1} = \frac{9}{2} = 4.5
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.57979em;vertical-align:-1.0998199999999998em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.37144em;&#34;&gt;&lt;span style=&#34;top:-2.3139999999999996em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34; style=&#34;margin-right:0.05556em;&#34;&gt;∂&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.677em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34; style=&#34;margin-right:0.05556em;&#34;&gt;∂&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8360000000000001em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;delimsizing mult&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.4799700000000002em;&#34;&gt;&lt;span style=&#34;top:-1.65598em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.25698em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.85798em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.87897em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.47997em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.9500199999999999em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:-0.5486119999999999em;&#34;&gt;&lt;span style=&#34;top:-1.7002800000000005em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3280857142857143em;&#34;&gt;&lt;span style=&#34;top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.143em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mrel mtight&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.0998199999999998em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.00744em;vertical-align:-0.686em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.32144em;&#34;&gt;&lt;span style=&#34;top:-2.314em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.677em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;9&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.686em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;从数学上来说，如果你有一个向量值函数：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;⃗&lt;/mo&gt;&lt;/mover&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\hat{y} = f(\vec{x})
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord accent&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.69444em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;accent-body&#34; style=&#34;left:-0.19444em;&#34;&gt;&lt;span class=&#34;mord&#34;&gt;^&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.19444em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord accent&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.714em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;accent-body&#34; style=&#34;left:-0.20772em;&#34;&gt;&lt;span class=&#34;overlay&#34; style=&#34;height:0.714em;width:0.471em;&#34;&gt;&lt;svg width=&#39;0.471em&#39; height=&#39;0.714em&#39; style=&#39;width:0.471em&#39; viewBox=&#39;0 0 471 714&#39; preserveAspectRatio=&#39;xMinYMin&#39;&gt;&lt;path d=&#39;M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z&#39;/&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么对应的梯度是一个雅克比矩阵 (Jacobian matrix)：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240210172846221.png&#34; alt=&#34;image-20240210172846221&#34; /&gt;&lt;/p&gt;
&lt;p&gt;一般来说， &lt;code&gt;torch.autograd&lt;/code&gt;  就是用于计算雅克比向量 (vector-Jacobian) 乘积的工具。这里略过数学公式，直接上代码例子介绍：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.randn(3, requires_grad=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = x * 2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;while y.data.norm() &amp;lt; 1000:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y = y * 2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(y)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;神经网络&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#神经网络&#34;&gt;#&lt;/a&gt; 神经网络&lt;/h2&gt;
&lt;p&gt;在 PyTorch 中  &lt;code&gt;torch.nn&lt;/code&gt;  专门用于实现神经网络。其中  &lt;code&gt;nn.Module&lt;/code&gt;  包含了网络层的搭建，以及一个方法 --  &lt;code&gt;forward(input)&lt;/code&gt;  ，并返回网络的输出  &lt;code&gt;output&lt;/code&gt;  .&lt;/p&gt;
&lt;p&gt;下面是一个经典的 LeNet 网络，用于对字符进行分类。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-06a914f4ee93f25c0d6c924df9b4b4cb_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;对于神经网络来说，一个标准的&lt;strong&gt;训练流程&lt;/strong&gt;是这样的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;定义一个&lt;strong&gt;多层的神经网络&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对数据集的&lt;strong&gt;预处理&lt;/strong&gt;并准备作为网络的输入&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将数据&lt;strong&gt;输入到网络&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算网络的&lt;strong&gt;损失&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;反向传播&lt;/strong&gt;，计算&lt;strong&gt;梯度&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt;网络的梯度，一个简单的更新规则是  &lt;code&gt;weight = weight - learning_rate * gradient&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;定义网络&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#定义网络&#34;&gt;#&lt;/a&gt; &lt;strong&gt;定义网络&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;首先定义一个神经网络，下面是一个 5 层的卷积神经网络，包含两层卷积层和三层全连接层：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Net&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Net,self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         &lt;span class=&#34;comment&#34;&gt;# 输入图像是单通道，conv1 kenrnel size=5*5，输出通道 6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; ,&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt; ,&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# conv2 kernel size=5*5, 输出通道 16&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;#全连接层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc1 = nn.Linear(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;*&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;*&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; , &lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc2 = nn.Linear(&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc3 = nn.Linear(&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self,x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# max-pooling 采用一个 (2,2) 的滑动窗口&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.max_pool2d(F.relu(self.conv1(x)), (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         &lt;span class=&#34;comment&#34;&gt;# 核(kernel)大小是方形的话，可仅定义一个数字，如 (2,2) 用 2 即可&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.max_pool2d(F.relu(self.conv2(x)), &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = x.view(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, self.num_flat_features(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(self.fc1(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(self.fc2(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.fc3(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;num_flat_features&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 除了 batch 维度外的所有维度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        size = x.size()[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        num_features = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; s &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; size:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            num_features *= s&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; num_features&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = Net()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;打印网络结构：&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Net(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (conv1): Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, kernel_size=(&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;), stride=(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (conv2): Conv2d(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, kernel_size=(&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;), stride=(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (fc1): Linear(in_features=&lt;span class=&#34;number&#34;&gt;400&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (fc2): Linear(in_features=&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (fc3): Linear(in_features=&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;打印网络结构：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Net(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (fc1): Linear(in_features=400, out_features=120, bias=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (fc2): Linear(in_features=120, out_features=84, bias=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  (fc3): Linear(in_features=84, out_features=10, bias=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里必须实现  &lt;code&gt;forward&lt;/code&gt;  函数，而  &lt;code&gt;backward&lt;/code&gt;  函数在采用  &lt;code&gt;autograd&lt;/code&gt;  时就自动定义好了，在  &lt;code&gt;forward&lt;/code&gt;  方法可以采用任何的张量操作。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;net.parameters()&lt;/code&gt;  可以返回网络的训练参数，使用例子如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;params = list(net.parameters())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;参数数量: &amp;#x27;, len(params))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# conv1.weight&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;第一个参数大小: &amp;#x27;, params[0].size())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;参数数量:  10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;第一个参数大小:  torch.Size([6, 1, 5, 5])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后简单测试下这个网络，随机生成一个 32*32 的输入：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 随机定义一个变量输入网络&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;input = torch.randn(1, 1, 32, 32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;out = net(input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(out)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[ 0.1005,  0.0263,  0.0013, -0.1157, -0.1197, -0.0141,  0.1425, -0.0521,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          0.0689,  0.0220]], grad_fn=&amp;lt;ThAddmmBackward&amp;gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;接着反向传播需要先清空梯度缓存，并反向传播随机梯度：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 清空所有参数的梯度缓存，然后计算随机梯度进行反向传播&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;out.backward(torch.randn(1, 10))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;torch.nn&lt;/code&gt;  只支持 ** 小批量 (mini-batches)** 数据，也就是输入不能是单个样本，比如对于  &lt;code&gt;nn.Conv2d&lt;/code&gt;  接收的输入是一个 4 维张量 -- &lt;code&gt;nSamples * nChannels * Height * Width&lt;/code&gt;  。&lt;br /&gt;
所以，如果你输入的是单个样本，&lt;strong&gt;需要采用&lt;/strong&gt;  &lt;code&gt;**input.unsqueeze(0)**&lt;/code&gt;  &lt;strong&gt;来扩充一个假的 batch 维度，即从 3 维变为 4 维&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;损失函数&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#损失函数&#34;&gt;#&lt;/a&gt; &lt;strong&gt;损失函数&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;损失函数的输入是  &lt;code&gt;(output, target)&lt;/code&gt;  ，即网络输出和真实标签对的数据，然后返回一个数值表示网络输出和真实标签的差距。&lt;/p&gt;
&lt;p&gt;PyTorch 中其实已经定义了不少的&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy9kb2NzL25uLmh0bWwlMjNsb3NzLWZ1bmN0aW9ucw==&#34;&gt;损失函数&lt;/span&gt;，这里仅采用简单的均方误差： &lt;code&gt;nn.MSELoss&lt;/code&gt;  ，例子如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;output = net(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 定义伪标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;target = torch.randn(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 调整大小，使得和 output 一样的 size&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;target = target.view(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;criterion = nn.MSELoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = criterion(output, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(loss)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor(0.6524, grad_fn=&amp;lt;MseLossBackward&amp;gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里，整个网络的数据输入到输出经历的计算图如下所示，其实也就是数据从输入层到输出层，计算  &lt;code&gt;loss&lt;/code&gt;  的过程。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;input -&amp;gt; conv2d -&amp;gt; relu -&amp;gt; maxpool2d -&amp;gt; conv2d -&amp;gt; relu -&amp;gt; maxpool2d&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -&amp;gt; view -&amp;gt; linear -&amp;gt; relu -&amp;gt; linear -&amp;gt; relu -&amp;gt; linear&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -&amp;gt; MSELoss&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -&amp;gt; loss&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果调用  &lt;code&gt;loss.backward()&lt;/code&gt;  ，那么整个图都是可微分的，也就是说包括  &lt;code&gt;loss&lt;/code&gt;  ，图中的所有张量变量，只要其属性  &lt;code&gt;requires_grad=True&lt;/code&gt;  ，那么其梯度  &lt;code&gt;.grad&lt;/code&gt;  张量都会随着梯度一直累计。&lt;/p&gt;
&lt;p&gt;用代码来说明：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# MSELoss&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(loss.grad_fn)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Linear layer&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(loss.grad_fn.next_functions[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Relu&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(loss.grad_fn.next_functions[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].next_functions[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&amp;lt;MseLossBackward object at 0x0000019C0C349908&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&amp;lt;ThAddmmBackward object at 0x0000019C0C365A58&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&amp;lt;ExpandBackward object at 0x0000019C0C3659E8&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;反向传播&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#反向传播&#34;&gt;#&lt;/a&gt; &lt;strong&gt;反向传播&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;反向传播的实现只需要调用  &lt;code&gt;loss.backward()&lt;/code&gt;  即可，当然首先需要清空当前梯度缓存，即 &lt;code&gt;.zero_grad()&lt;/code&gt;  方法，否则之前的梯度会累加到当前的梯度，这样会影响权值参数的更新。&lt;/p&gt;
&lt;p&gt;下面是一个简单的例子，以  &lt;code&gt;conv1&lt;/code&gt;  层的偏置参数  &lt;code&gt;bias&lt;/code&gt;  在反向传播前后的结果为例：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 清空所有参数的梯度缓存&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;conv1.bias.grad before backward&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net.conv1.bias.grad)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;conv1.bias.grad after backward&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net.conv1.bias.grad)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conv1.bias.grad before backward&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensor([0., 0., 0., 0., 0., 0.])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;conv1.bias.grad after backward&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensor([ 0.0069,  0.0021,  0.0090, -0.0060, -0.0008, -0.0073])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;了解更多有关  &lt;code&gt;torch.nn&lt;/code&gt;  库，可以查看官方文档：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9ubi5odG1s&#34;&gt;https://pytorch.org/docs/stable/nn.html&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;更新权重&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#更新权重&#34;&gt;#&lt;/a&gt; &lt;strong&gt;更新权重&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;采用随机梯度下降 (Stochastic Gradient Descent, SGD) 方法的最简单的更新权重规则如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;weight = weight - learning_rate * gradient&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;按照这个规则，代码实现如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 简单实现权重的更新例子&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;learning_rate = 0.01&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;for f in net.parameters():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.data.sub_(f.grad.data * learning_rate)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;但是这只是最简单的规则，深度学习有很多的优化算法，不仅仅是  &lt;code&gt;SGD&lt;/code&gt; ，还有  &lt;code&gt;Nesterov-SGD, Adam, RMSProp&lt;/code&gt;  等等，为了采用这些不同的方法，这里采用  &lt;code&gt;torch.optim&lt;/code&gt;  库，使用例子如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch.optim as optim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 创建优化器&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(net.parameters(), lr=0.01)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 在训练过程中执行下列操作&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer.zero_grad() # 清空梯度缓存&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = net(input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = criterion(output, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 更新权重&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;，同样需要调用  &lt;code&gt;optimizer.zero_grad()&lt;/code&gt;  方法清空梯度缓存。&lt;/p&gt;
&lt;p&gt;本小节教程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvYmxpdHovbmV1cmFsX25ldHdvcmtzX3R1dG9yaWFsLmh0bWw=&#34;&gt;https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;本小节的代码：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL2NjYzAxMy9EZWVwTGVhcm5pbmdfTm90ZXMvYmxvYi9tYXN0ZXIvUHl0b3JjaC9wcmFjdGlzZS9uZXVyYWxfbmV0d29yay5pcHluYg==&#34;&gt;https://github.com/ccc013/DeepLearning_Notes/blob/master/Pytorch/practise/neural_network.ipynb&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;训练分类器&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#训练分类器&#34;&gt;#&lt;/a&gt; &lt;strong&gt;训练分类器&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;上一节介绍了如何构建神经网络、计算  &lt;code&gt;loss&lt;/code&gt;  和更新网络的权值参数，接下来需要做的就是实现一个图片分类器。&lt;/p&gt;
&lt;h4 id=&#34;训练数据&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#训练数据&#34;&gt;#&lt;/a&gt; &lt;strong&gt;训练数据&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在训练分类器前，当然需要考虑数据的问题。通常在处理如图片、文本、语音或者视频数据的时候，一般都采用标准的 Python 库将其加载并转成 Numpy 数组，然后再转回为 PyTorch 的张量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于图像，可以采用  &lt;code&gt;Pillow, OpenCV&lt;/code&gt;  库；&lt;/li&gt;
&lt;li&gt;对于语音，有  &lt;code&gt;scipy&lt;/code&gt;  和  &lt;code&gt;librosa&lt;/code&gt; ;&lt;/li&gt;
&lt;li&gt;对于文本，可以选择原生 Python 或者 Cython 进行加载数据，或者使用  &lt;code&gt;NLTK&lt;/code&gt;  和  &lt;code&gt;SpaCy&lt;/code&gt;  。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PyTorch 对于计算机视觉，特别创建了一个  &lt;code&gt;torchvision&lt;/code&gt;  的库，它包含一个数据加载器 (data loader)，可以加载比较常见的数据集，比如  &lt;code&gt;Imagenet, CIFAR10, MNIST&lt;/code&gt;  等等，然后还有一个用于图像的数据转换器 (data transformers)，调用的库是  &lt;code&gt;torchvision.datasets&lt;/code&gt;  和  &lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt;  。&lt;/p&gt;
&lt;p&gt;在本教程中，将采用  &lt;code&gt;CIFAR10&lt;/code&gt;  数据集，它包含 10 个类别，分别是飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。数据集中的图片都是  &lt;code&gt;3x32x32&lt;/code&gt; 。一些例子如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic2.zhimg.com/80/v2-2dcc41f9079d1abf5883a113c0d1ca31_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;训练图片分类器&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#训练图片分类器&#34;&gt;#&lt;/a&gt; &lt;strong&gt;训练图片分类器&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;训练流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过调用  &lt;code&gt;torchvision&lt;/code&gt;  加载和归一化  &lt;code&gt;CIFAR10&lt;/code&gt;  训练集和测试集；&lt;/li&gt;
&lt;li&gt;构建一个卷积神经网络；&lt;/li&gt;
&lt;li&gt;定义一个损失函数；&lt;/li&gt;
&lt;li&gt;在训练集上训练网络；&lt;/li&gt;
&lt;li&gt;在测试集上测试网络性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;加载和归一化-cifar10&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#加载和归一化-cifar10&#34;&gt;#&lt;/a&gt; &lt;strong&gt;加载和归一化 CIFAR10&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;首先导入必须的包：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision.transforms &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;`&lt;/p&gt;
&lt;p&gt;&lt;code&gt;torchvision&lt;/code&gt;  的数据集输出的图片都是  &lt;code&gt;PILImage&lt;/code&gt;  ，即取值范围是  &lt;code&gt;[0, 1]&lt;/code&gt;  ，这里需要做一个转换，变成取值范围是  &lt;code&gt;[-1, 1]&lt;/code&gt;  ,&lt;/p&gt;
&lt;p&gt;代码如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 将图片数据从 [0,1] 归一化为 [-1, 1] 的取值范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;transform = transforms.Compose(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [transforms.ToTensor(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     transforms.Normalize((&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;))])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trainset = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;#x27;./data&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                        download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=transform)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trainloader = torch.utils.data.DataLoader(trainset, batch_size=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                          shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;testset = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;#x27;./data&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                       download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=transform)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;testloader = torch.utils.data.DataLoader(testset, batch_size=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                         shuffle=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;classes = (&lt;span class=&#34;string&#34;&gt;&amp;#x27;plane&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;car&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bird&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;cat&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;           &lt;span class=&#34;string&#34;&gt;&amp;#x27;deer&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;dog&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;frog&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;horse&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;ship&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;truck&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里下载好数据后，可以可视化部分训练图片，代码如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 展示图片的函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;imshow&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;img&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    img = img / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; + &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;     &lt;span class=&#34;comment&#34;&gt;# 非归一化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    npimg = img.numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.imshow(np.transpose(npimg, (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 随机获取训练集图片&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dataiter = &lt;span class=&#34;built_in&#34;&gt;iter&lt;/span&gt;(trainloader)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;images, labels = dataiter.&lt;span class=&#34;built_in&#34;&gt;next&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 展示图片&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;imshow(torchvision.utils.make_grid(images))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 打印图片类别标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;.join(&lt;span class=&#34;string&#34;&gt;&amp;#x27;%5s&amp;#x27;&lt;/span&gt; % classes[labels[j]] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;展示图片如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic2.zhimg.com/80/v2-736499796b713d873d1f9ae72fbc66f5_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;其类别标签为：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;frog plane   dog  ship&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;构建一个卷积神经网络&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#构建一个卷积神经网络&#34;&gt;#&lt;/a&gt; &lt;strong&gt;构建一个卷积神经网络&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;这部分内容其实直接采用上一节定义的网络即可，除了修改  &lt;code&gt;conv1&lt;/code&gt;  的输入通道，从 1 变为 3，因为这次接收的是 3 通道的彩色图片。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Net&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Net, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.pool = nn.MaxPool2d(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv2 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc1 = nn.Linear(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc2 = nn.Linear(&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc3 = nn.Linear(&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.pool(F.relu(self.conv1(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.pool(F.relu(self.conv2(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = x.view(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(self.fc1(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(self.fc2(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.fc3(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = Net()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;定义损失函数和优化器&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#定义损失函数和优化器&#34;&gt;#&lt;/a&gt; &lt;strong&gt;定义损失函数和优化器&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;这里采用&lt;strong&gt;类别交叉熵函数&lt;/strong&gt;和&lt;strong&gt;带有动量的 SGD 优化方法：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.optim &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; optim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;criterion = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(net.parameters(), lr=&lt;span class=&#34;number&#34;&gt;0.001&lt;/span&gt;, momentum=&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;训练网络&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#训练网络&#34;&gt;#&lt;/a&gt; &lt;strong&gt;训练网络&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;第四步自然就是开始训练网络，指定需要迭代的 epoch，然后输入数据，指定次数打印当前网络的信息，比如  &lt;code&gt;loss&lt;/code&gt;  或者准确率等性能评价标准。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; time&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;start = time.time()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    running_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(trainloader, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 获取输入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        inputs, labels = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 清空梯度缓存&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs = net(inputs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = criterion(outputs, labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 打印统计信息&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        running_loss += loss.item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i % &lt;span class=&#34;number&#34;&gt;2000&lt;/span&gt; == &lt;span class=&#34;number&#34;&gt;1999&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 每 2000 次迭代打印一次信息&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;[%d, %5d] loss: %.3f&amp;#x27;&lt;/span&gt; % (epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, i+&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, running_loss / &lt;span class=&#34;number&#34;&gt;2000&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            running_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Finished Training! Total cost time: &amp;#x27;&lt;/span&gt;, time.time()-start)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里定义训练总共 2 个 epoch，训练信息如下，大概耗时为 77s。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[1,  2000] loss: 2.226&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[1,  4000] loss: 1.897&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[1,  6000] loss: 1.725&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[1,  8000] loss: 1.617&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[1, 10000] loss: 1.524&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[1, 12000] loss: 1.489&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[2,  2000] loss: 1.407&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[2,  4000] loss: 1.376&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[2,  6000] loss: 1.354&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[2,  8000] loss: 1.347&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[2, 10000] loss: 1.324&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[2, 12000] loss: 1.311&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Finished Training! Total cost time:  77.24696755409241&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;测试模型性能&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#测试模型性能&#34;&gt;#&lt;/a&gt; &lt;strong&gt;测试模型性能&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;训练好一个网络模型后，就需要用测试集进行测试，检验网络模型的泛化能力。对于图像分类任务来说，一般就是用准确率作为评价标准。&lt;/p&gt;
&lt;p&gt;首先，我们先用一个  &lt;code&gt;batch&lt;/code&gt;  的图片进行小小测试，这里  &lt;code&gt;batch=4&lt;/code&gt;  ，也就是 4 张图片，代码如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;dataiter = iter(testloader)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;images, labels = dataiter.next()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 打印图片&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;imshow(torchvision.utils.make_grid(images))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;GroundTruth: &amp;#x27;, &amp;#x27; &amp;#x27;.join(&amp;#x27;%5s&amp;#x27; % classes[labels[j]] for j in range(4)))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;图片和标签分别如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://pic4.zhimg.com/80/v2-ddb522e45f298b8da5ab6d3a48ac470b_1440w.webp&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;GroundTruth:    cat  ship  ship plane&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后用这四张图片输入网络，看看网络的预测结果：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# 网络输出&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;outputs = net(images)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 预测结果&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;_, predicted = torch.max(outputs, 1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;Predicted: &amp;#x27;, &amp;#x27; &amp;#x27;.join(&amp;#x27;%5s&amp;#x27; % classes[predicted[j]] for j in range(4)))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出为：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Predicted:    cat  ship  ship  ship&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;前面三张图片都预测正确了，第四张图片错误预测飞机为船。&lt;/p&gt;
&lt;p&gt;接着，让我们看看在整个测试集上的准确率可以达到多少吧！&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;correct = 0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;total = 0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;with torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    for data in testloader:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        images, labels = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs = net(images)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        _, predicted = torch.max(outputs.data, 1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        total += labels.size(0)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        correct += (predicted == labels).sum().item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;Accuracy of the network on the 10000 test images: %d %%&amp;#x27; % (100 * correct / total))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果如下&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of the network on the 10000 test images: 55 %&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里可能准确率并不一定一样，教程中的结果是  &lt;code&gt;51%&lt;/code&gt;  ，因为权重初始化问题，可能多少有些浮动，相比随机猜测 10 个类别的准确率 (即 10%)，这个结果是不错的，当然实际上是非常不好，不过我们仅仅采用 5 层网络，而且仅仅作为教程的一个示例代码。&lt;/p&gt;
&lt;p&gt;然后，还可以再进一步，查看每个类别的分类准确率，跟上述代码有所不同的是，计算准确率部分是  &lt;code&gt;c = (predicted == labels).squeeze()&lt;/code&gt; ，这段代码其实会根据预测和真实标签是否相等，输出 1 或者 0，表示真或者假，因此在计算当前类别正确预测数&lt;/p&gt;
&lt;p&gt;量时候直接相加，预测正确自然就是加 1，错误就是加 0，也就是没有变化。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;class_correct = list(0. for i in range(10))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;class_total = list(0. for i in range(10))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;with torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    for data in testloader:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        images, labels = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs = net(images)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        _, predicted = torch.max(outputs, 1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c = (predicted == labels).squeeze()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        for i in range(4):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            label = labels[i]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            class_correct[label] += c[i].item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            class_total[label] += 1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;for i in range(10):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    print(&amp;#x27;Accuracy of %5s : %2d %%&amp;#x27; % (classes[i], 100 * class_correct[i] / class_total[i]))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果，可以看到猫、鸟、鹿是错误率前三，即预测最不准确的三个类别，反倒是船和卡车最准确。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of plane : 58 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of   car : 59 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of  bird : 40 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of   cat : 33 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of  deer : 39 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of   dog : 60 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of  frog : 54 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of horse : 66 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of  ship : 70 %&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Accuracy of truck : 72 %&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;在-gpu-上训练&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#在-gpu-上训练&#34;&gt;#&lt;/a&gt; &lt;strong&gt;在 GPU 上训练&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;深度学习自然需要 GPU 来加快训练速度的。所以接下来介绍如果是在 GPU 上训练，应该如何实现。&lt;/p&gt;
&lt;p&gt;首先，需要检查是否有可用的 GPU 来训练，代码如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&amp;quot;cuda:0&amp;quot; if torch.cuda.is_available() else &amp;quot;cpu&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出结果如下，这表明你的第一块 GPU 显卡或者唯一的 GPU 显卡是空闲可用状态，否则会打印  &lt;code&gt;cpu&lt;/code&gt;  。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;cuda:0&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;既然有可用的 GPU ，接下来就是在 GPU 上进行训练了，其中需要修改的代码如下，分别是需要将网络参数和数据都转移到 GPU 上：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;inputs, labels = inputs.to(device), labels.to(device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;修改后的训练部分代码：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import time&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# 在 GPU 上训练注意需要将网络和数据放到 GPU 上&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;criterion = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;start = time.time()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;for epoch in range(2):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    running_loss = 0.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    for i, data in enumerate(trainloader, 0):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 获取输入数据&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        inputs, labels = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        inputs, labels = inputs.to(device), labels.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 清空梯度缓存&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs = net(inputs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = criterion(outputs, labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 打印统计信息&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        running_loss += loss.item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        if i % 2000 == 1999:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            # 每 2000 次迭代打印一次信息&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            print(&amp;#x27;[%d, %5d] loss: %.3f&amp;#x27; % (epoch + 1, i+1, running_loss / 2000))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            running_loss = 0.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(&amp;#x27;Finished Training! Total cost time: &amp;#x27;, time.time() - start)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;注意，这里调用  &lt;code&gt;net.to(device)&lt;/code&gt;  后，需要定义下优化器，即传入的是 CUDA 张量的网络参数。训练结果和之前的类似，而且其实因为这个网络非常小，转移到 GPU 上并不会有多大的速度提升，而且我的训练结果看来反而变慢了，也可能是因为我的笔记本的 GPU 显卡问题。&lt;/p&gt;
&lt;p&gt;如果需要进一步提升速度，可以考虑采用多 GPUs，也就是下一节的内容。&lt;/p&gt;
&lt;p&gt;本小节教程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvYmxpdHovY2lmYXIxMF90dXRvcmlhbC5odG1s&#34;&gt;https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;本小节的代码：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL2NjYzAxMy9EZWVwTGVhcm5pbmdfTm90ZXMvYmxvYi9tYXN0ZXIvUHl0b3JjaC9wcmFjdGlzZS90cmFpbl9jbGFzc2lmaWVyX2V4YW1wbGUuaXB5bmI=&#34;&gt;https://github.com/ccc013/DeepLearning_Notes/blob/master/Pytorch/practise/train_classifier_example.ipynb&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据并行&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#数据并行&#34;&gt;#&lt;/a&gt; &lt;strong&gt;数据并行&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;这部分教程将学习如何使用  &lt;code&gt;DataParallel&lt;/code&gt;  来使用多个 GPUs 训练网络。&lt;/p&gt;
&lt;p&gt;首先，在 GPU 上训练模型的做法很简单，如下代码所示，定义一个  &lt;code&gt;device&lt;/code&gt;  对象，然后用  &lt;code&gt;.to()&lt;/code&gt;  方法将网络模型参数放到指定的 GPU 上。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&amp;quot;cuda:0&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.to(device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;接着就是将所有的张量变量放到 GPU 上：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;mytensor = my_tensor.to(device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;注意，这里  &lt;code&gt;my_tensor.to(device)&lt;/code&gt;  是返回一个  &lt;code&gt;my_tensor&lt;/code&gt;  的新的拷贝对象，而不是直接修改  &lt;code&gt;my_tensor&lt;/code&gt;  变量，因此你需要将其赋值给一个新的张量，然后使用这个张量。&lt;/p&gt;
&lt;p&gt;Pytorch 默认只会采用一个 GPU，因此需要使用多个 GPU，需要采用  &lt;code&gt;DataParallel&lt;/code&gt;  ，代码如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;model = nn.DataParallel(model)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这代码也就是本节教程的关键，接下来会继续详细介绍。&lt;/p&gt;
&lt;h3 id=&#34;导入和参数&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#导入和参数&#34;&gt;#&lt;/a&gt; &lt;strong&gt;导入和参数&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;首先导入必须的库以及定义一些参数：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;import torch.nn as nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;from torch.utils.data import Dataset, DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;# Parameters and DataLoaders&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;input_size = 5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output_size = 2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = 30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_size = 100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&amp;quot;cuda:0&amp;quot; if torch.cuda.is_available() else &amp;quot;cpu&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里主要定义网络输入大小和输出大小， &lt;code&gt;batch&lt;/code&gt;  以及图片的大小，并定义了一个  &lt;code&gt;device&lt;/code&gt;  对象。&lt;/p&gt;
&lt;h3 id=&#34;构建一个假数据集&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#构建一个假数据集&#34;&gt;#&lt;/a&gt; &lt;strong&gt;构建一个假数据集&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;接着就是构建一个假的 (随机) 数据集。实现代码如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;class RandomDataset(Dataset):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def __init__(self, size, length):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.len = length&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.data = torch.randn(length, size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def __getitem__(self, index):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        return self.data[index]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def __len__(self):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        return self.len&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                         batch_size=batch_size, shuffle=True)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;简单的模型&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#简单的模型&#34;&gt;#&lt;/a&gt; &lt;strong&gt;简单的模型&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;接下来构建一个简单的网络模型，仅仅包含一层全连接层的神经网络，加入  &lt;code&gt;print()&lt;/code&gt;  函数用于监控网络输入和输出  &lt;code&gt;tensors&lt;/code&gt;  的大小：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;class Model(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    # Our model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def __init__(self, input_size, output_size):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        super(Model, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc = nn.Linear(input_size, output_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def forward(self, input):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.fc(input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        print(&amp;quot;\tIn Model: input size&amp;quot;, input.size(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;              &amp;quot;output size&amp;quot;, output.size())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        return output&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;创建模型和数据平行&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建模型和数据平行&#34;&gt;#&lt;/a&gt; &lt;strong&gt;创建模型和数据平行&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;这是本节的核心部分。首先需要定义一个模型实例，并且检查是否拥有多个 GPUs，如果是就可以将模型包裹在  &lt;code&gt;nn.DataParallel&lt;/code&gt;  ，并调用  &lt;code&gt;model.to(device)&lt;/code&gt;  。代码如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;model = Model(input_size, output_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;if torch.cuda.device_count() &amp;gt; 1:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  print(&amp;quot;Let&amp;#x27;s use&amp;quot;, torch.cuda.device_count(), &amp;quot;GPUs!&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  # dim = 0 [30, xxx] -&amp;gt; [10, ...], [10, ...], [10, ...] on 3 GPUs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  model = nn.DataParallel(model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.to(device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;运行模型&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#运行模型&#34;&gt;#&lt;/a&gt; &lt;strong&gt;运行模型&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;接着就可以运行模型，看看打印的信息：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;for data in rand_loader:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    input = data.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = model(input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    print(&amp;quot;Outside: input size&amp;quot;, input.size(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          &amp;quot;output_size&amp;quot;, output.size())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;运行结果&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#运行结果&#34;&gt;#&lt;/a&gt; &lt;strong&gt;运行结果&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;如果仅仅只有 1 个或者没有 GPU ，那么  &lt;code&gt;batch=30&lt;/code&gt;  的时候，模型会得到输入输出的大小都是 30。但如果有多个 GPUs，那么结果如下：&lt;/p&gt;
&lt;h3 id=&#34;2-gpus&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-gpus&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2 GPUs&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# on 2 GPUs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Let&amp;#x27;s use 2 GPUs!&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-gpus&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-gpus&#34;&gt;#&lt;/a&gt; &lt;strong&gt;3 GPUs&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Let&amp;#x27;s use 3 GPUs!&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;8-gpus&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#8-gpus&#34;&gt;#&lt;/a&gt; &lt;strong&gt;8 GPUs&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Let&amp;#x27;s use 8 GPUs!&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#总结&#34;&gt;#&lt;/a&gt; &lt;strong&gt;总结&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;DataParallel&lt;/code&gt;  会自动分割数据集并发送任务给多个 GPUs 上的多个模型。然后等待每个模型都完成各自的工作后，它又会收集并融合结果，然后返回。&lt;/p&gt;
&lt;p&gt;更详细的数据并行教程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvZm9ybWVyX3RvcmNoaWVzL3BhcmFsbGVsaXNtX3R1dG9yaWFsLmh0bWw=&#34;&gt;https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;本小节教程：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy90dXRvcmlhbHMvYmVnaW5uZXIvYmxpdHovZGF0YV9wYXJhbGxlbF90dXRvcmlhbC5odG1s&#34;&gt;https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;小结&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#小结&#34;&gt;#&lt;/a&gt; &lt;strong&gt;小结&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;教程从最基础的张量开始介绍，然后介绍了非常重要的自动求梯度的  &lt;code&gt;autograd&lt;/code&gt;  ，接着介绍如何构建一个神经网络，如何训练图像分类器，最后简单介绍使用多 GPUs 加快训练速度的方法。&lt;/p&gt;
&lt;p&gt;快速入门教程就介绍完了，接下来你可以选择：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy90dXRvcmlhbHMvaW50ZXJtZWRpYXRlL3JlaW5mb3JjZW1lbnRfcV9sZWFybmluZy5odG1s&#34;&gt;训练一个神经网络来玩视频游戏&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL3B5dG9yY2gvZXhhbXBsZXMvdHJlZS9tYXN0ZXIvaW1hZ2VuZXQ=&#34;&gt;在 imagenet 上训练 ResNet&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL3B5dG9yY2gvZXhhbXBsZXMvdHJlZS9tYXN0ZXIvZGNnYW4=&#34;&gt;采用 GAN 训练一个人脸生成器&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL3B5dG9yY2gvZXhhbXBsZXMvdHJlZS9tYXN0ZXIvd29yZF9sYW5ndWFnZV9tb2RlbA==&#34;&gt;采用循环 LSTM 网络训练一个词语级别的语言模型&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9naXRodWIuY29tL3B5dG9yY2gvZXhhbXBsZXM=&#34;&gt;更多的例子&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9weXRvcmNoLm9yZy90dXRvcmlhbHM=&#34;&gt;更多的教程&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHBzJTNBLy9kaXNjdXNzLnB5dG9yY2gub3JnLw==&#34;&gt;在 Forums 社区讨论 PyTorch&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;项目练习手写数字识别练习mnist&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#项目练习手写数字识别练习mnist&#34;&gt;#&lt;/a&gt; 项目练习：手写数字识别练习 MNIST&lt;/h2&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240210153152886.png&#34; alt=&#34;image-20240210153152886&#34; /&gt;&lt;/p&gt;
&lt;p&gt;softmax 归一化&lt;/p&gt;
&lt;p&gt;梯度下降法等调参&lt;/p&gt;
&lt;p&gt;一批次一批次的训练：一个批次一个 batch&lt;/p&gt;
&lt;p&gt;神经网络过程是线性的，需要非线性结果&lt;/p&gt;
&lt;p&gt;在每个节点上再套上一个非线性函数 f (), 又称激活函数&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;(&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo fence=&#34;true&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x_j^{k+1} = \sum_i f\left(a_{i,j}^k \cdot x_i^k + b_{i,j}^k\right)
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.3022109999999998em;vertical-align:-0.403103em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8991079999999999em;&#34;&gt;&lt;span style=&#34;top:-2.4330050000000005em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.403103em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.327674em;vertical-align:-1.277669em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.0500050000000003em;&#34;&gt;&lt;span style=&#34;top:-1.872331em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.050005em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.277669em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.899108em;&#34;&gt;&lt;span style=&#34;top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mpunct mtight&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.1130000000000004em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.383108em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;⋅&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8991079999999998em;&#34;&gt;&lt;span style=&#34;top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.247em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.899108em;&#34;&gt;&lt;span style=&#34;top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mpunct mtight&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.1130000000000004em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.383108em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240210153529250.png&#34; alt=&#34;image-20240210153529250&#34; /&gt;&lt;/p&gt;
&lt;p&gt;同时安装四个库&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install numpy torch torchvision matplotlib&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;手写数字识别练习&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;#定义一个神经网络&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;class Net(torch.nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	def __init__(self):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		#神经网络主体，包含四个全连接层&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		super().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		self.fc1 = torch.nn.Linear(28*28,64) #输入为28*28像素尺寸的图像&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		self.fc2 = torch.nn.Linear(64,64)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		self.fc3 = torch.nn.Linear(64,64)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		self.fc4 = torch.nn.Linear(64,10)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	#中间3层都放了64个节点，输出为10个数字类别&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	def forward(self,x): #x图像输入&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		x = torch.nn.functional.relu(self.fc1(x) )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		x = torch.nn.functional.relu(self.fc2(x) )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		x = torch.nn.functional.relu(self.fc3(x) )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		x = torch.nn.functional.log_softmax(self.fc3(x),dim=1)#提高计算稳定性&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		return x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	#导入数据&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	def get_data_loader(is_train):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		#定义数据转换类型&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		to_tensor = transforms.Compose([transforms,ToTensor()])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		data_set = MNIST(&amp;quot;&amp;quot;,is_train,transform=to_tensor,download = True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		return DataLoader(data_set,batch_size=15,shuffle=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	def evaluate(test_data,net):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		n_correct = 0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		n_total = 0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		with torch.no_grad(): 	#从测试集中按批次取出数据&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;			for(x,y) in test_data:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				outputs = net.forward(x,view(-1,28*28))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				for i,output in enumerate(outputs) :&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;					if torch.argmax(output) == y[i] :&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;						n_correct += 1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;					n_total += 1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		return n_correct / n_total #返回正确率&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	def main():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		train_data = get_data_loader(is_train=True)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		test_data = get_data_loader(is_train=False)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		net = Net()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		print(&amp;quot;initial accuracy:&amp;quot;,evaluate(test_data,net))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		#训练model Pytorch固定写法&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		optimizer = torch.optim.Adam(net.parameters(),lr=0.001)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		for epoch in range(2):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;			for(x,y) in train_data:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				net.zero_grad() #初始化&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				output = net.forward(x,view(-1,28*28 )) #正向传播&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				loss = torch.nn.functional.nll_loss(output,y) #计算差值&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				loss.backward() #反向误差传播&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				optimizer.step() #优化网络参数&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;				#&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;			print(&amp;quot;epoch&amp;quot;,epoch,&amp;quot;accuracy:&amp;quot;,evaluate(test_data,net))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		#如果一切正常，训练率会越来越高&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		#训练完成后，随机选取三张图像，显示网络预测结果&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        for (n, (x, _ )) in enumerate(test_data):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        	if n &amp;gt; 3:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        		break&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        	predict = torch.argmax(net.forward(x[0].view(-1,28*28)) )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        	plt.figure(n)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        	plt.imshow(x[0].view(28,28))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        	plt.title(&amp;quot;prediction: &amp;quot;+str(int(predict) ) )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;   		plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	if __name__ == &amp;quot;__main__&amp;quot;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;		main()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;注释版&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;import torch.nn as nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;import torch.nn.functional as F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;class Net(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def __init__(self):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        super(Net,self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 定义第一个卷积层，输入通道为1（单通道图像，如灰度图），输出通道为6，使用5*5的卷积核&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(1, 6, 5)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 第二个卷积层，输入通道为6（由于第一个卷积层的输出是6），输出通道为16，同样使用5*5的卷积核&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 注意：这里的定义缺失了，应该在`__init__`方法中添加self.conv2的定义&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 全连接层（fc1）的定义，输入特征维度为16*5*5（假设经过两次卷积和池化后的特征图大小），输出特征维度为120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc1 = nn.Linear(16*5*5, 120)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 第二个全连接层，输入特征维度为120，输出特征维度为84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc2 = nn.Linear(120, 84)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 第三个全连接层，输入特征维度为84，输出特征维度为10（假设为分类问题的类别数）&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc3 = nn.Linear(84, 10)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def forward(self, x):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 应用第一个卷积层后使用ReLU激活函数，然后进行2x2的最大池化&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 应用第二个卷积层，同样使用ReLU激活函数和2x2的最大池化&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 注意：这里需要确保conv2在`__init__`方法中被定义&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.max_pool2d(F.relu(self.conv2(x)), 2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 将多维输入张量展平成一维，准备输入到全连接层&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = x.view(-1, self.num_flat_features(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 第一个全连接层后使用ReLU激活函数&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(self.fc1(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 第二个全连接层同样使用ReLU激活函数&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(self.fc2(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 最后一个全连接层输出最终结果，这里不使用激活函数是因为后续可能接softmax进行分类&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.fc3(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        return x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    def num_flat_features(self, x):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        # 计算除batch维度外的所有维度乘积，即在全连接层之前需要展平的特征数量&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        size = x.size()[1:]  # 所有维度除了batch维度&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        num_features = 1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        for s in size:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            num_features *= s&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        return num_features&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = Net()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(net)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这段代码定义了一个简单的卷积神经网络，包含两个卷积层和三个全连接层。它演示了在 PyTorch 中如何构建网络、应用卷积、激活函数、池化以及全连接层。注意，代码中确实漏掉了 &lt;code&gt;self.conv2&lt;/code&gt;  的定义，这是必须添加的部分以确保网络能够正常工作。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;forward&lt;/code&gt;  前向传输&lt;br /&gt;
全连接线性运算 self.fc1 (x) 再套上激活函数 x 为图像输入&lt;/p&gt;
&lt;p&gt;第一个参数表示下载目录，&amp;quot;&amp;quot; 空表示当前目录&lt;/p&gt;
&lt;p&gt;&lt;code&gt;is_train&lt;/code&gt;  用于指定导入训练集还是测试集&lt;/p&gt;
&lt;p&gt;&lt;code&gt;batch_size=15&lt;/code&gt;  表示一个批次包含 15 张图片&lt;/p&gt;
&lt;p&gt;&lt;code&gt;shuffle=True&lt;/code&gt;  表示打乱顺序&lt;/p&gt;
&lt;p&gt;返回数据加载器 &lt;code&gt;DataLoader&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;evaluate&lt;/code&gt;  函数用来评估神经网络的识别正确率&lt;/p&gt;
&lt;p&gt;从测试集中按批次取出数据，计算神经网路的预测值&lt;/p&gt;
&lt;p&gt;再对批次中的每个结果进行比较，累加正确预测的数量&lt;/p&gt;
&lt;p&gt;nll_loss 对数损失函数&lt;/p&gt;
&lt;p&gt;是 log_softmax 中的对数运算&lt;/p&gt;
&lt;p&gt;epoch 训练伦次，提高数据利用率&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/10/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E7%AB%A0%E2%80%94%E2%80%94%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%89%E8%A3%85/</guid>
            <title>PyTorch学习第一章——简介与安装</title>
            <link>https://jinjiaojiao.top/2024/02/10/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E7%AB%A0%E2%80%94%E2%80%94%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%89%E8%A3%85/</link>
            <category term="PyTorch学习" scheme="https://jinjiaojiao.top/categories/PyTorch%E5%AD%A6%E4%B9%A0/" />
            <category term="PyTorch学习" scheme="https://jinjiaojiao.top/tags/PyTorch%E5%AD%A6%E4%B9%A0/" />
            <pubDate>Sat, 10 Feb 2024 14:15:33 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;学习参考项目：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL2ZlbmRvdWFpL1B5VG9yY2hEb2NzL3RyZWUvbWFzdGVy&#34;&gt;https://github.com/fendouai/PyTorchDocs/tree/master&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;处于学习阶段，内容几乎全部上述文档，仅进行归纳整理与加上自己的部分理解，特此声明。&lt;/p&gt;
&lt;h1 id=&#34;第一章-pytorch之简介与下载&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#第一章-pytorch之简介与下载&#34;&gt;#&lt;/a&gt; 第一章 PyTorch 之简介与下载&lt;/h1&gt;
&lt;h2 id=&#34;pytorch简介&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#pytorch简介&#34;&gt;#&lt;/a&gt; Pytorch 简介&lt;/h2&gt;
&lt;p&gt;要介绍 &lt;code&gt;PyTorch&lt;/code&gt;  之前，不得不说一下 &lt;code&gt;Torch&lt;/code&gt; 。 &lt;code&gt;Torch&lt;/code&gt;  是一个有大量机器学习算法支持的科学计算框架，是一个与 &lt;code&gt;Numpy&lt;/code&gt;  类似的张量（ &lt;code&gt;Tensor&lt;/code&gt; ）&lt;br /&gt;
操作库，其特点是特别灵活，但因其采用了小众的编程语言是 &lt;code&gt;Lua&lt;/code&gt; ，所以流行度不高，这也就有了 &lt;code&gt;PyTorch&lt;/code&gt;  的出现。所以其实 &lt;code&gt;Torch&lt;/code&gt;  是 &lt;code&gt;PyTorch&lt;/code&gt;  的前身，它们的底层语言相同，只是使用了不同的 &lt;code&gt;上层包装语言&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;PyTorch&lt;/code&gt;  是一个基于 Torch 的 Python&lt;strong&gt; 开源机器学习库&lt;/strong&gt;，用于自然语言处理等应用程序。&lt;/p&gt;
&lt;p&gt;它主要由 &lt;code&gt;Facebook&lt;/code&gt;  的人工智能小组开发，不仅能够实现强大的 &lt;code&gt;GPU&lt;/code&gt;  加速，同时还支持动态神经网络，这一点是现在很多主流框架如 &lt;code&gt;TensorFlow&lt;/code&gt;  都不支持的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;code&gt;PyTorch&lt;/code&gt;  提供了两个高级功能：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;具有强大的 &lt;code&gt;GPU&lt;/code&gt;  加速的张量计算（如 &lt;code&gt;Numpy&lt;/code&gt; ）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;包含自动求导系统的深度神经网络&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;TensorFlow&lt;/code&gt;  和 &lt;code&gt;Caffe&lt;/code&gt;  都是&lt;strong&gt;命令式&lt;/strong&gt;的编程语言，而且是&lt;strong&gt;静态&lt;/strong&gt;的，首先必须构建一个神经网络，然后一次又一次使用相同的结构，如果想要改变网络的结构，就必须&lt;strong&gt;从头开始&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;但是对于 &lt;code&gt;PyTorch&lt;/code&gt; ，通过&lt;strong&gt;反向求导&lt;/strong&gt;技术，可以让你零延迟地任意改变神经网络的行为，而且其实现速度快。正是这一灵活性是 &lt;code&gt;PyTorch&lt;/code&gt;  对比 &lt;code&gt;TensorFlow&lt;/code&gt;  的最大优势。&lt;/p&gt;
&lt;p&gt;所以，总结一下 PyTorch 的优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持 GPU&lt;/li&gt;
&lt;li&gt;灵活，支持动态神经网络&lt;/li&gt;
&lt;li&gt;底层代码易于理解&lt;/li&gt;
&lt;li&gt;命令式体验&lt;/li&gt;
&lt;li&gt;自定义扩展&lt;/li&gt;
&lt;li&gt;少量代码就能完成机器学习任务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;缺点：对比 &lt;code&gt;TensorFlow&lt;/code&gt; ，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其全面性处于劣势，目前 PyTorch 还不支持快速傅里叶、沿维翻转张量和检查无穷与非数值张量；&lt;/li&gt;
&lt;li&gt;针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；&lt;/li&gt;
&lt;li&gt;框架较新，社区没有那么强大，C 库大多数没有文档。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pytorch环境搭建&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#pytorch环境搭建&#34;&gt;#&lt;/a&gt;  &lt;code&gt;Pytorch&lt;/code&gt;  环境搭建&lt;/h2&gt;
&lt;h3 id=&#34;1-安装anaconda-35&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-安装anaconda-35&#34;&gt;#&lt;/a&gt; 1. 安装 Anaconda 3.5&lt;/h3&gt;
&lt;p&gt;Anaconda 是一个用于科学计算的 Python 发行版，支持 Linux、Mac 和 Window 系统，提供了包管理与环境管理的功能，可以很方便地解决 Python 并存、切换，以及各种第三方包安装的问题。&lt;/p&gt;
&lt;h4 id=&#34;下载&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#下载&#34;&gt;#&lt;/a&gt; 下载：&lt;/h4&gt;
&lt;p&gt;可以直接从 &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuY29udGludXVtLmlvL2Rvd25sb2Fkcw==&#34;&gt;Anaconda 官网&lt;/span&gt;下载，但因为 Anaconda 的服务器在国外，所以下载速度会很慢，这里推荐使用&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2FuYWNvbmRhL2FyY2hpdmUv&#34;&gt;清华的镜像&lt;/span&gt;来下载。选择合适你的版本下载，我这里选择&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2FuYWNvbmRhL2FyY2hpdmUvQW5hY29uZGEzLTUuMS4wLVdpbmRvd3MteDg2XzY0LmV4ZQ==&#34;&gt; Anaconda3-5.1.0-Windows-x86_64.exe&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&#34;安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装&#34;&gt;#&lt;/a&gt; 安装：&lt;/h4&gt;
&lt;p&gt;安装完成后，进行 Anaconda 的环境变量配置，打开控制面板 -&amp;gt; 高级系统设置 -&amp;gt; 环境变量 -&amp;gt; 系统变量找到 Path，点击编辑，加入三个文件夹的存储路径（注意三个路径之间需用分号隔开）&lt;/p&gt;
&lt;h3 id=&#34;2安装pytorch-torchvision&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2安装pytorch-torchvision&#34;&gt;#&lt;/a&gt; 2. 安装 PyTorch &amp;amp; torchvision&lt;/h3&gt;
&lt;h4 id=&#34;命令获取&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#命令获取&#34;&gt;#&lt;/a&gt; 命令获取&lt;/h4&gt;
&lt;p&gt;进入 &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9weXRvcmNoLm9yZy8=&#34;&gt;PyTorch 官网&lt;/span&gt;，依次选择你电脑的配置（我这里已经下载了 python3.7），这里提供使用 pip 和 conda 两种环境下安装的步骤截图&lt;/p&gt;
&lt;p&gt;(1) 使用 pip：windows+pip+python3.7+None&lt;/p&gt;
&lt;p&gt;(2) 使用 conda：windows+conda+python3.7+None&lt;/p&gt;
&lt;h5 id=&#34;建议参照官网这里没有拷贝下来&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#建议参照官网这里没有拷贝下来&#34;&gt;#&lt;/a&gt; （建议参照官网）这里没有拷贝下来&lt;/h5&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://jinjiaojiao.top/2024/02/07/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</guid>
            <title>复盘in2vec</title>
            <link>https://jinjiaojiao.top/2024/02/07/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</link>
            <category term="AI复盘" scheme="https://jinjiaojiao.top/categories/AI%E5%A4%8D%E7%9B%98/" />
            <pubDate>Wed, 07 Feb 2024 13:26:07 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;2024-2-7&lt;/p&gt;
&lt;p&gt;复盘：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL0NWTEFCLVVuaWJvL2lucjJ2ZWM/dGFiPXJlYWRtZS1vdi1maWxl&#34;&gt;https://github.com/CVLAB-Unibo/inr2vec?tab=readme-ov-file&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#前言&#34;&gt;#&lt;/a&gt; 前言&lt;/h2&gt;
&lt;p&gt;用的阿里云服务器&lt;/p&gt;
&lt;p&gt;vscode-&amp;gt; 先下载扩展 remote-ssh&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;#ssh username@公有ip&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;username 经常是root&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;.config 选一个本地的 我就是第一个C:/29785/.config 差不多这个&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Linux&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;password:输入你自己的&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;进入终端&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;mkdir cs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cd cs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mkdir in2vec&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;发现没 conda&lt;/p&gt;
&lt;h2 id=&#34;服务器安装anaconda&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#服务器安装anaconda&#34;&gt;#&lt;/a&gt; 服务器安装 anaconda&lt;/h2&gt;
&lt;h4 id=&#34;下载anaconda&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#下载anaconda&#34;&gt;#&lt;/a&gt; 下载 anaconda&lt;/h4&gt;
&lt;p&gt;后面的链接可以去官网查找自己适合的版本&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;wget https://repo.anaconda.com/archive/Anaconda3-5.3.0-Linux-x86_64.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;.sh 为 Linux 后缀&lt;/p&gt;
&lt;p&gt;——————————————————&lt;/p&gt;
&lt;p&gt;如果出现&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;bash: wget: command not found&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;具体解决办法如下:&lt;br /&gt;
Debian/Ubuntu 系统，需要执行以下命令：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;apt-get install -y wget&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CentOS 系统则需要输入下面指令:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;yum install wget -y&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;————————————————————&lt;/p&gt;
&lt;h4 id=&#34;赋权anaconda&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#赋权anaconda&#34;&gt;#&lt;/a&gt; 赋权 anaconda&lt;/h4&gt;
&lt;p&gt;接下来我们需要首先赋权再执行安装程序，依次输入下面两句命令:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;chmod +x Anaconda3-5.3.0-Linux-x86_64.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;./Anaconda3-5.3.0-Linux-x86_64.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后出现下面图所示:&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/OKcNDvCVY75lrqe.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;一直点击enter回车键&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#一直点击enter回车键&#34;&gt;#&lt;/a&gt; 一直点击 Enter（回车键）&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/mIkfztbra6cKnYT.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;此时显示 Anaconda 的信息，并且会出现 More，继续按 Enter，直到如下图所示:&lt;/p&gt;
&lt;h4 id=&#34;输入-yes&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#输入-yes&#34;&gt;#&lt;/a&gt; 输入 yes&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/bEM3dxyNGqgoz4K.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;继续点击-enter&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#继续点击-enter&#34;&gt;#&lt;/a&gt; 继续点击 Enter&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/zZvmdlD3Gcahxqu.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;输入-yes添加环境变量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#输入-yes添加环境变量&#34;&gt;#&lt;/a&gt; 输入 yes，添加环境变量&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/yBq74es8zYAwDiC.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;^^^^^^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt;
&lt;p&gt;这里需要注意点的就是如果你直接跳过这部设置环境变量的话：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[no ] &amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;那你需要自己到这个文件夹设置你安装 Anaconda 路径&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;find -name &amp;quot;anaconda3&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;（比如上面显示我的是）&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;./anaconda3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;单击进去，在最后一行添加：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;export PATH=./anaconda3/bin:$PATH&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里只是个示例，具体的还是要看你们自己安装的路径。&lt;/p&gt;
&lt;p&gt;然后保存更改，输入下面这句指令：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;source ~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;—————————————————————&lt;/p&gt;
&lt;h4 id=&#34;完成安装以及检测是否安装成功&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#完成安装以及检测是否安装成功&#34;&gt;#&lt;/a&gt; 完成安装以及检测是否安装成功&lt;/h4&gt;
&lt;p&gt;打开新的终端后，进入自己的文件夹目录下，输入 anaconda -V（注意 a 要小写，V 要大写），conda -V ,&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda -V&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;或者&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;conda --version&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;显示版本信息，若显示则表示安装成功。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;conda 4.5.11&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;anaconda安装pytorch&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#anaconda安装pytorch&#34;&gt;#&lt;/a&gt; Anaconda 安装&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9zby5jc2RuLm5ldC9zby9zZWFyY2g/cT1QeXRvcmNoJmFtcDtzcG09MTAwMS4yMTAxLjMwMDEuNzAyMA==&#34;&gt; Pytorch&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&#34;创建虚拟环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建虚拟环境&#34;&gt;#&lt;/a&gt; 创建虚拟环境&lt;/h3&gt;
&lt;p&gt;第一个程序环境名为 pytorch&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda create -n pytorch python=3.7 （pytorch 是我自己取的名字）&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;激活环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#激活环境&#34;&gt;#&lt;/a&gt; 激活环境&lt;/h3&gt;
&lt;p&gt;使用下面这条命令，激活环境：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda activate pytorch&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;可能出现的问题&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#可能出现的问题&#34;&gt;#&lt;/a&gt; 可能出现的问题&lt;/h3&gt;
&lt;p&gt;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt;
&lt;p&gt;出现下面所示 1：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/yBq74es8zYAwDiC.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;问题出现是因为尽管安装了  &lt;code&gt;Anaconda&lt;/code&gt;  或  &lt;code&gt;Miniconda&lt;/code&gt; ，&lt;/p&gt;
&lt;p&gt;但是你的 shell 环境没有被正确配置以识别  &lt;code&gt;conda&lt;/code&gt;  命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决办法：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;启用  &lt;code&gt;conda&lt;/code&gt;  命令&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果你使用的是 Bash shell 或者类似 Bourne 的 shell，你需要将  &lt;code&gt;conda&lt;/code&gt;  的初始化脚本添加到你的 shell 配置文件中（通常是&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;文件），以便  &lt;code&gt;conda&lt;/code&gt;  命令可以被识别。根据提供的信息，你可以通过运行以下命令来做到这一点：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;echo &amp;quot;. /root/anaconda3/etc/profile.d/conda.sh&amp;quot; &amp;gt;&amp;gt; ~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这会将初始化脚本的路径添加到你的&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;文件中，每次启动新的 shell 会话时都会自动执行这个脚本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;激活  &lt;code&gt;conda&lt;/code&gt;  的基础（root）环境&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;为了使用 &lt;code&gt;conda&lt;/code&gt;  管理你的环境和包，你需要激活  &lt;code&gt;conda&lt;/code&gt;  的基础环境。你可以通过在终端中运行以下命令来做到这一点：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda activate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果你想在每次打开新的终端会话时自动激活  &lt;code&gt;conda&lt;/code&gt;  的基础环境，你可以将上述命令添加到你的&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;文件中：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;echo &amp;quot;conda activate&amp;quot; &amp;gt;&amp;gt; ~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;移除旧的 PATH 设置&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果你之前尝试通过直接修改  &lt;code&gt;PATH&lt;/code&gt;  环境变量来使用  &lt;code&gt;conda&lt;/code&gt; ，你应该从你的&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;文件中移除这样的行：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;export PATH=&amp;quot;/root/anaconda3/bin:$PATH&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这是因为直接修改  &lt;code&gt;PATH&lt;/code&gt;  不再是推荐的方法，使用  &lt;code&gt;conda&lt;/code&gt;  的初始化脚本和  &lt;code&gt;conda activate&lt;/code&gt;  命令是更好的选择。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;完成以上步骤后，关闭并重新打开你的终端，或者运行  &lt;code&gt;source ~/.bashrc&lt;/code&gt;  来使改动生效。这样，你的 shell 环境就被正确配置了，应该能够识别  &lt;code&gt;conda&lt;/code&gt;  命令了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;出现下面所示 2:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;(pytorch) root@dev-wyf-react:~/wyf#&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;检测环境是否安装好:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda info --envs&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;出现下面所示：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;base /root/anaconda3&lt;/code&gt; &lt;br /&gt;
 &lt;code&gt;pytorch * /root/anaconda3/envs/pytorch&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然后去选择适合自己的 pytorch 版本，点击下面那个链接:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9weXRvcmNoLm9yZy8=&#34;&gt;https://pytorch.org/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;get started&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240207012929597.png&#34; alt=&#34;image-20240207012929597&#34; /&gt;&lt;/p&gt;
&lt;p&gt;输入到控制台:&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;弹出提示，输入 y，即可完成安装，显示 “done”。&lt;/p&gt;
&lt;p&gt;——————————————————————————————&lt;/p&gt;
&lt;h3 id=&#34;测试安装成功&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#测试安装成功&#34;&gt;#&lt;/a&gt; 测试安装成功&lt;/h3&gt;
&lt;p&gt;首先输入：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;python&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后在输入：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/M9jTXGulqSwhE8d.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;如果没有可以&lt;strong&gt;重新下载康康&lt;/strong&gt;或者&lt;strong&gt;查看环境&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;退出之后如何查看自己安装的环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#退出之后如何查看自己安装的环境&#34;&gt;#&lt;/a&gt; 退出之后如何查看自己安装的环境&lt;/h3&gt;
&lt;p&gt;如果在一台服务器上安装多个环境，一下子可能不记得需要激活哪个环境名称，这时候我们需要使用下面这个命令来查找：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda info --envs&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/hkcRHwlpSIx2UJ1.png&#34; alt=&#34;image-20240207012544351&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;复盘项目&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#复盘项目&#34;&gt;#&lt;/a&gt; 复盘项目&lt;/h2&gt;
&lt;p&gt;打开&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL0NWTEFCLVVuaWJvL2lucjJ2ZWM/dGFiPXJlYWRtZS1vdi1maWxl&#34;&gt;https://github.com/CVLAB-Unibo/inr2vec?tab=readme-ov-file&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;配置git&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#配置git&#34;&gt;#&lt;/a&gt; 配置 git&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;git --version&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果已经安装过了就可以直接跳到 3.2 了&lt;/p&gt;
&lt;p&gt;也不知道阿里云服务器什么发行版，输入如下命令查看&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;cat /etc/*-release&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/WQzUZjoMIs6tX4L.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;根据信息，Alibaba Cloud Linux 3 是一个与 RHEL（Red Hat Enterprise Linux）、Fedora 和 CentOS 兼容的发行版。&lt;/p&gt;
&lt;p&gt;使用与这些发行版相同的包管理器，大多数情况下将是  &lt;code&gt;yum&lt;/code&gt;  或者在某些新版本中是  &lt;code&gt;dnf&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;以下命令来安装 &lt;code&gt;git&lt;/code&gt; ：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo yum update&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;sudo yum install git&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;或者，如果系统支持  &lt;code&gt;dnf&lt;/code&gt; ：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo dnf update&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;sudo dnf install git&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;执行更新（ &lt;code&gt;yum update&lt;/code&gt;  或  &lt;code&gt;dnf update&lt;/code&gt; ）是一个好习惯，它会确保所有的软件包都是最新的。然后，使用安装命令来安装 &lt;code&gt;git&lt;/code&gt; 。&lt;/p&gt;
&lt;h3 id=&#34;git-clone-代码&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#git-clone-代码&#34;&gt;#&lt;/a&gt; git clone 代码&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;git clone https://github.com/CVLAB-Unibo/inr2vec.git&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;等一会儿就下好啦&lt;/p&gt;
&lt;h3 id=&#34;创建对应的环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建对应的环境&#34;&gt;#&lt;/a&gt; 创建对应的环境&lt;/h3&gt;
&lt;p&gt;！！！！以下内容仅作知识补充&lt;/p&gt;
&lt;h4 id=&#34;创建虚拟环境-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建虚拟环境-2&#34;&gt;#&lt;/a&gt; &lt;strong&gt;创建虚拟环境&lt;/strong&gt;：&lt;/h4&gt;
&lt;p&gt;​	Anaconda 创建环境：&lt;br /&gt;
​	比如，创建 pyhon＝3.7 的版本环境取名叫 &lt;code&gt;inr2vec&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda create -n inr2vec python=3.7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;删除虚拟环境操作谨慎操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#删除虚拟环境操作谨慎操作&#34;&gt;#&lt;/a&gt; &lt;strong&gt;删除虚拟环境操作&lt;/strong&gt;：（谨慎操作）&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda remove -n inr2vec --all&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;激活环境-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#激活环境-2&#34;&gt;#&lt;/a&gt; &lt;strong&gt;激活环境&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda activate inr2vec&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果发现进不去，那么&lt;/p&gt;
&lt;p&gt;先:  &lt;code&gt;source activate inr2vec&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;再:  &lt;code&gt;conda activate inr2vec&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 查看python版本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;python --version&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;查看环境下已有的安装包&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#查看环境下已有的安装包&#34;&gt;#&lt;/a&gt; 查看环境下已有的安装包：&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;效果如下&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/y6pf4seiK3kMhlY.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在进入虚拟环境的情况下， &lt;code&gt;安装对应包&lt;/code&gt; 直接&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install xxxx 或者 conda install xxxx&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install tensorflow&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt; ：此环境下的安装包在 &lt;code&gt;退出虚拟环境后无法使用&lt;/code&gt; 的&lt;/p&gt;
&lt;h4 id=&#34;退出当前虚拟环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#退出当前虚拟环境&#34;&gt;#&lt;/a&gt; 退出当前虚拟环境：&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda deactivate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;补充：Linux 下查看已有虚拟环境：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda-env &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;提醒：有时候遇到过几次异常，所以开启完虚拟环境后最好使用命令&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;which python&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;判断编译器位置最为稳妥（inr2vec 是虚拟环境名），有一个 &lt;code&gt;home/anaconda/envs/nlp/bin/python&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/6YRAH5giOa2KkId.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;如果发现没有在  &lt;code&gt;anaconda/envs&lt;/code&gt;  的虚拟环境 (inr2vec) 下，则多次使用&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda deactivate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;先退出当前环境，然后再重新使用  &lt;code&gt;source activate xxxx&lt;/code&gt;  进入环境&lt;/p&gt;
&lt;h4 id=&#34;重命名环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#重命名环境&#34;&gt;#&lt;/a&gt; 重命名环境&lt;/h4&gt;
&lt;p&gt;conda 其实没有重命名指令，实现重命名是通过 clone 完成的，分两步：&lt;br /&gt;
①先 clone 一份 new name 的环境&lt;br /&gt;
②删除 old name 的环境&lt;/p&gt;
&lt;p&gt;如，将 &lt;code&gt;inr2vec&lt;/code&gt;  重命名成 &lt;code&gt;tf2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda create -n tf2 --clone inr2vec&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;删除原环境&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda remove -n inr2vec --&lt;span class=&#34;built_in&#34;&gt;all&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;————————————&lt;/p&gt;
&lt;h3 id=&#34;根据readme-继续操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#根据readme-继续操作&#34;&gt;#&lt;/a&gt; 根据 readme 继续操作&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240207095527514.png&#34; alt=&#34;image-20240207095527514&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:%5CUsers%5C29758%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240207095541074.png&#34; alt=&#34;image-20240207095541074&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;跟着操作细节&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#跟着操作细节&#34;&gt;#&lt;/a&gt; 跟着操作细节&lt;/h3&gt;
&lt;p&gt;Create a virtual environment and install the library  &lt;code&gt;pycarus&lt;/code&gt; :&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;python3 -m venv .venv&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;source .venv/bin/activate&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pip install -U pip setuptools&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pip install pycarus&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;前两个没问题 第三个开始发现太慢了&lt;/p&gt;
&lt;p&gt;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt;
&lt;p&gt;于是决定来个镜像&lt;/p&gt;
&lt;h4 id=&#34;为本地conda环境配置国内镜像源&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为本地conda环境配置国内镜像源&#34;&gt;#&lt;/a&gt; 为本地 conda 环境配置国内镜像源&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda config --add channels https://mirrors.aliyun.com/pypi/simple/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&#34;为服务器的conda环境配置国内镜像源&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为服务器的conda环境配置国内镜像源&#34;&gt;#&lt;/a&gt; 为服务器的 conda 环境配置国内镜像源&lt;/h4&gt;
&lt;p&gt;添加清华镜像源&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/win-64/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;【注】使用 http 不是 https，在后面加上 win-64&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;常用操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#常用操作&#34;&gt;#&lt;/a&gt; 常用操作&lt;/h4&gt;
&lt;p&gt;显示添加的源通道&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda config --show-sources&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;移除某一镜像源&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda config --remove channels 源名称或链接 &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;验证安装&lt;/p&gt;
&lt;p&gt;为了确保正确安装了 PyTorch，我们可以通过运行示例 PyTorch 代码来验证安装。在这里，我们将构造一个随机初始张量&lt;/p&gt;
&lt;p&gt;在 anaconda prompt (miniconda3) 命令行或者 shell 中，输入：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;python &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后输入以下代码：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.rand(5, 3) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;print(x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输出应类似于以下内容：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[0.3380, 0.3845, 0.3217],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      [0.8337, 0.9050, 0.2650],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      [0.2979, 0.7141, 0.9069],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      [0.1449, 0.1132, 0.1375],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      [0.4675, 0.3947, 0.1426]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;此外，如果要检查 PyTorch 是否启用了 GPU 和 CUDA，请运行以下命令以返回是否启用了 CUDA 驱动程序：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight text&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;import torch  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.cuda.is_available()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果返回了 True， 恭喜您，成功安装了 GPU 版本。&lt;/p&gt;
&lt;p&gt;——————————————————————————————&lt;/p&gt;
&lt;p&gt;Then, try to import  &lt;code&gt;pycarus&lt;/code&gt;  to get the command that you can run to install all the needed Pytorch libraries:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常用的检查有没有 $ pip install -U pip setuptools 装好包的步骤：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ python3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import pycarus&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;...&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ModuleNotFoundError: PyTorch is not installed. Install it by running: source /XXX/.venv/lib/python3.8/site-packages/pycarus/install_torch.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;exit（）退出 python 环境&lt;/p&gt;
&lt;p&gt;不记得有没有安装好&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ pip install -U pip setuptools&lt;/code&gt; &lt;br /&gt;
 &lt;code&gt;$ pip install pycarus&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;重新执行啦&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install -U pip setuptools&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;————————————————————————&lt;/p&gt;
&lt;p&gt;出现这种情况&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/d7BQk6IHzu8DwAP.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;成功安装&lt;/p&gt;
&lt;p&gt;waring 是因为&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在 Linux 中， &lt;code&gt;root&lt;/code&gt;  是具有最高权限的用户账户，可以访问和修改系统的任何部分。以 &lt;code&gt;root&lt;/code&gt;  用户身份运行 &lt;code&gt;pip&lt;/code&gt;  可能会导致权限问题，尤其是当系统的包管理器试图管理相同的 Python 包时。这可能会导致系统中的包版本冲突或损坏。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;解决方法（无虚拟环境条件）&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;python3 -m venv myenv        # 创建一个名为myenv的虚拟环境&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;source myenv/bin/activate    # 激活虚拟环境&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pip install package_name     # 在虚拟环境中安装包&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;——————————————————&lt;/p&gt;
&lt;h3 id=&#34;尾声磁盘空间不足&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#尾声磁盘空间不足&#34;&gt;#&lt;/a&gt; 尾声：磁盘空间不足&lt;/h3&gt;
&lt;p&gt;安装包后&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;磁盘空间不足的错误（ &lt;code&gt;No space left on device&lt;/code&gt; ）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;删除不必要的文件或数据&lt;/strong&gt;：首先，检查您的磁盘空间使用情况，查找并删除不再需要的大文件或目录。可以使用如 &lt;code&gt;du&lt;/code&gt;  和 &lt;code&gt;df&lt;/code&gt;  命令来帮助您找出使用最多磁盘空间的目录。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;df -h          # 查看每个挂载点的磁盘使用情况&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;du -sh /*      # 查看根目录下每个文件夹的大小&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果发现特定目录特别大，可以深入查看该目录下的内容：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;du -sh /path/to/directory/*   # 替换路径以检查特定目录&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;当找到不需要的大文件或目录时，使用 &lt;code&gt;rm&lt;/code&gt;  命令删除它们：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;rm -rf /path/to/directory/large_file   # 替换路径和文件名以删除大文件&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/8IZJhUogzwb4jA5.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;清理缓存&lt;/strong&gt;：某些系统和应用程序会创建缓存文件，这些文件可以删除以释放空间。例如，您可以清理包管理器的缓存：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果您的系统基于 RPM（如 Alibaba Cloud Linux），您可以使用以下命令清理缓存：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo yum clean all  # 或者 sudo dnf clean all&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这将删除缓存的软件包和软件仓库元数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;删除旧的或无用的虚拟环境&lt;/strong&gt;：如果您创建了虚拟环境并且不再需要它们，可以直接删除包含虚拟环境的目录。假设您的虚拟环境名为 &lt;code&gt;myenv&lt;/code&gt; ，可以使用以下命令：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;rm -rf myenv&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;请确保只删除不再需要的环境，因为这个操作是不可逆的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;卸载不需要的软件包&lt;/strong&gt;：如果安装了不再需要的软件包，可以将它们卸载以释放空间。&lt;/p&gt;
&lt;p&gt;查找并卸载不再需要的软件包：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo yum remove package_name   # 替换package_name为您想要卸载的包名&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;检查并清理日志文件&lt;/strong&gt;：系统日志文件有时会变得很大。检查 &lt;code&gt;/var/log&lt;/code&gt;  目录并删除旧的或不必要的日志文件。对于日志文件的清理，建议谨慎行事，因为某些日志文件对于系统运维和故障排查很重要。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sudo du -sh /var/log/*     # 查看日志文件的大小&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;sudo rm /var/log/old_log_file   # 删除旧的或大的日志文件，替换old_log_file为实际文件名&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：在删除任何日志文件之前，请确保这些文件不是正在使用的或对系统运行至关重要的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;检查用户文件&lt;/strong&gt;：检查您的家目录下的文件，并移除不再需要的内容：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;cd ~                    # 切换到家目录&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;du -sh *               # 查看家目录下文件和目录的大小&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;rm -rf unnecessary_folder_or_file   # 删除不需要的文件或目录&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;警告&lt;/strong&gt;： &lt;code&gt;rm -rf&lt;/code&gt;  命令非常强大，它会在没有任何提示的情况下删除文件和目录。在使用之前，请确保您正在删除正确的文件或目录。如果不确定，最好备份或者单独删除文件而非整个目录。&lt;/p&gt;
&lt;p&gt;但要请格外小心，不要删除不了解的系统文件，这可能会导致系统不稳定或不可用。如果您不确定某个文件或目录的用途，请在删除前进行查询或备份。&lt;/p&gt;
&lt;h4 id=&#34;最后查看服务器情况&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#最后查看服务器情况&#34;&gt;#&lt;/a&gt; 最后查看服务器情况&lt;/h4&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;free -m&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/wZbEkGv5XIfuOep.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Mem 行（单位均为 M）：&lt;br /&gt;
* total：内存总数&lt;br /&gt;
 * used：已使用内存数&lt;br /&gt;
 * free：空闲内存数&lt;br /&gt;
 * shared：当前废弃不用&lt;br /&gt;
 * buffers：缓存内存数（Buffer）&lt;br /&gt;
* cached：缓存内舒数（Page）&lt;/p&gt;
&lt;p&gt;(-/+ buffers/cache) 行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（-buffers/cache）: 真正使用的内存数，指的是第一部分的 used - buffers - cached&lt;/li&gt;
&lt;li&gt;（+buffers/cache）: 可用的内存数，指的是第一部分的 free + buffers + cached&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Swap 行指交换分区。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;实际上不要看 free 少就觉得内存不足了，buffers 和 cached 都是可以在使用内存时拿来用的，应该以 (-/+ buffers/cache) 行的 free 和 used 来看。只要没发现 swap 的使用，就不用太担心，如果 swap 用了很多，那就要考虑增加物理内存了。&lt;/p&gt;
&lt;h4 id=&#34;查看cpu使用情况&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#查看cpu使用情况&#34;&gt;#&lt;/a&gt; 查看 CPU 使用情况&lt;/h4&gt;
&lt;p&gt;使用命令：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;top&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;大致结果类似下图&lt;/p&gt;
&lt;p&gt;上方文字部分的红框为总的 CPU 占用百分率，下方的表格是每个进程的 CPU 占用率，在表格第一行可以看到红框中占用率超过了 150%，这是因为服务器是多核 CPU，而该进程使用了多核。&lt;/p&gt;
&lt;h4 id=&#34;查看显卡使用情况&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#查看显卡使用情况&#34;&gt;#&lt;/a&gt; 查看显卡使用情况&lt;/h4&gt;
&lt;p&gt;使用命令：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;nvidia-smi&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;大致结果类似下图：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s2.loli.net/2024/02/07/kBApnN1zP2gU4M5.png&#34; alt=&#34;image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;表格中会显示显卡的一些信息，第一行是版本信息，第二行是标题栏，第三行就是具体的显卡信息了，如果有多个显卡，会有多行，每一行的信息值对应标题栏对应位置的信息。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;* GPU：编号&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Fan：风扇转速，在0到100%之间变动，这里是42%&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Name：显卡名，这里是TITAN X&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Temp：显卡温度，这里是69摄氏度&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Perf：性能状态，从P0到P12，P0性能最大，P12最小&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Persistence-M：持续模式的状态开关，该模式耗能大，但是启动新GPU应用时比较快，这里是off&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Pwr：能耗&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Bus-Id：涉及GPU总线的东西&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Disp.A：表示GPU的显示是否初始化&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Memory-Usage：现存使用率，这里已经快满了&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* GPU-Util：GPU利用率&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;* Compute M.：计算模式&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;需要注意的一点是显存占用率和 GPU 占用率是两个不一样的东西，类似于内存和 CPU，两个指标的占用率不一定是互相对应的。&lt;/p&gt;
&lt;p&gt;在下面就是每个进程使用的 GPU 情况了。&lt;/p&gt;
&lt;p&gt;———————————————&lt;/p&gt;
&lt;p&gt;由于项目复盘起来直接撑爆内存条，所以下一篇学习一些 clip 和 ulip&lt;/p&gt;
&lt;p&gt;参考文档&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZjIwMTcvYXJ0aWNsZS9kZXRhaWxzLzExODY3Njc2NQ==&#34;&gt;https://blog.csdn.net/wyf2017/article/details/118676765&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYnJpdGhUb1NwcmluZy9wLzEzNDk0OTY2Lmh0bWw=&#34;&gt;https://www.cnblogs.com/brithToSpring/p/13494966.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80MzQzNTY5NDc=&#34;&gt;https://zhuanlan.zhihu.com/p/434356947&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Nsb3Vkb3hfL2FydGljbGUvZGV0YWlscy83ODY1MTYzNw==&#34;&gt;https://blog.csdn.net/Cloudox_/article/details/78651637&lt;/span&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
